{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#DCGAN Task\n",
        "\n",
        "Essentially given an input data x:\n",
        "* The Generator G(z,Θ) is a mapping from some input distribution to $\\rho_g \\sim x$\n",
        "* The Discriminator D(z,Θ) is a mapping from $ρ_g$ to [0,1] which gives us the probability of whether z is a part of original distribution x  \n",
        "\n",
        "* here our x is Training imgs\n",
        "* $\\rho_g$ is generated imgs\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "MUzzXBRJOrBD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Importing Libs"
      ],
      "metadata": {
        "id": "AdXNQfhppXRq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R3-zIEPQUku2"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the hyperparameters/input shape etc. as a class to access later\n",
        "\n",
        "I have changed the hyperparams for faster training (may not be the best accuracy)"
      ],
      "metadata": {
        "id": "j8Tw8ktYpf3L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"images\", exist_ok=True)\n",
        "\n",
        "class OPT:\n",
        "  def __init__(self,epochs,batch,lr,b1,b2,cpu,lat,img,chan,samp):\n",
        "    self.n_epochs = epochs\n",
        "    self.batch_size = batch\n",
        "    self.lr = lr\n",
        "    self.b1 = b1\n",
        "    self.b2 = b2\n",
        "    self.n_cpu = cpu\n",
        "    self.latent_dim = lat\n",
        "    self.img_size = img\n",
        "    self.channels = chan\n",
        "    self.sample_interval = samp\n",
        "\n",
        "opt = OPT(50,1024,0.0002,0.5,0.999,4,100,32,1,400)\n",
        "\n",
        "cuda = True if torch.cuda.is_available() else False"
      ],
      "metadata": {
        "id": "0Z-gAGNZVAj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#init weights for conv and batchnorm layers with std : 0.02 and mean 0/1 for conv and batch norm resp.\n",
        "\n",
        "This helps the optimizer to not get s"
      ],
      "metadata": {
        "id": "TwIAB9nYqCyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)"
      ],
      "metadata": {
        "id": "lE5_udw0VXcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Defining the model as given in the paper\n",
        "\n",
        "Some Intresting things to note\n",
        "*   We do not have a FC layer like a normal CNN, we have a batchnorm layer which helps with the latency of inference and time of training\n",
        "*   It uses LeakyRelu which helps with the dying ReLU problem\n",
        "*   Uses Droput layers to increase the robustness of the model\n"
      ],
      "metadata": {
        "id": "ZUxN73HmqQAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.init_size = opt.img_size // 4\n",
        "        self.l1 = nn.Sequential(nn.Linear(opt.latent_dim, 128 * self.init_size ** 2))\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, opt.channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.l1(z)\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        img = self.conv_blocks(out)\n",
        "        return img"
      ],
      "metadata": {
        "id": "WmlxFPikVZuW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "\n",
        "        def discriminator_block(in_filters, out_filters, bn=True):\n",
        "            block = [nn.Conv2d(in_filters, out_filters, 3, 2, 1), nn.LeakyReLU(0.2, inplace=True), nn.Dropout2d(0.25)]\n",
        "            if bn:\n",
        "                block.append(nn.BatchNorm2d(out_filters, 0.8))\n",
        "            return block\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            *discriminator_block(opt.channels, 16, bn=False),\n",
        "            *discriminator_block(16, 32),\n",
        "            *discriminator_block(32, 64),\n",
        "            *discriminator_block(64, 128),\n",
        "        )\n",
        "        ds_size = opt.img_size // 2 ** 4\n",
        "        self.adv_layer = nn.Sequential(nn.Linear(128 * ds_size ** 2, 1), nn.Sigmoid())\n",
        "\n",
        "    def forward(self, img):\n",
        "        out = self.model(img)\n",
        "        out = out.view(out.shape[0], -1)\n",
        "        validity = self.adv_layer(out)\n",
        "\n",
        "        return validity\n"
      ],
      "metadata": {
        "id": "_tsUmJ2_XRDg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loss function\n",
        "adversarial_loss = torch.nn.BCELoss()"
      ],
      "metadata": {
        "id": "9WB1VETzXUIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialising generator and discriminator\n",
        "generator = Generator()\n",
        "discriminator = Discriminator()"
      ],
      "metadata": {
        "id": "mZD0vZsPXVPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#using gpu for discriminator and generator\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()"
      ],
      "metadata": {
        "id": "cwf03vaNXWcg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cuda"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZjybedgiZzRh",
        "outputId": "a7af2a2e-50b8-4bb3-beeb-6379aa576bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Applying normal distribution as given in paper\n",
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fbYEDxz8XYEQ",
        "outputId": "3536a620-3a6c-4acb-a473-eac614e46256"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Discriminator(\n",
              "  (model): Sequential(\n",
              "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (2): Dropout2d(p=0.25, inplace=False)\n",
              "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (5): Dropout2d(p=0.25, inplace=False)\n",
              "    (6): BatchNorm2d(32, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (7): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (8): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (9): Dropout2d(p=0.25, inplace=False)\n",
              "    (10): BatchNorm2d(64, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (11): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
              "    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n",
              "    (13): Dropout2d(p=0.25, inplace=False)\n",
              "    (14): BatchNorm2d(128, eps=0.8, momentum=0.1, affine=True, track_running_stats=True)\n",
              "  )\n",
              "  (adv_layer): Sequential(\n",
              "    (0): Linear(in_features=512, out_features=1, bias=True)\n",
              "    (1): Sigmoid()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Downloading the Dataset : MNIST Numbers\n",
        "\n",
        "This was in the code, thought I will just use this"
      ],
      "metadata": {
        "id": "Z6vbd3eNrYTh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"../../data/mnist\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [transforms.Resize(opt.img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
        "        ),\n",
        "    ),\n",
        "    batch_size=opt.batch_size,\n",
        "    shuffle=True,\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7B57jLi0XZyA",
        "outputId": "c7790df9-014f-4d29-9e6a-5e2f512fe845"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 449890288.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 38321953.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 216724370.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to ../../data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 4542/4542 [00:00<00:00, 3082609.83it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../../data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../../data/mnist/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting opitimizer and alias for tensor class\n",
        "\n",
        "The paper seems to have used Mini-Batch SGD, I would prefer Adam"
      ],
      "metadata": {
        "id": "8HefN0HcrgAg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#using adam opitmizer\n",
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=opt.lr, betas=(opt.b1, opt.b2))\n",
        "\n",
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n"
      ],
      "metadata": {
        "id": "vqxM2uVSZQyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Training Loop\n",
        "\n",
        "* We init the gnd truths for the gen and real imgs\n",
        "* then we train the gen by feeding in gaussian noise and real imgs\n",
        "* we train the discriminator on the real and fake imgs\n",
        "* One thing to note is that the real_imgs is a leaf variable thus the loss info from gen are carried to disc and vice-versa"
      ],
      "metadata": {
        "id": "evy4rcEnrnDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(opt.n_epochs):\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "\n",
        "        # Init adversarial ground truths\n",
        "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "\n",
        "        #generator loop\n",
        "        optimizer_G.zero_grad()\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], opt.latent_dim))))\n",
        "        gen_imgs = generator(z)\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
        "        g_loss.backward()\n",
        "        optimizer_G.step()\n",
        "\n",
        "\n",
        "        #discriminator loop\n",
        "        optimizer_D.zero_grad()\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "        d_loss.backward()\n",
        "        optimizer_D.step()\n",
        "\n",
        "        print(\n",
        "            f\"[Epoch {epoch}{opt.n_epochs}] [Batch {i}{len(dataloader)}] [D loss: {d_loss.item()}] [G loss: %f]\"\n",
        "            % (epoch, opt.n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
        "        )\n",
        "\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        if batches_done % opt.sample_interval == 0:\n",
        "            save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mD7h2WAtZrvv",
        "outputId": "dc2b6efa-e4dc-4de5-9811-e3272ec0d809"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 0/50] [Batch 0/59] [D loss: 0.693352] [G loss: 0.672998]\n",
            "[Epoch 0/50] [Batch 1/59] [D loss: 0.693257] [G loss: 0.673688]\n",
            "[Epoch 0/50] [Batch 2/59] [D loss: 0.693147] [G loss: 0.674437]\n",
            "[Epoch 0/50] [Batch 3/59] [D loss: 0.693044] [G loss: 0.675041]\n",
            "[Epoch 0/50] [Batch 4/59] [D loss: 0.692917] [G loss: 0.675741]\n",
            "[Epoch 0/50] [Batch 5/59] [D loss: 0.692798] [G loss: 0.676392]\n",
            "[Epoch 0/50] [Batch 6/59] [D loss: 0.692581] [G loss: 0.677068]\n",
            "[Epoch 0/50] [Batch 7/59] [D loss: 0.692355] [G loss: 0.677738]\n",
            "[Epoch 0/50] [Batch 8/59] [D loss: 0.692143] [G loss: 0.678277]\n",
            "[Epoch 0/50] [Batch 9/59] [D loss: 0.691925] [G loss: 0.678694]\n",
            "[Epoch 0/50] [Batch 10/59] [D loss: 0.691647] [G loss: 0.679031]\n",
            "[Epoch 0/50] [Batch 11/59] [D loss: 0.691339] [G loss: 0.679034]\n",
            "[Epoch 0/50] [Batch 12/59] [D loss: 0.691299] [G loss: 0.678465]\n",
            "[Epoch 0/50] [Batch 13/59] [D loss: 0.691042] [G loss: 0.677697]\n",
            "[Epoch 0/50] [Batch 14/59] [D loss: 0.691506] [G loss: 0.676357]\n",
            "[Epoch 0/50] [Batch 15/59] [D loss: 0.691850] [G loss: 0.675116]\n",
            "[Epoch 0/50] [Batch 16/59] [D loss: 0.692227] [G loss: 0.673745]\n",
            "[Epoch 0/50] [Batch 17/59] [D loss: 0.692385] [G loss: 0.673627]\n",
            "[Epoch 0/50] [Batch 18/59] [D loss: 0.692736] [G loss: 0.673613]\n",
            "[Epoch 0/50] [Batch 19/59] [D loss: 0.693144] [G loss: 0.675047]\n",
            "[Epoch 0/50] [Batch 20/59] [D loss: 0.692778] [G loss: 0.677329]\n",
            "[Epoch 0/50] [Batch 21/59] [D loss: 0.692620] [G loss: 0.680025]\n",
            "[Epoch 0/50] [Batch 22/59] [D loss: 0.692126] [G loss: 0.683639]\n",
            "[Epoch 0/50] [Batch 23/59] [D loss: 0.691026] [G loss: 0.687442]\n",
            "[Epoch 0/50] [Batch 24/59] [D loss: 0.690137] [G loss: 0.691062]\n",
            "[Epoch 0/50] [Batch 25/59] [D loss: 0.688644] [G loss: 0.694901]\n",
            "[Epoch 0/50] [Batch 26/59] [D loss: 0.687389] [G loss: 0.699000]\n",
            "[Epoch 0/50] [Batch 27/59] [D loss: 0.686092] [G loss: 0.702935]\n",
            "[Epoch 0/50] [Batch 28/59] [D loss: 0.685433] [G loss: 0.707122]\n",
            "[Epoch 0/50] [Batch 29/59] [D loss: 0.684760] [G loss: 0.708434]\n",
            "[Epoch 0/50] [Batch 30/59] [D loss: 0.684758] [G loss: 0.707321]\n",
            "[Epoch 0/50] [Batch 31/59] [D loss: 0.685625] [G loss: 0.705811]\n",
            "[Epoch 0/50] [Batch 32/59] [D loss: 0.685748] [G loss: 0.700061]\n",
            "[Epoch 0/50] [Batch 33/59] [D loss: 0.685914] [G loss: 0.696620]\n",
            "[Epoch 0/50] [Batch 34/59] [D loss: 0.685772] [G loss: 0.690817]\n",
            "[Epoch 0/50] [Batch 35/59] [D loss: 0.682604] [G loss: 0.688486]\n",
            "[Epoch 0/50] [Batch 36/59] [D loss: 0.680207] [G loss: 0.684952]\n",
            "[Epoch 0/50] [Batch 37/59] [D loss: 0.677583] [G loss: 0.683847]\n",
            "[Epoch 0/50] [Batch 38/59] [D loss: 0.672919] [G loss: 0.680823]\n",
            "[Epoch 0/50] [Batch 39/59] [D loss: 0.669473] [G loss: 0.675704]\n",
            "[Epoch 0/50] [Batch 40/59] [D loss: 0.667360] [G loss: 0.670842]\n",
            "[Epoch 0/50] [Batch 41/59] [D loss: 0.664827] [G loss: 0.660587]\n",
            "[Epoch 0/50] [Batch 42/59] [D loss: 0.665730] [G loss: 0.647251]\n",
            "[Epoch 0/50] [Batch 43/59] [D loss: 0.667237] [G loss: 0.635490]\n",
            "[Epoch 0/50] [Batch 44/59] [D loss: 0.674801] [G loss: 0.619597]\n",
            "[Epoch 0/50] [Batch 45/59] [D loss: 0.683644] [G loss: 0.606788]\n",
            "[Epoch 0/50] [Batch 46/59] [D loss: 0.688629] [G loss: 0.601569]\n",
            "[Epoch 0/50] [Batch 47/59] [D loss: 0.696103] [G loss: 0.605683]\n",
            "[Epoch 0/50] [Batch 48/59] [D loss: 0.700880] [G loss: 0.616257]\n",
            "[Epoch 0/50] [Batch 49/59] [D loss: 0.703046] [G loss: 0.634963]\n",
            "[Epoch 0/50] [Batch 50/59] [D loss: 0.702722] [G loss: 0.656588]\n",
            "[Epoch 0/50] [Batch 51/59] [D loss: 0.698755] [G loss: 0.677556]\n",
            "[Epoch 0/50] [Batch 52/59] [D loss: 0.697236] [G loss: 0.693860]\n",
            "[Epoch 0/50] [Batch 53/59] [D loss: 0.694448] [G loss: 0.715091]\n",
            "[Epoch 0/50] [Batch 54/59] [D loss: 0.691823] [G loss: 0.727350]\n",
            "[Epoch 0/50] [Batch 55/59] [D loss: 0.687792] [G loss: 0.739596]\n",
            "[Epoch 0/50] [Batch 56/59] [D loss: 0.687343] [G loss: 0.745392]\n",
            "[Epoch 0/50] [Batch 57/59] [D loss: 0.684461] [G loss: 0.751457]\n",
            "[Epoch 0/50] [Batch 58/59] [D loss: 0.682479] [G loss: 0.750840]\n",
            "[Epoch 1/50] [Batch 0/59] [D loss: 0.684344] [G loss: 0.750827]\n",
            "[Epoch 1/50] [Batch 1/59] [D loss: 0.686187] [G loss: 0.742460]\n",
            "[Epoch 1/50] [Batch 2/59] [D loss: 0.692231] [G loss: 0.727042]\n",
            "[Epoch 1/50] [Batch 3/59] [D loss: 0.700098] [G loss: 0.708166]\n",
            "[Epoch 1/50] [Batch 4/59] [D loss: 0.706953] [G loss: 0.689291]\n",
            "[Epoch 1/50] [Batch 5/59] [D loss: 0.709795] [G loss: 0.674275]\n",
            "[Epoch 1/50] [Batch 6/59] [D loss: 0.704235] [G loss: 0.669036]\n",
            "[Epoch 1/50] [Batch 7/59] [D loss: 0.700562] [G loss: 0.669937]\n",
            "[Epoch 1/50] [Batch 8/59] [D loss: 0.694857] [G loss: 0.670899]\n",
            "[Epoch 1/50] [Batch 9/59] [D loss: 0.687607] [G loss: 0.676112]\n",
            "[Epoch 1/50] [Batch 10/59] [D loss: 0.681912] [G loss: 0.677528]\n",
            "[Epoch 1/50] [Batch 11/59] [D loss: 0.676357] [G loss: 0.680479]\n",
            "[Epoch 1/50] [Batch 12/59] [D loss: 0.669244] [G loss: 0.679498]\n",
            "[Epoch 1/50] [Batch 13/59] [D loss: 0.665266] [G loss: 0.677187]\n",
            "[Epoch 1/50] [Batch 14/59] [D loss: 0.664608] [G loss: 0.666335]\n",
            "[Epoch 1/50] [Batch 15/59] [D loss: 0.671837] [G loss: 0.646345]\n",
            "[Epoch 1/50] [Batch 16/59] [D loss: 0.683914] [G loss: 0.619192]\n",
            "[Epoch 1/50] [Batch 17/59] [D loss: 0.701165] [G loss: 0.590815]\n",
            "[Epoch 1/50] [Batch 18/59] [D loss: 0.713558] [G loss: 0.585817]\n",
            "[Epoch 1/50] [Batch 19/59] [D loss: 0.718298] [G loss: 0.593694]\n",
            "[Epoch 1/50] [Batch 20/59] [D loss: 0.720849] [G loss: 0.615670]\n",
            "[Epoch 1/50] [Batch 21/59] [D loss: 0.717090] [G loss: 0.644243]\n",
            "[Epoch 1/50] [Batch 22/59] [D loss: 0.712159] [G loss: 0.670191]\n",
            "[Epoch 1/50] [Batch 23/59] [D loss: 0.708119] [G loss: 0.693965]\n",
            "[Epoch 1/50] [Batch 24/59] [D loss: 0.703203] [G loss: 0.716064]\n",
            "[Epoch 1/50] [Batch 25/59] [D loss: 0.698248] [G loss: 0.733945]\n",
            "[Epoch 1/50] [Batch 26/59] [D loss: 0.696565] [G loss: 0.745603]\n",
            "[Epoch 1/50] [Batch 27/59] [D loss: 0.692515] [G loss: 0.755550]\n",
            "[Epoch 1/50] [Batch 28/59] [D loss: 0.689963] [G loss: 0.765980]\n",
            "[Epoch 1/50] [Batch 29/59] [D loss: 0.686877] [G loss: 0.770437]\n",
            "[Epoch 1/50] [Batch 30/59] [D loss: 0.684634] [G loss: 0.776017]\n",
            "[Epoch 1/50] [Batch 31/59] [D loss: 0.683917] [G loss: 0.779387]\n",
            "[Epoch 1/50] [Batch 32/59] [D loss: 0.681197] [G loss: 0.786034]\n",
            "[Epoch 1/50] [Batch 33/59] [D loss: 0.678840] [G loss: 0.786333]\n",
            "[Epoch 1/50] [Batch 34/59] [D loss: 0.676111] [G loss: 0.785103]\n",
            "[Epoch 1/50] [Batch 35/59] [D loss: 0.676934] [G loss: 0.786034]\n",
            "[Epoch 1/50] [Batch 36/59] [D loss: 0.677275] [G loss: 0.782729]\n",
            "[Epoch 1/50] [Batch 37/59] [D loss: 0.679032] [G loss: 0.778237]\n",
            "[Epoch 1/50] [Batch 38/59] [D loss: 0.682709] [G loss: 0.762889]\n",
            "[Epoch 1/50] [Batch 39/59] [D loss: 0.684518] [G loss: 0.747537]\n",
            "[Epoch 1/50] [Batch 40/59] [D loss: 0.689461] [G loss: 0.724771]\n",
            "[Epoch 1/50] [Batch 41/59] [D loss: 0.696504] [G loss: 0.703096]\n",
            "[Epoch 1/50] [Batch 42/59] [D loss: 0.702183] [G loss: 0.679092]\n",
            "[Epoch 1/50] [Batch 43/59] [D loss: 0.708249] [G loss: 0.661388]\n",
            "[Epoch 1/50] [Batch 44/59] [D loss: 0.708522] [G loss: 0.651640]\n",
            "[Epoch 1/50] [Batch 45/59] [D loss: 0.703063] [G loss: 0.650315]\n",
            "[Epoch 1/50] [Batch 46/59] [D loss: 0.699149] [G loss: 0.652023]\n",
            "[Epoch 1/50] [Batch 47/59] [D loss: 0.693601] [G loss: 0.654211]\n",
            "[Epoch 1/50] [Batch 48/59] [D loss: 0.689227] [G loss: 0.656015]\n",
            "[Epoch 1/50] [Batch 49/59] [D loss: 0.686477] [G loss: 0.658047]\n",
            "[Epoch 1/50] [Batch 50/59] [D loss: 0.684892] [G loss: 0.658118]\n",
            "[Epoch 1/50] [Batch 51/59] [D loss: 0.685120] [G loss: 0.656194]\n",
            "[Epoch 1/50] [Batch 52/59] [D loss: 0.682933] [G loss: 0.655696]\n",
            "[Epoch 1/50] [Batch 53/59] [D loss: 0.685037] [G loss: 0.651946]\n",
            "[Epoch 1/50] [Batch 54/59] [D loss: 0.687671] [G loss: 0.643728]\n",
            "[Epoch 1/50] [Batch 55/59] [D loss: 0.690739] [G loss: 0.641491]\n",
            "[Epoch 1/50] [Batch 56/59] [D loss: 0.694513] [G loss: 0.638315]\n",
            "[Epoch 1/50] [Batch 57/59] [D loss: 0.696226] [G loss: 0.636373]\n",
            "[Epoch 1/50] [Batch 58/59] [D loss: 0.701555] [G loss: 0.641432]\n",
            "[Epoch 2/50] [Batch 0/59] [D loss: 0.702790] [G loss: 0.647182]\n",
            "[Epoch 2/50] [Batch 1/59] [D loss: 0.701070] [G loss: 0.657284]\n",
            "[Epoch 2/50] [Batch 2/59] [D loss: 0.702924] [G loss: 0.666954]\n",
            "[Epoch 2/50] [Batch 3/59] [D loss: 0.701622] [G loss: 0.677048]\n",
            "[Epoch 2/50] [Batch 4/59] [D loss: 0.700703] [G loss: 0.686647]\n",
            "[Epoch 2/50] [Batch 5/59] [D loss: 0.698773] [G loss: 0.696410]\n",
            "[Epoch 2/50] [Batch 6/59] [D loss: 0.698161] [G loss: 0.705559]\n",
            "[Epoch 2/50] [Batch 7/59] [D loss: 0.695471] [G loss: 0.715344]\n",
            "[Epoch 2/50] [Batch 8/59] [D loss: 0.694241] [G loss: 0.720644]\n",
            "[Epoch 2/50] [Batch 9/59] [D loss: 0.693857] [G loss: 0.727133]\n",
            "[Epoch 2/50] [Batch 10/59] [D loss: 0.691982] [G loss: 0.732946]\n",
            "[Epoch 2/50] [Batch 11/59] [D loss: 0.691983] [G loss: 0.738444]\n",
            "[Epoch 2/50] [Batch 12/59] [D loss: 0.691114] [G loss: 0.739056]\n",
            "[Epoch 2/50] [Batch 13/59] [D loss: 0.691148] [G loss: 0.741554]\n",
            "[Epoch 2/50] [Batch 14/59] [D loss: 0.690628] [G loss: 0.743531]\n",
            "[Epoch 2/50] [Batch 15/59] [D loss: 0.691487] [G loss: 0.742315]\n",
            "[Epoch 2/50] [Batch 16/59] [D loss: 0.692219] [G loss: 0.742348]\n",
            "[Epoch 2/50] [Batch 17/59] [D loss: 0.692224] [G loss: 0.737642]\n",
            "[Epoch 2/50] [Batch 18/59] [D loss: 0.695740] [G loss: 0.735310]\n",
            "[Epoch 2/50] [Batch 19/59] [D loss: 0.696085] [G loss: 0.730046]\n",
            "[Epoch 2/50] [Batch 20/59] [D loss: 0.697595] [G loss: 0.727287]\n",
            "[Epoch 2/50] [Batch 21/59] [D loss: 0.697368] [G loss: 0.723659]\n",
            "[Epoch 2/50] [Batch 22/59] [D loss: 0.698078] [G loss: 0.717758]\n",
            "[Epoch 2/50] [Batch 23/59] [D loss: 0.699581] [G loss: 0.711773]\n",
            "[Epoch 2/50] [Batch 24/59] [D loss: 0.697946] [G loss: 0.709062]\n",
            "[Epoch 2/50] [Batch 25/59] [D loss: 0.697428] [G loss: 0.705690]\n",
            "[Epoch 2/50] [Batch 26/59] [D loss: 0.696434] [G loss: 0.702410]\n",
            "[Epoch 2/50] [Batch 27/59] [D loss: 0.696336] [G loss: 0.700235]\n",
            "[Epoch 2/50] [Batch 28/59] [D loss: 0.694711] [G loss: 0.698344]\n",
            "[Epoch 2/50] [Batch 29/59] [D loss: 0.694376] [G loss: 0.696533]\n",
            "[Epoch 2/50] [Batch 30/59] [D loss: 0.693096] [G loss: 0.695051]\n",
            "[Epoch 2/50] [Batch 31/59] [D loss: 0.692726] [G loss: 0.693271]\n",
            "[Epoch 2/50] [Batch 32/59] [D loss: 0.691702] [G loss: 0.690824]\n",
            "[Epoch 2/50] [Batch 33/59] [D loss: 0.690485] [G loss: 0.689421]\n",
            "[Epoch 2/50] [Batch 34/59] [D loss: 0.691207] [G loss: 0.687354]\n",
            "[Epoch 2/50] [Batch 35/59] [D loss: 0.690961] [G loss: 0.686430]\n",
            "[Epoch 2/50] [Batch 36/59] [D loss: 0.691111] [G loss: 0.684573]\n",
            "[Epoch 2/50] [Batch 37/59] [D loss: 0.691660] [G loss: 0.682672]\n",
            "[Epoch 2/50] [Batch 38/59] [D loss: 0.692312] [G loss: 0.680210]\n",
            "[Epoch 2/50] [Batch 39/59] [D loss: 0.691681] [G loss: 0.678838]\n",
            "[Epoch 2/50] [Batch 40/59] [D loss: 0.693490] [G loss: 0.677975]\n",
            "[Epoch 2/50] [Batch 41/59] [D loss: 0.692990] [G loss: 0.678627]\n",
            "[Epoch 2/50] [Batch 42/59] [D loss: 0.694726] [G loss: 0.679338]\n",
            "[Epoch 2/50] [Batch 43/59] [D loss: 0.695104] [G loss: 0.678786]\n",
            "[Epoch 2/50] [Batch 44/59] [D loss: 0.695026] [G loss: 0.682227]\n",
            "[Epoch 2/50] [Batch 45/59] [D loss: 0.694513] [G loss: 0.683225]\n",
            "[Epoch 2/50] [Batch 46/59] [D loss: 0.696278] [G loss: 0.685491]\n",
            "[Epoch 2/50] [Batch 47/59] [D loss: 0.695763] [G loss: 0.688445]\n",
            "[Epoch 2/50] [Batch 48/59] [D loss: 0.695045] [G loss: 0.693003]\n",
            "[Epoch 2/50] [Batch 49/59] [D loss: 0.694716] [G loss: 0.695974]\n",
            "[Epoch 2/50] [Batch 50/59] [D loss: 0.695144] [G loss: 0.698926]\n",
            "[Epoch 2/50] [Batch 51/59] [D loss: 0.694555] [G loss: 0.700239]\n",
            "[Epoch 2/50] [Batch 52/59] [D loss: 0.694588] [G loss: 0.703816]\n",
            "[Epoch 2/50] [Batch 53/59] [D loss: 0.693909] [G loss: 0.705550]\n",
            "[Epoch 2/50] [Batch 54/59] [D loss: 0.694301] [G loss: 0.707432]\n",
            "[Epoch 2/50] [Batch 55/59] [D loss: 0.693890] [G loss: 0.708770]\n",
            "[Epoch 2/50] [Batch 56/59] [D loss: 0.694272] [G loss: 0.710269]\n",
            "[Epoch 2/50] [Batch 57/59] [D loss: 0.694155] [G loss: 0.710603]\n",
            "[Epoch 2/50] [Batch 58/59] [D loss: 0.693558] [G loss: 0.712116]\n",
            "[Epoch 3/50] [Batch 0/59] [D loss: 0.692739] [G loss: 0.713179]\n",
            "[Epoch 3/50] [Batch 1/59] [D loss: 0.693455] [G loss: 0.714762]\n",
            "[Epoch 3/50] [Batch 2/59] [D loss: 0.693885] [G loss: 0.714404]\n",
            "[Epoch 3/50] [Batch 3/59] [D loss: 0.693772] [G loss: 0.715528]\n",
            "[Epoch 3/50] [Batch 4/59] [D loss: 0.693540] [G loss: 0.714396]\n",
            "[Epoch 3/50] [Batch 5/59] [D loss: 0.693746] [G loss: 0.713583]\n",
            "[Epoch 3/50] [Batch 6/59] [D loss: 0.693891] [G loss: 0.714272]\n",
            "[Epoch 3/50] [Batch 7/59] [D loss: 0.693605] [G loss: 0.712439]\n",
            "[Epoch 3/50] [Batch 8/59] [D loss: 0.693830] [G loss: 0.711803]\n",
            "[Epoch 3/50] [Batch 9/59] [D loss: 0.694118] [G loss: 0.710689]\n",
            "[Epoch 3/50] [Batch 10/59] [D loss: 0.694823] [G loss: 0.708907]\n",
            "[Epoch 3/50] [Batch 11/59] [D loss: 0.694136] [G loss: 0.708353]\n",
            "[Epoch 3/50] [Batch 12/59] [D loss: 0.694192] [G loss: 0.705800]\n",
            "[Epoch 3/50] [Batch 13/59] [D loss: 0.694097] [G loss: 0.704805]\n",
            "[Epoch 3/50] [Batch 14/59] [D loss: 0.694729] [G loss: 0.704283]\n",
            "[Epoch 3/50] [Batch 15/59] [D loss: 0.694301] [G loss: 0.702874]\n",
            "[Epoch 3/50] [Batch 16/59] [D loss: 0.694678] [G loss: 0.700974]\n",
            "[Epoch 3/50] [Batch 17/59] [D loss: 0.693960] [G loss: 0.700283]\n",
            "[Epoch 3/50] [Batch 18/59] [D loss: 0.693813] [G loss: 0.698478]\n",
            "[Epoch 3/50] [Batch 19/59] [D loss: 0.694272] [G loss: 0.697589]\n",
            "[Epoch 3/50] [Batch 20/59] [D loss: 0.693753] [G loss: 0.696712]\n",
            "[Epoch 3/50] [Batch 21/59] [D loss: 0.693103] [G loss: 0.695270]\n",
            "[Epoch 3/50] [Batch 22/59] [D loss: 0.693166] [G loss: 0.693896]\n",
            "[Epoch 3/50] [Batch 23/59] [D loss: 0.692140] [G loss: 0.693929]\n",
            "[Epoch 3/50] [Batch 24/59] [D loss: 0.692787] [G loss: 0.692550]\n",
            "[Epoch 3/50] [Batch 25/59] [D loss: 0.692125] [G loss: 0.691159]\n",
            "[Epoch 3/50] [Batch 26/59] [D loss: 0.692016] [G loss: 0.689957]\n",
            "[Epoch 3/50] [Batch 27/59] [D loss: 0.692121] [G loss: 0.688657]\n",
            "[Epoch 3/50] [Batch 28/59] [D loss: 0.691628] [G loss: 0.688165]\n",
            "[Epoch 3/50] [Batch 29/59] [D loss: 0.691892] [G loss: 0.686540]\n",
            "[Epoch 3/50] [Batch 30/59] [D loss: 0.690789] [G loss: 0.685014]\n",
            "[Epoch 3/50] [Batch 31/59] [D loss: 0.691155] [G loss: 0.685041]\n",
            "[Epoch 3/50] [Batch 32/59] [D loss: 0.691624] [G loss: 0.682963]\n",
            "[Epoch 3/50] [Batch 33/59] [D loss: 0.691303] [G loss: 0.682709]\n",
            "[Epoch 3/50] [Batch 34/59] [D loss: 0.691954] [G loss: 0.681617]\n",
            "[Epoch 3/50] [Batch 35/59] [D loss: 0.692353] [G loss: 0.680525]\n",
            "[Epoch 3/50] [Batch 36/59] [D loss: 0.692371] [G loss: 0.680552]\n",
            "[Epoch 3/50] [Batch 37/59] [D loss: 0.692173] [G loss: 0.680713]\n",
            "[Epoch 3/50] [Batch 38/59] [D loss: 0.692720] [G loss: 0.681192]\n",
            "[Epoch 3/50] [Batch 39/59] [D loss: 0.692607] [G loss: 0.682202]\n",
            "[Epoch 3/50] [Batch 40/59] [D loss: 0.693635] [G loss: 0.683634]\n",
            "[Epoch 3/50] [Batch 41/59] [D loss: 0.693545] [G loss: 0.685542]\n",
            "[Epoch 3/50] [Batch 42/59] [D loss: 0.693395] [G loss: 0.687033]\n",
            "[Epoch 3/50] [Batch 43/59] [D loss: 0.693846] [G loss: 0.688762]\n",
            "[Epoch 3/50] [Batch 44/59] [D loss: 0.693899] [G loss: 0.689574]\n",
            "[Epoch 3/50] [Batch 45/59] [D loss: 0.693548] [G loss: 0.693111]\n",
            "[Epoch 3/50] [Batch 46/59] [D loss: 0.692832] [G loss: 0.694876]\n",
            "[Epoch 3/50] [Batch 47/59] [D loss: 0.692889] [G loss: 0.696505]\n",
            "[Epoch 3/50] [Batch 48/59] [D loss: 0.692673] [G loss: 0.698335]\n",
            "[Epoch 3/50] [Batch 49/59] [D loss: 0.692712] [G loss: 0.700477]\n",
            "[Epoch 3/50] [Batch 50/59] [D loss: 0.692085] [G loss: 0.702272]\n",
            "[Epoch 3/50] [Batch 51/59] [D loss: 0.692882] [G loss: 0.703689]\n",
            "[Epoch 3/50] [Batch 52/59] [D loss: 0.692415] [G loss: 0.704707]\n",
            "[Epoch 3/50] [Batch 53/59] [D loss: 0.691882] [G loss: 0.706069]\n",
            "[Epoch 3/50] [Batch 54/59] [D loss: 0.691999] [G loss: 0.706360]\n",
            "[Epoch 3/50] [Batch 55/59] [D loss: 0.691686] [G loss: 0.707887]\n",
            "[Epoch 3/50] [Batch 56/59] [D loss: 0.692023] [G loss: 0.707893]\n",
            "[Epoch 3/50] [Batch 57/59] [D loss: 0.691386] [G loss: 0.707536]\n",
            "[Epoch 3/50] [Batch 58/59] [D loss: 0.691335] [G loss: 0.708145]\n",
            "[Epoch 4/50] [Batch 0/59] [D loss: 0.691846] [G loss: 0.708299]\n",
            "[Epoch 4/50] [Batch 1/59] [D loss: 0.691957] [G loss: 0.707825]\n",
            "[Epoch 4/50] [Batch 2/59] [D loss: 0.691830] [G loss: 0.707488]\n",
            "[Epoch 4/50] [Batch 3/59] [D loss: 0.692269] [G loss: 0.706842]\n",
            "[Epoch 4/50] [Batch 4/59] [D loss: 0.693038] [G loss: 0.706568]\n",
            "[Epoch 4/50] [Batch 5/59] [D loss: 0.693676] [G loss: 0.704730]\n",
            "[Epoch 4/50] [Batch 6/59] [D loss: 0.694332] [G loss: 0.703641]\n",
            "[Epoch 4/50] [Batch 7/59] [D loss: 0.693763] [G loss: 0.702650]\n",
            "[Epoch 4/50] [Batch 8/59] [D loss: 0.694427] [G loss: 0.700810]\n",
            "[Epoch 4/50] [Batch 9/59] [D loss: 0.694462] [G loss: 0.698958]\n",
            "[Epoch 4/50] [Batch 10/59] [D loss: 0.694493] [G loss: 0.697934]\n",
            "[Epoch 4/50] [Batch 11/59] [D loss: 0.694994] [G loss: 0.695463]\n",
            "[Epoch 4/50] [Batch 12/59] [D loss: 0.695178] [G loss: 0.693986]\n",
            "[Epoch 4/50] [Batch 13/59] [D loss: 0.695017] [G loss: 0.692721]\n",
            "[Epoch 4/50] [Batch 14/59] [D loss: 0.695054] [G loss: 0.691746]\n",
            "[Epoch 4/50] [Batch 15/59] [D loss: 0.694625] [G loss: 0.690903]\n",
            "[Epoch 4/50] [Batch 16/59] [D loss: 0.694778] [G loss: 0.690102]\n",
            "[Epoch 4/50] [Batch 17/59] [D loss: 0.694849] [G loss: 0.688896]\n",
            "[Epoch 4/50] [Batch 18/59] [D loss: 0.694407] [G loss: 0.688470]\n",
            "[Epoch 4/50] [Batch 19/59] [D loss: 0.693704] [G loss: 0.687395]\n",
            "[Epoch 4/50] [Batch 20/59] [D loss: 0.693842] [G loss: 0.688555]\n",
            "[Epoch 4/50] [Batch 21/59] [D loss: 0.693110] [G loss: 0.686899]\n",
            "[Epoch 4/50] [Batch 22/59] [D loss: 0.692583] [G loss: 0.686130]\n",
            "[Epoch 4/50] [Batch 23/59] [D loss: 0.692319] [G loss: 0.685728]\n",
            "[Epoch 4/50] [Batch 24/59] [D loss: 0.692361] [G loss: 0.684614]\n",
            "[Epoch 4/50] [Batch 25/59] [D loss: 0.691842] [G loss: 0.683466]\n",
            "[Epoch 4/50] [Batch 26/59] [D loss: 0.691371] [G loss: 0.682123]\n",
            "[Epoch 4/50] [Batch 27/59] [D loss: 0.692007] [G loss: 0.681291]\n",
            "[Epoch 4/50] [Batch 28/59] [D loss: 0.691995] [G loss: 0.679922]\n",
            "[Epoch 4/50] [Batch 29/59] [D loss: 0.691471] [G loss: 0.680052]\n",
            "[Epoch 4/50] [Batch 30/59] [D loss: 0.691255] [G loss: 0.679248]\n",
            "[Epoch 4/50] [Batch 31/59] [D loss: 0.692180] [G loss: 0.678401]\n",
            "[Epoch 4/50] [Batch 32/59] [D loss: 0.691665] [G loss: 0.678443]\n",
            "[Epoch 4/50] [Batch 33/59] [D loss: 0.692422] [G loss: 0.677357]\n",
            "[Epoch 4/50] [Batch 34/59] [D loss: 0.692595] [G loss: 0.677776]\n",
            "[Epoch 4/50] [Batch 35/59] [D loss: 0.693055] [G loss: 0.679581]\n",
            "[Epoch 4/50] [Batch 36/59] [D loss: 0.693025] [G loss: 0.680979]\n",
            "[Epoch 4/50] [Batch 37/59] [D loss: 0.692686] [G loss: 0.683464]\n",
            "[Epoch 4/50] [Batch 38/59] [D loss: 0.693314] [G loss: 0.683876]\n",
            "[Epoch 4/50] [Batch 39/59] [D loss: 0.693617] [G loss: 0.688022]\n",
            "[Epoch 4/50] [Batch 40/59] [D loss: 0.693361] [G loss: 0.690575]\n",
            "[Epoch 4/50] [Batch 41/59] [D loss: 0.692763] [G loss: 0.693782]\n",
            "[Epoch 4/50] [Batch 42/59] [D loss: 0.692058] [G loss: 0.696161]\n",
            "[Epoch 4/50] [Batch 43/59] [D loss: 0.692948] [G loss: 0.697705]\n",
            "[Epoch 4/50] [Batch 44/59] [D loss: 0.692733] [G loss: 0.699741]\n",
            "[Epoch 4/50] [Batch 45/59] [D loss: 0.692107] [G loss: 0.701399]\n",
            "[Epoch 4/50] [Batch 46/59] [D loss: 0.693190] [G loss: 0.702908]\n",
            "[Epoch 4/50] [Batch 47/59] [D loss: 0.693221] [G loss: 0.703689]\n",
            "[Epoch 4/50] [Batch 48/59] [D loss: 0.693330] [G loss: 0.704985]\n",
            "[Epoch 4/50] [Batch 49/59] [D loss: 0.693257] [G loss: 0.706154]\n",
            "[Epoch 4/50] [Batch 50/59] [D loss: 0.693784] [G loss: 0.706942]\n",
            "[Epoch 4/50] [Batch 51/59] [D loss: 0.693748] [G loss: 0.708840]\n",
            "[Epoch 4/50] [Batch 52/59] [D loss: 0.693545] [G loss: 0.710248]\n",
            "[Epoch 4/50] [Batch 53/59] [D loss: 0.693339] [G loss: 0.710517]\n",
            "[Epoch 4/50] [Batch 54/59] [D loss: 0.692896] [G loss: 0.711168]\n",
            "[Epoch 4/50] [Batch 55/59] [D loss: 0.692847] [G loss: 0.710655]\n",
            "[Epoch 4/50] [Batch 56/59] [D loss: 0.693626] [G loss: 0.710596]\n",
            "[Epoch 4/50] [Batch 57/59] [D loss: 0.693276] [G loss: 0.709546]\n",
            "[Epoch 4/50] [Batch 58/59] [D loss: 0.692370] [G loss: 0.708343]\n",
            "[Epoch 5/50] [Batch 0/59] [D loss: 0.692979] [G loss: 0.708444]\n",
            "[Epoch 5/50] [Batch 1/59] [D loss: 0.693297] [G loss: 0.706416]\n",
            "[Epoch 5/50] [Batch 2/59] [D loss: 0.692840] [G loss: 0.705413]\n",
            "[Epoch 5/50] [Batch 3/59] [D loss: 0.692709] [G loss: 0.704021]\n",
            "[Epoch 5/50] [Batch 4/59] [D loss: 0.693032] [G loss: 0.702430]\n",
            "[Epoch 5/50] [Batch 5/59] [D loss: 0.693099] [G loss: 0.700013]\n",
            "[Epoch 5/50] [Batch 6/59] [D loss: 0.693259] [G loss: 0.698231]\n",
            "[Epoch 5/50] [Batch 7/59] [D loss: 0.693347] [G loss: 0.696818]\n",
            "[Epoch 5/50] [Batch 8/59] [D loss: 0.693561] [G loss: 0.694379]\n",
            "[Epoch 5/50] [Batch 9/59] [D loss: 0.693323] [G loss: 0.693125]\n",
            "[Epoch 5/50] [Batch 10/59] [D loss: 0.693080] [G loss: 0.690837]\n",
            "[Epoch 5/50] [Batch 11/59] [D loss: 0.692862] [G loss: 0.689711]\n",
            "[Epoch 5/50] [Batch 12/59] [D loss: 0.692570] [G loss: 0.687576]\n",
            "[Epoch 5/50] [Batch 13/59] [D loss: 0.692032] [G loss: 0.686380]\n",
            "[Epoch 5/50] [Batch 14/59] [D loss: 0.692788] [G loss: 0.684424]\n",
            "[Epoch 5/50] [Batch 15/59] [D loss: 0.691244] [G loss: 0.683293]\n",
            "[Epoch 5/50] [Batch 16/59] [D loss: 0.691293] [G loss: 0.682076]\n",
            "[Epoch 5/50] [Batch 17/59] [D loss: 0.691592] [G loss: 0.679778]\n",
            "[Epoch 5/50] [Batch 18/59] [D loss: 0.692028] [G loss: 0.678105]\n",
            "[Epoch 5/50] [Batch 19/59] [D loss: 0.691996] [G loss: 0.676676]\n",
            "[Epoch 5/50] [Batch 20/59] [D loss: 0.693511] [G loss: 0.674733]\n",
            "[Epoch 5/50] [Batch 21/59] [D loss: 0.692780] [G loss: 0.673990]\n",
            "[Epoch 5/50] [Batch 22/59] [D loss: 0.694015] [G loss: 0.673567]\n",
            "[Epoch 5/50] [Batch 23/59] [D loss: 0.694721] [G loss: 0.673763]\n",
            "[Epoch 5/50] [Batch 24/59] [D loss: 0.695786] [G loss: 0.674583]\n",
            "[Epoch 5/50] [Batch 25/59] [D loss: 0.694895] [G loss: 0.676613]\n",
            "[Epoch 5/50] [Batch 26/59] [D loss: 0.695201] [G loss: 0.679192]\n",
            "[Epoch 5/50] [Batch 27/59] [D loss: 0.694869] [G loss: 0.682724]\n",
            "[Epoch 5/50] [Batch 28/59] [D loss: 0.694633] [G loss: 0.685181]\n",
            "[Epoch 5/50] [Batch 29/59] [D loss: 0.696000] [G loss: 0.687246]\n",
            "[Epoch 5/50] [Batch 30/59] [D loss: 0.695250] [G loss: 0.690420]\n",
            "[Epoch 5/50] [Batch 31/59] [D loss: 0.694508] [G loss: 0.692895]\n",
            "[Epoch 5/50] [Batch 32/59] [D loss: 0.694558] [G loss: 0.695432]\n",
            "[Epoch 5/50] [Batch 33/59] [D loss: 0.694750] [G loss: 0.697235]\n",
            "[Epoch 5/50] [Batch 34/59] [D loss: 0.694425] [G loss: 0.700041]\n",
            "[Epoch 5/50] [Batch 35/59] [D loss: 0.693836] [G loss: 0.701401]\n",
            "[Epoch 5/50] [Batch 36/59] [D loss: 0.693556] [G loss: 0.703334]\n",
            "[Epoch 5/50] [Batch 37/59] [D loss: 0.693140] [G loss: 0.704513]\n",
            "[Epoch 5/50] [Batch 38/59] [D loss: 0.693164] [G loss: 0.706077]\n",
            "[Epoch 5/50] [Batch 39/59] [D loss: 0.692885] [G loss: 0.707057]\n",
            "[Epoch 5/50] [Batch 40/59] [D loss: 0.692532] [G loss: 0.708172]\n",
            "[Epoch 5/50] [Batch 41/59] [D loss: 0.692627] [G loss: 0.708805]\n",
            "[Epoch 5/50] [Batch 42/59] [D loss: 0.691878] [G loss: 0.710719]\n",
            "[Epoch 5/50] [Batch 43/59] [D loss: 0.692014] [G loss: 0.710515]\n",
            "[Epoch 5/50] [Batch 44/59] [D loss: 0.692016] [G loss: 0.711645]\n",
            "[Epoch 5/50] [Batch 45/59] [D loss: 0.692177] [G loss: 0.712610]\n",
            "[Epoch 5/50] [Batch 46/59] [D loss: 0.692280] [G loss: 0.712284]\n",
            "[Epoch 5/50] [Batch 47/59] [D loss: 0.692165] [G loss: 0.712906]\n",
            "[Epoch 5/50] [Batch 48/59] [D loss: 0.691859] [G loss: 0.712665]\n",
            "[Epoch 5/50] [Batch 49/59] [D loss: 0.691903] [G loss: 0.712675]\n",
            "[Epoch 5/50] [Batch 50/59] [D loss: 0.692175] [G loss: 0.712017]\n",
            "[Epoch 5/50] [Batch 51/59] [D loss: 0.692120] [G loss: 0.711452]\n",
            "[Epoch 5/50] [Batch 52/59] [D loss: 0.692524] [G loss: 0.711478]\n",
            "[Epoch 5/50] [Batch 53/59] [D loss: 0.692669] [G loss: 0.709714]\n",
            "[Epoch 5/50] [Batch 54/59] [D loss: 0.693373] [G loss: 0.708569]\n",
            "[Epoch 5/50] [Batch 55/59] [D loss: 0.693925] [G loss: 0.707968]\n",
            "[Epoch 5/50] [Batch 56/59] [D loss: 0.694156] [G loss: 0.705519]\n",
            "[Epoch 5/50] [Batch 57/59] [D loss: 0.694236] [G loss: 0.704044]\n",
            "[Epoch 5/50] [Batch 58/59] [D loss: 0.695297] [G loss: 0.701238]\n",
            "[Epoch 6/50] [Batch 0/59] [D loss: 0.695224] [G loss: 0.699318]\n",
            "[Epoch 6/50] [Batch 1/59] [D loss: 0.695454] [G loss: 0.697485]\n",
            "[Epoch 6/50] [Batch 2/59] [D loss: 0.695017] [G loss: 0.696261]\n",
            "[Epoch 6/50] [Batch 3/59] [D loss: 0.695055] [G loss: 0.694267]\n",
            "[Epoch 6/50] [Batch 4/59] [D loss: 0.694261] [G loss: 0.693837]\n",
            "[Epoch 6/50] [Batch 5/59] [D loss: 0.694256] [G loss: 0.693177]\n",
            "[Epoch 6/50] [Batch 6/59] [D loss: 0.693702] [G loss: 0.691724]\n",
            "[Epoch 6/50] [Batch 7/59] [D loss: 0.693802] [G loss: 0.691108]\n",
            "[Epoch 6/50] [Batch 8/59] [D loss: 0.693227] [G loss: 0.690111]\n",
            "[Epoch 6/50] [Batch 9/59] [D loss: 0.692610] [G loss: 0.689901]\n",
            "[Epoch 6/50] [Batch 10/59] [D loss: 0.691592] [G loss: 0.689039]\n",
            "[Epoch 6/50] [Batch 11/59] [D loss: 0.691583] [G loss: 0.687857]\n",
            "[Epoch 6/50] [Batch 12/59] [D loss: 0.690981] [G loss: 0.687393]\n",
            "[Epoch 6/50] [Batch 13/59] [D loss: 0.691270] [G loss: 0.686554]\n",
            "[Epoch 6/50] [Batch 14/59] [D loss: 0.690617] [G loss: 0.685409]\n",
            "[Epoch 6/50] [Batch 15/59] [D loss: 0.689817] [G loss: 0.683550]\n",
            "[Epoch 6/50] [Batch 16/59] [D loss: 0.689283] [G loss: 0.682933]\n",
            "[Epoch 6/50] [Batch 17/59] [D loss: 0.688639] [G loss: 0.681028]\n",
            "[Epoch 6/50] [Batch 18/59] [D loss: 0.688890] [G loss: 0.677672]\n",
            "[Epoch 6/50] [Batch 19/59] [D loss: 0.688236] [G loss: 0.675931]\n",
            "[Epoch 6/50] [Batch 20/59] [D loss: 0.689076] [G loss: 0.672639]\n",
            "[Epoch 6/50] [Batch 21/59] [D loss: 0.689771] [G loss: 0.669453]\n",
            "[Epoch 6/50] [Batch 22/59] [D loss: 0.690492] [G loss: 0.665559]\n",
            "[Epoch 6/50] [Batch 23/59] [D loss: 0.692550] [G loss: 0.663442]\n",
            "[Epoch 6/50] [Batch 24/59] [D loss: 0.694097] [G loss: 0.662142]\n",
            "[Epoch 6/50] [Batch 25/59] [D loss: 0.696029] [G loss: 0.660122]\n",
            "[Epoch 6/50] [Batch 26/59] [D loss: 0.695799] [G loss: 0.664829]\n",
            "[Epoch 6/50] [Batch 27/59] [D loss: 0.696663] [G loss: 0.668988]\n",
            "[Epoch 6/50] [Batch 28/59] [D loss: 0.696550] [G loss: 0.673090]\n",
            "[Epoch 6/50] [Batch 29/59] [D loss: 0.697646] [G loss: 0.676976]\n",
            "[Epoch 6/50] [Batch 30/59] [D loss: 0.696980] [G loss: 0.682736]\n",
            "[Epoch 6/50] [Batch 31/59] [D loss: 0.697186] [G loss: 0.687920]\n",
            "[Epoch 6/50] [Batch 32/59] [D loss: 0.696439] [G loss: 0.692278]\n",
            "[Epoch 6/50] [Batch 33/59] [D loss: 0.695698] [G loss: 0.696350]\n",
            "[Epoch 6/50] [Batch 34/59] [D loss: 0.695334] [G loss: 0.699941]\n",
            "[Epoch 6/50] [Batch 35/59] [D loss: 0.695238] [G loss: 0.702356]\n",
            "[Epoch 6/50] [Batch 36/59] [D loss: 0.694901] [G loss: 0.704714]\n",
            "[Epoch 6/50] [Batch 37/59] [D loss: 0.694233] [G loss: 0.707254]\n",
            "[Epoch 6/50] [Batch 38/59] [D loss: 0.693891] [G loss: 0.709016]\n",
            "[Epoch 6/50] [Batch 39/59] [D loss: 0.693538] [G loss: 0.710018]\n",
            "[Epoch 6/50] [Batch 40/59] [D loss: 0.693181] [G loss: 0.711812]\n",
            "[Epoch 6/50] [Batch 41/59] [D loss: 0.693437] [G loss: 0.712547]\n",
            "[Epoch 6/50] [Batch 42/59] [D loss: 0.692392] [G loss: 0.713110]\n",
            "[Epoch 6/50] [Batch 43/59] [D loss: 0.691820] [G loss: 0.714713]\n",
            "[Epoch 6/50] [Batch 44/59] [D loss: 0.691067] [G loss: 0.715413]\n",
            "[Epoch 6/50] [Batch 45/59] [D loss: 0.691682] [G loss: 0.715660]\n",
            "[Epoch 6/50] [Batch 46/59] [D loss: 0.691156] [G loss: 0.716986]\n",
            "[Epoch 6/50] [Batch 47/59] [D loss: 0.690771] [G loss: 0.717426]\n",
            "[Epoch 6/50] [Batch 48/59] [D loss: 0.690717] [G loss: 0.718422]\n",
            "[Epoch 6/50] [Batch 49/59] [D loss: 0.690324] [G loss: 0.719408]\n",
            "[Epoch 6/50] [Batch 50/59] [D loss: 0.690294] [G loss: 0.718963]\n",
            "[Epoch 6/50] [Batch 51/59] [D loss: 0.691177] [G loss: 0.719521]\n",
            "[Epoch 6/50] [Batch 52/59] [D loss: 0.690881] [G loss: 0.718362]\n",
            "[Epoch 6/50] [Batch 53/59] [D loss: 0.691677] [G loss: 0.717227]\n",
            "[Epoch 6/50] [Batch 54/59] [D loss: 0.692692] [G loss: 0.715793]\n",
            "[Epoch 6/50] [Batch 55/59] [D loss: 0.693532] [G loss: 0.711172]\n",
            "[Epoch 6/50] [Batch 56/59] [D loss: 0.694586] [G loss: 0.708368]\n",
            "[Epoch 6/50] [Batch 57/59] [D loss: 0.694909] [G loss: 0.705111]\n",
            "[Epoch 6/50] [Batch 58/59] [D loss: 0.695135] [G loss: 0.700515]\n",
            "[Epoch 7/50] [Batch 0/59] [D loss: 0.696120] [G loss: 0.697278]\n",
            "[Epoch 7/50] [Batch 1/59] [D loss: 0.696489] [G loss: 0.693621]\n",
            "[Epoch 7/50] [Batch 2/59] [D loss: 0.696155] [G loss: 0.690588]\n",
            "[Epoch 7/50] [Batch 3/59] [D loss: 0.695340] [G loss: 0.688980]\n",
            "[Epoch 7/50] [Batch 4/59] [D loss: 0.694965] [G loss: 0.686938]\n",
            "[Epoch 7/50] [Batch 5/59] [D loss: 0.694919] [G loss: 0.685575]\n",
            "[Epoch 7/50] [Batch 6/59] [D loss: 0.694349] [G loss: 0.684802]\n",
            "[Epoch 7/50] [Batch 7/59] [D loss: 0.693219] [G loss: 0.684795]\n",
            "[Epoch 7/50] [Batch 8/59] [D loss: 0.693061] [G loss: 0.683102]\n",
            "[Epoch 7/50] [Batch 9/59] [D loss: 0.692453] [G loss: 0.681515]\n",
            "[Epoch 7/50] [Batch 10/59] [D loss: 0.691763] [G loss: 0.681781]\n",
            "[Epoch 7/50] [Batch 11/59] [D loss: 0.692232] [G loss: 0.679769]\n",
            "[Epoch 7/50] [Batch 12/59] [D loss: 0.691109] [G loss: 0.678014]\n",
            "[Epoch 7/50] [Batch 13/59] [D loss: 0.691432] [G loss: 0.677004]\n",
            "[Epoch 7/50] [Batch 14/59] [D loss: 0.690515] [G loss: 0.676799]\n",
            "[Epoch 7/50] [Batch 15/59] [D loss: 0.689788] [G loss: 0.674573]\n",
            "[Epoch 7/50] [Batch 16/59] [D loss: 0.690261] [G loss: 0.672902]\n",
            "[Epoch 7/50] [Batch 17/59] [D loss: 0.690920] [G loss: 0.671403]\n",
            "[Epoch 7/50] [Batch 18/59] [D loss: 0.690529] [G loss: 0.670263]\n",
            "[Epoch 7/50] [Batch 19/59] [D loss: 0.690435] [G loss: 0.669240]\n",
            "[Epoch 7/50] [Batch 20/59] [D loss: 0.691921] [G loss: 0.668586]\n",
            "[Epoch 7/50] [Batch 21/59] [D loss: 0.691324] [G loss: 0.668944]\n",
            "[Epoch 7/50] [Batch 22/59] [D loss: 0.691950] [G loss: 0.667955]\n",
            "[Epoch 7/50] [Batch 23/59] [D loss: 0.692273] [G loss: 0.669923]\n",
            "[Epoch 7/50] [Batch 24/59] [D loss: 0.693802] [G loss: 0.671812]\n",
            "[Epoch 7/50] [Batch 25/59] [D loss: 0.692811] [G loss: 0.674393]\n",
            "[Epoch 7/50] [Batch 26/59] [D loss: 0.694263] [G loss: 0.676884]\n",
            "[Epoch 7/50] [Batch 27/59] [D loss: 0.694731] [G loss: 0.680534]\n",
            "[Epoch 7/50] [Batch 28/59] [D loss: 0.694459] [G loss: 0.684576]\n",
            "[Epoch 7/50] [Batch 29/59] [D loss: 0.694097] [G loss: 0.687477]\n",
            "[Epoch 7/50] [Batch 30/59] [D loss: 0.694375] [G loss: 0.690250]\n",
            "[Epoch 7/50] [Batch 31/59] [D loss: 0.694582] [G loss: 0.693340]\n",
            "[Epoch 7/50] [Batch 32/59] [D loss: 0.694311] [G loss: 0.696393]\n",
            "[Epoch 7/50] [Batch 33/59] [D loss: 0.694232] [G loss: 0.698433]\n",
            "[Epoch 7/50] [Batch 34/59] [D loss: 0.694474] [G loss: 0.701086]\n",
            "[Epoch 7/50] [Batch 35/59] [D loss: 0.694546] [G loss: 0.703000]\n",
            "[Epoch 7/50] [Batch 36/59] [D loss: 0.694846] [G loss: 0.704785]\n",
            "[Epoch 7/50] [Batch 37/59] [D loss: 0.694565] [G loss: 0.706526]\n",
            "[Epoch 7/50] [Batch 38/59] [D loss: 0.694480] [G loss: 0.707883]\n",
            "[Epoch 7/50] [Batch 39/59] [D loss: 0.694278] [G loss: 0.708713]\n",
            "[Epoch 7/50] [Batch 40/59] [D loss: 0.695097] [G loss: 0.708872]\n",
            "[Epoch 7/50] [Batch 41/59] [D loss: 0.694356] [G loss: 0.710331]\n",
            "[Epoch 7/50] [Batch 42/59] [D loss: 0.694496] [G loss: 0.710684]\n",
            "[Epoch 7/50] [Batch 43/59] [D loss: 0.694361] [G loss: 0.711391]\n",
            "[Epoch 7/50] [Batch 44/59] [D loss: 0.694397] [G loss: 0.710591]\n",
            "[Epoch 7/50] [Batch 45/59] [D loss: 0.694144] [G loss: 0.711228]\n",
            "[Epoch 7/50] [Batch 46/59] [D loss: 0.694114] [G loss: 0.710277]\n",
            "[Epoch 7/50] [Batch 47/59] [D loss: 0.694058] [G loss: 0.709693]\n",
            "[Epoch 7/50] [Batch 48/59] [D loss: 0.693652] [G loss: 0.709361]\n",
            "[Epoch 7/50] [Batch 49/59] [D loss: 0.694001] [G loss: 0.708186]\n",
            "[Epoch 7/50] [Batch 50/59] [D loss: 0.693420] [G loss: 0.707558]\n",
            "[Epoch 7/50] [Batch 51/59] [D loss: 0.694180] [G loss: 0.706494]\n",
            "[Epoch 7/50] [Batch 52/59] [D loss: 0.693818] [G loss: 0.705858]\n",
            "[Epoch 7/50] [Batch 53/59] [D loss: 0.693411] [G loss: 0.704321]\n",
            "[Epoch 7/50] [Batch 54/59] [D loss: 0.693359] [G loss: 0.703450]\n",
            "[Epoch 7/50] [Batch 55/59] [D loss: 0.693738] [G loss: 0.702344]\n",
            "[Epoch 7/50] [Batch 56/59] [D loss: 0.693351] [G loss: 0.700987]\n",
            "[Epoch 7/50] [Batch 57/59] [D loss: 0.693296] [G loss: 0.699886]\n",
            "[Epoch 7/50] [Batch 58/59] [D loss: 0.693283] [G loss: 0.698304]\n",
            "[Epoch 8/50] [Batch 0/59] [D loss: 0.693063] [G loss: 0.697429]\n",
            "[Epoch 8/50] [Batch 1/59] [D loss: 0.692922] [G loss: 0.696270]\n",
            "[Epoch 8/50] [Batch 2/59] [D loss: 0.692532] [G loss: 0.695395]\n",
            "[Epoch 8/50] [Batch 3/59] [D loss: 0.692323] [G loss: 0.694182]\n",
            "[Epoch 8/50] [Batch 4/59] [D loss: 0.692022] [G loss: 0.693114]\n",
            "[Epoch 8/50] [Batch 5/59] [D loss: 0.691754] [G loss: 0.692124]\n",
            "[Epoch 8/50] [Batch 6/59] [D loss: 0.690997] [G loss: 0.690104]\n",
            "[Epoch 8/50] [Batch 7/59] [D loss: 0.690453] [G loss: 0.688752]\n",
            "[Epoch 8/50] [Batch 8/59] [D loss: 0.690007] [G loss: 0.686799]\n",
            "[Epoch 8/50] [Batch 9/59] [D loss: 0.689178] [G loss: 0.685136]\n",
            "[Epoch 8/50] [Batch 10/59] [D loss: 0.688638] [G loss: 0.683116]\n",
            "[Epoch 8/50] [Batch 11/59] [D loss: 0.688079] [G loss: 0.679986]\n",
            "[Epoch 8/50] [Batch 12/59] [D loss: 0.688208] [G loss: 0.675292]\n",
            "[Epoch 8/50] [Batch 13/59] [D loss: 0.688673] [G loss: 0.671408]\n",
            "[Epoch 8/50] [Batch 14/59] [D loss: 0.690570] [G loss: 0.665020]\n",
            "[Epoch 8/50] [Batch 15/59] [D loss: 0.692068] [G loss: 0.659674]\n",
            "[Epoch 8/50] [Batch 16/59] [D loss: 0.695409] [G loss: 0.656872]\n",
            "[Epoch 8/50] [Batch 17/59] [D loss: 0.696168] [G loss: 0.656270]\n",
            "[Epoch 8/50] [Batch 18/59] [D loss: 0.698362] [G loss: 0.658920]\n",
            "[Epoch 8/50] [Batch 19/59] [D loss: 0.700078] [G loss: 0.662635]\n",
            "[Epoch 8/50] [Batch 20/59] [D loss: 0.700422] [G loss: 0.667318]\n",
            "[Epoch 8/50] [Batch 21/59] [D loss: 0.698824] [G loss: 0.674610]\n",
            "[Epoch 8/50] [Batch 22/59] [D loss: 0.698977] [G loss: 0.681214]\n",
            "[Epoch 8/50] [Batch 23/59] [D loss: 0.697229] [G loss: 0.688504]\n",
            "[Epoch 8/50] [Batch 24/59] [D loss: 0.696675] [G loss: 0.693313]\n",
            "[Epoch 8/50] [Batch 25/59] [D loss: 0.696133] [G loss: 0.696691]\n",
            "[Epoch 8/50] [Batch 26/59] [D loss: 0.695198] [G loss: 0.699890]\n",
            "[Epoch 8/50] [Batch 27/59] [D loss: 0.695043] [G loss: 0.701772]\n",
            "[Epoch 8/50] [Batch 28/59] [D loss: 0.694698] [G loss: 0.703833]\n",
            "[Epoch 8/50] [Batch 29/59] [D loss: 0.694204] [G loss: 0.705824]\n",
            "[Epoch 8/50] [Batch 30/59] [D loss: 0.693500] [G loss: 0.706903]\n",
            "[Epoch 8/50] [Batch 31/59] [D loss: 0.693434] [G loss: 0.707525]\n",
            "[Epoch 8/50] [Batch 32/59] [D loss: 0.693216] [G loss: 0.708849]\n",
            "[Epoch 8/50] [Batch 33/59] [D loss: 0.692993] [G loss: 0.708940]\n",
            "[Epoch 8/50] [Batch 34/59] [D loss: 0.692875] [G loss: 0.709507]\n",
            "[Epoch 8/50] [Batch 35/59] [D loss: 0.692418] [G loss: 0.709341]\n",
            "[Epoch 8/50] [Batch 36/59] [D loss: 0.692397] [G loss: 0.710191]\n",
            "[Epoch 8/50] [Batch 37/59] [D loss: 0.691956] [G loss: 0.710219]\n",
            "[Epoch 8/50] [Batch 38/59] [D loss: 0.692071] [G loss: 0.710258]\n",
            "[Epoch 8/50] [Batch 39/59] [D loss: 0.691339] [G loss: 0.710483]\n",
            "[Epoch 8/50] [Batch 40/59] [D loss: 0.691179] [G loss: 0.710543]\n",
            "[Epoch 8/50] [Batch 41/59] [D loss: 0.691097] [G loss: 0.711144]\n",
            "[Epoch 8/50] [Batch 42/59] [D loss: 0.691348] [G loss: 0.711191]\n",
            "[Epoch 8/50] [Batch 43/59] [D loss: 0.690546] [G loss: 0.710701]\n",
            "[Epoch 8/50] [Batch 44/59] [D loss: 0.691022] [G loss: 0.711601]\n",
            "[Epoch 8/50] [Batch 45/59] [D loss: 0.690052] [G loss: 0.711222]\n",
            "[Epoch 8/50] [Batch 46/59] [D loss: 0.690097] [G loss: 0.711895]\n",
            "[Epoch 8/50] [Batch 47/59] [D loss: 0.690372] [G loss: 0.711328]\n",
            "[Epoch 8/50] [Batch 48/59] [D loss: 0.689819] [G loss: 0.710846]\n",
            "[Epoch 8/50] [Batch 49/59] [D loss: 0.690063] [G loss: 0.712215]\n",
            "[Epoch 8/50] [Batch 50/59] [D loss: 0.690360] [G loss: 0.711062]\n",
            "[Epoch 8/50] [Batch 51/59] [D loss: 0.690164] [G loss: 0.710829]\n",
            "[Epoch 8/50] [Batch 52/59] [D loss: 0.690313] [G loss: 0.710539]\n",
            "[Epoch 8/50] [Batch 53/59] [D loss: 0.690903] [G loss: 0.708707]\n",
            "[Epoch 8/50] [Batch 54/59] [D loss: 0.689856] [G loss: 0.709070]\n",
            "[Epoch 8/50] [Batch 55/59] [D loss: 0.690813] [G loss: 0.708239]\n",
            "[Epoch 8/50] [Batch 56/59] [D loss: 0.691507] [G loss: 0.705771]\n",
            "[Epoch 8/50] [Batch 57/59] [D loss: 0.692544] [G loss: 0.703049]\n",
            "[Epoch 8/50] [Batch 58/59] [D loss: 0.693369] [G loss: 0.700034]\n",
            "[Epoch 9/50] [Batch 0/59] [D loss: 0.694101] [G loss: 0.697067]\n",
            "[Epoch 9/50] [Batch 1/59] [D loss: 0.695270] [G loss: 0.693538]\n",
            "[Epoch 9/50] [Batch 2/59] [D loss: 0.694814] [G loss: 0.690499]\n",
            "[Epoch 9/50] [Batch 3/59] [D loss: 0.695576] [G loss: 0.687352]\n",
            "[Epoch 9/50] [Batch 4/59] [D loss: 0.695488] [G loss: 0.685050]\n",
            "[Epoch 9/50] [Batch 5/59] [D loss: 0.695839] [G loss: 0.682116]\n",
            "[Epoch 9/50] [Batch 6/59] [D loss: 0.695821] [G loss: 0.680987]\n",
            "[Epoch 9/50] [Batch 7/59] [D loss: 0.695721] [G loss: 0.679730]\n",
            "[Epoch 9/50] [Batch 8/59] [D loss: 0.695055] [G loss: 0.678561]\n",
            "[Epoch 9/50] [Batch 9/59] [D loss: 0.694749] [G loss: 0.677773]\n",
            "[Epoch 9/50] [Batch 10/59] [D loss: 0.694944] [G loss: 0.677125]\n",
            "[Epoch 9/50] [Batch 11/59] [D loss: 0.694311] [G loss: 0.678062]\n",
            "[Epoch 9/50] [Batch 12/59] [D loss: 0.694509] [G loss: 0.677598]\n",
            "[Epoch 9/50] [Batch 13/59] [D loss: 0.694580] [G loss: 0.677077]\n",
            "[Epoch 9/50] [Batch 14/59] [D loss: 0.694075] [G loss: 0.677835]\n",
            "[Epoch 9/50] [Batch 15/59] [D loss: 0.694145] [G loss: 0.677545]\n",
            "[Epoch 9/50] [Batch 16/59] [D loss: 0.694205] [G loss: 0.678021]\n",
            "[Epoch 9/50] [Batch 17/59] [D loss: 0.693985] [G loss: 0.678336]\n",
            "[Epoch 9/50] [Batch 18/59] [D loss: 0.693560] [G loss: 0.679688]\n",
            "[Epoch 9/50] [Batch 19/59] [D loss: 0.693132] [G loss: 0.680882]\n",
            "[Epoch 9/50] [Batch 20/59] [D loss: 0.693482] [G loss: 0.680278]\n",
            "[Epoch 9/50] [Batch 21/59] [D loss: 0.693125] [G loss: 0.682387]\n",
            "[Epoch 9/50] [Batch 22/59] [D loss: 0.692523] [G loss: 0.682185]\n",
            "[Epoch 9/50] [Batch 23/59] [D loss: 0.692655] [G loss: 0.683144]\n",
            "[Epoch 9/50] [Batch 24/59] [D loss: 0.692546] [G loss: 0.683401]\n",
            "[Epoch 9/50] [Batch 25/59] [D loss: 0.692535] [G loss: 0.684146]\n",
            "[Epoch 9/50] [Batch 26/59] [D loss: 0.692342] [G loss: 0.685350]\n",
            "[Epoch 9/50] [Batch 27/59] [D loss: 0.692087] [G loss: 0.686331]\n",
            "[Epoch 9/50] [Batch 28/59] [D loss: 0.692184] [G loss: 0.686615]\n",
            "[Epoch 9/50] [Batch 29/59] [D loss: 0.691758] [G loss: 0.688040]\n",
            "[Epoch 9/50] [Batch 30/59] [D loss: 0.692249] [G loss: 0.689243]\n",
            "[Epoch 9/50] [Batch 31/59] [D loss: 0.691766] [G loss: 0.689595]\n",
            "[Epoch 9/50] [Batch 32/59] [D loss: 0.692452] [G loss: 0.689476]\n",
            "[Epoch 9/50] [Batch 33/59] [D loss: 0.692411] [G loss: 0.691060]\n",
            "[Epoch 9/50] [Batch 34/59] [D loss: 0.692834] [G loss: 0.691170]\n",
            "[Epoch 9/50] [Batch 35/59] [D loss: 0.693182] [G loss: 0.692581]\n",
            "[Epoch 9/50] [Batch 36/59] [D loss: 0.693385] [G loss: 0.694411]\n",
            "[Epoch 9/50] [Batch 37/59] [D loss: 0.693739] [G loss: 0.695299]\n",
            "[Epoch 9/50] [Batch 38/59] [D loss: 0.693529] [G loss: 0.697264]\n",
            "[Epoch 9/50] [Batch 39/59] [D loss: 0.693930] [G loss: 0.698504]\n",
            "[Epoch 9/50] [Batch 40/59] [D loss: 0.693135] [G loss: 0.702029]\n",
            "[Epoch 9/50] [Batch 41/59] [D loss: 0.692791] [G loss: 0.704320]\n",
            "[Epoch 9/50] [Batch 42/59] [D loss: 0.692683] [G loss: 0.707129]\n",
            "[Epoch 9/50] [Batch 43/59] [D loss: 0.692487] [G loss: 0.708026]\n",
            "[Epoch 9/50] [Batch 44/59] [D loss: 0.691985] [G loss: 0.710041]\n",
            "[Epoch 9/50] [Batch 45/59] [D loss: 0.691320] [G loss: 0.711430]\n",
            "[Epoch 9/50] [Batch 46/59] [D loss: 0.691994] [G loss: 0.712980]\n",
            "[Epoch 9/50] [Batch 47/59] [D loss: 0.690711] [G loss: 0.714662]\n",
            "[Epoch 9/50] [Batch 48/59] [D loss: 0.691007] [G loss: 0.714914]\n",
            "[Epoch 9/50] [Batch 49/59] [D loss: 0.690872] [G loss: 0.716506]\n",
            "[Epoch 9/50] [Batch 50/59] [D loss: 0.691303] [G loss: 0.715322]\n",
            "[Epoch 9/50] [Batch 51/59] [D loss: 0.691059] [G loss: 0.713978]\n",
            "[Epoch 9/50] [Batch 52/59] [D loss: 0.692533] [G loss: 0.712545]\n",
            "[Epoch 9/50] [Batch 53/59] [D loss: 0.694169] [G loss: 0.708900]\n",
            "[Epoch 9/50] [Batch 54/59] [D loss: 0.694313] [G loss: 0.704874]\n",
            "[Epoch 9/50] [Batch 55/59] [D loss: 0.695415] [G loss: 0.700704]\n",
            "[Epoch 9/50] [Batch 56/59] [D loss: 0.696523] [G loss: 0.695767]\n",
            "[Epoch 9/50] [Batch 57/59] [D loss: 0.697577] [G loss: 0.691591]\n",
            "[Epoch 9/50] [Batch 58/59] [D loss: 0.697411] [G loss: 0.688252]\n",
            "[Epoch 10/50] [Batch 0/59] [D loss: 0.696951] [G loss: 0.686706]\n",
            "[Epoch 10/50] [Batch 1/59] [D loss: 0.695884] [G loss: 0.686039]\n",
            "[Epoch 10/50] [Batch 2/59] [D loss: 0.695058] [G loss: 0.685409]\n",
            "[Epoch 10/50] [Batch 3/59] [D loss: 0.693733] [G loss: 0.684673]\n",
            "[Epoch 10/50] [Batch 4/59] [D loss: 0.692450] [G loss: 0.684832]\n",
            "[Epoch 10/50] [Batch 5/59] [D loss: 0.691007] [G loss: 0.684392]\n",
            "[Epoch 10/50] [Batch 6/59] [D loss: 0.689982] [G loss: 0.684203]\n",
            "[Epoch 10/50] [Batch 7/59] [D loss: 0.688548] [G loss: 0.682470]\n",
            "[Epoch 10/50] [Batch 8/59] [D loss: 0.687242] [G loss: 0.681016]\n",
            "[Epoch 10/50] [Batch 9/59] [D loss: 0.686275] [G loss: 0.677664]\n",
            "[Epoch 10/50] [Batch 10/59] [D loss: 0.685044] [G loss: 0.674119]\n",
            "[Epoch 10/50] [Batch 11/59] [D loss: 0.685169] [G loss: 0.667154]\n",
            "[Epoch 10/50] [Batch 12/59] [D loss: 0.687243] [G loss: 0.659181]\n",
            "[Epoch 10/50] [Batch 13/59] [D loss: 0.690439] [G loss: 0.649786]\n",
            "[Epoch 10/50] [Batch 14/59] [D loss: 0.692663] [G loss: 0.643252]\n",
            "[Epoch 10/50] [Batch 15/59] [D loss: 0.696403] [G loss: 0.639827]\n",
            "[Epoch 10/50] [Batch 16/59] [D loss: 0.698805] [G loss: 0.641037]\n",
            "[Epoch 10/50] [Batch 17/59] [D loss: 0.699627] [G loss: 0.648906]\n",
            "[Epoch 10/50] [Batch 18/59] [D loss: 0.699257] [G loss: 0.658392]\n",
            "[Epoch 10/50] [Batch 19/59] [D loss: 0.700002] [G loss: 0.666110]\n",
            "[Epoch 10/50] [Batch 20/59] [D loss: 0.699328] [G loss: 0.675922]\n",
            "[Epoch 10/50] [Batch 21/59] [D loss: 0.699055] [G loss: 0.682946]\n",
            "[Epoch 10/50] [Batch 22/59] [D loss: 0.698200] [G loss: 0.690470]\n",
            "[Epoch 10/50] [Batch 23/59] [D loss: 0.697314] [G loss: 0.696052]\n",
            "[Epoch 10/50] [Batch 24/59] [D loss: 0.696438] [G loss: 0.699399]\n",
            "[Epoch 10/50] [Batch 25/59] [D loss: 0.695683] [G loss: 0.702921]\n",
            "[Epoch 10/50] [Batch 26/59] [D loss: 0.695603] [G loss: 0.705158]\n",
            "[Epoch 10/50] [Batch 27/59] [D loss: 0.694963] [G loss: 0.707093]\n",
            "[Epoch 10/50] [Batch 28/59] [D loss: 0.694547] [G loss: 0.708681]\n",
            "[Epoch 10/50] [Batch 29/59] [D loss: 0.694346] [G loss: 0.709803]\n",
            "[Epoch 10/50] [Batch 30/59] [D loss: 0.693966] [G loss: 0.710727]\n",
            "[Epoch 10/50] [Batch 31/59] [D loss: 0.693559] [G loss: 0.710908]\n",
            "[Epoch 10/50] [Batch 32/59] [D loss: 0.693331] [G loss: 0.711391]\n",
            "[Epoch 10/50] [Batch 33/59] [D loss: 0.693209] [G loss: 0.711906]\n",
            "[Epoch 10/50] [Batch 34/59] [D loss: 0.692834] [G loss: 0.712654]\n",
            "[Epoch 10/50] [Batch 35/59] [D loss: 0.692464] [G loss: 0.712623]\n",
            "[Epoch 10/50] [Batch 36/59] [D loss: 0.692408] [G loss: 0.712676]\n",
            "[Epoch 10/50] [Batch 37/59] [D loss: 0.692244] [G loss: 0.713239]\n",
            "[Epoch 10/50] [Batch 38/59] [D loss: 0.692119] [G loss: 0.713195]\n",
            "[Epoch 10/50] [Batch 39/59] [D loss: 0.691879] [G loss: 0.713344]\n",
            "[Epoch 10/50] [Batch 40/59] [D loss: 0.691601] [G loss: 0.713436]\n",
            "[Epoch 10/50] [Batch 41/59] [D loss: 0.691401] [G loss: 0.714012]\n",
            "[Epoch 10/50] [Batch 42/59] [D loss: 0.691265] [G loss: 0.714602]\n",
            "[Epoch 10/50] [Batch 43/59] [D loss: 0.691097] [G loss: 0.714216]\n",
            "[Epoch 10/50] [Batch 44/59] [D loss: 0.690649] [G loss: 0.715593]\n",
            "[Epoch 10/50] [Batch 45/59] [D loss: 0.690400] [G loss: 0.716084]\n",
            "[Epoch 10/50] [Batch 46/59] [D loss: 0.690166] [G loss: 0.717165]\n",
            "[Epoch 10/50] [Batch 47/59] [D loss: 0.689968] [G loss: 0.717545]\n",
            "[Epoch 10/50] [Batch 48/59] [D loss: 0.689569] [G loss: 0.719507]\n",
            "[Epoch 10/50] [Batch 49/59] [D loss: 0.689405] [G loss: 0.720967]\n",
            "[Epoch 10/50] [Batch 50/59] [D loss: 0.689306] [G loss: 0.722163]\n",
            "[Epoch 10/50] [Batch 51/59] [D loss: 0.689003] [G loss: 0.722831]\n",
            "[Epoch 10/50] [Batch 52/59] [D loss: 0.687869] [G loss: 0.724978]\n",
            "[Epoch 10/50] [Batch 53/59] [D loss: 0.688300] [G loss: 0.727210]\n",
            "[Epoch 10/50] [Batch 54/59] [D loss: 0.688082] [G loss: 0.727218]\n",
            "[Epoch 10/50] [Batch 55/59] [D loss: 0.687566] [G loss: 0.729725]\n",
            "[Epoch 10/50] [Batch 56/59] [D loss: 0.688605] [G loss: 0.730016]\n",
            "[Epoch 10/50] [Batch 57/59] [D loss: 0.687642] [G loss: 0.729773]\n",
            "[Epoch 10/50] [Batch 58/59] [D loss: 0.687099] [G loss: 0.727866]\n",
            "[Epoch 11/50] [Batch 0/59] [D loss: 0.689053] [G loss: 0.725376]\n",
            "[Epoch 11/50] [Batch 1/59] [D loss: 0.690525] [G loss: 0.722160]\n",
            "[Epoch 11/50] [Batch 2/59] [D loss: 0.690234] [G loss: 0.715313]\n",
            "[Epoch 11/50] [Batch 3/59] [D loss: 0.693202] [G loss: 0.708201]\n",
            "[Epoch 11/50] [Batch 4/59] [D loss: 0.695185] [G loss: 0.697480]\n",
            "[Epoch 11/50] [Batch 5/59] [D loss: 0.695884] [G loss: 0.689774]\n",
            "[Epoch 11/50] [Batch 6/59] [D loss: 0.697892] [G loss: 0.680516]\n",
            "[Epoch 11/50] [Batch 7/59] [D loss: 0.697534] [G loss: 0.673942]\n",
            "[Epoch 11/50] [Batch 8/59] [D loss: 0.697455] [G loss: 0.670215]\n",
            "[Epoch 11/50] [Batch 9/59] [D loss: 0.696827] [G loss: 0.667884]\n",
            "[Epoch 11/50] [Batch 10/59] [D loss: 0.695747] [G loss: 0.667359]\n",
            "[Epoch 11/50] [Batch 11/59] [D loss: 0.694307] [G loss: 0.667169]\n",
            "[Epoch 11/50] [Batch 12/59] [D loss: 0.694264] [G loss: 0.667450]\n",
            "[Epoch 11/50] [Batch 13/59] [D loss: 0.692817] [G loss: 0.667963]\n",
            "[Epoch 11/50] [Batch 14/59] [D loss: 0.692136] [G loss: 0.668777]\n",
            "[Epoch 11/50] [Batch 15/59] [D loss: 0.691588] [G loss: 0.668597]\n",
            "[Epoch 11/50] [Batch 16/59] [D loss: 0.690033] [G loss: 0.668326]\n",
            "[Epoch 11/50] [Batch 17/59] [D loss: 0.689637] [G loss: 0.668182]\n",
            "[Epoch 11/50] [Batch 18/59] [D loss: 0.689151] [G loss: 0.668896]\n",
            "[Epoch 11/50] [Batch 19/59] [D loss: 0.689220] [G loss: 0.667476]\n",
            "[Epoch 11/50] [Batch 20/59] [D loss: 0.688700] [G loss: 0.666377]\n",
            "[Epoch 11/50] [Batch 21/59] [D loss: 0.688111] [G loss: 0.665771]\n",
            "[Epoch 11/50] [Batch 22/59] [D loss: 0.688788] [G loss: 0.665291]\n",
            "[Epoch 11/50] [Batch 23/59] [D loss: 0.688506] [G loss: 0.665069]\n",
            "[Epoch 11/50] [Batch 24/59] [D loss: 0.689433] [G loss: 0.665041]\n",
            "[Epoch 11/50] [Batch 25/59] [D loss: 0.690091] [G loss: 0.665207]\n",
            "[Epoch 11/50] [Batch 26/59] [D loss: 0.691065] [G loss: 0.667352]\n",
            "[Epoch 11/50] [Batch 27/59] [D loss: 0.691606] [G loss: 0.669203]\n",
            "[Epoch 11/50] [Batch 28/59] [D loss: 0.692487] [G loss: 0.670940]\n",
            "[Epoch 11/50] [Batch 29/59] [D loss: 0.693289] [G loss: 0.672605]\n",
            "[Epoch 11/50] [Batch 30/59] [D loss: 0.694631] [G loss: 0.676999]\n",
            "[Epoch 11/50] [Batch 31/59] [D loss: 0.694987] [G loss: 0.680881]\n",
            "[Epoch 11/50] [Batch 32/59] [D loss: 0.696932] [G loss: 0.683295]\n",
            "[Epoch 11/50] [Batch 33/59] [D loss: 0.696397] [G loss: 0.686500]\n",
            "[Epoch 11/50] [Batch 34/59] [D loss: 0.697372] [G loss: 0.688969]\n",
            "[Epoch 11/50] [Batch 35/59] [D loss: 0.697428] [G loss: 0.692343]\n",
            "[Epoch 11/50] [Batch 36/59] [D loss: 0.697630] [G loss: 0.694552]\n",
            "[Epoch 11/50] [Batch 37/59] [D loss: 0.696228] [G loss: 0.699114]\n",
            "[Epoch 11/50] [Batch 38/59] [D loss: 0.696889] [G loss: 0.701267]\n",
            "[Epoch 11/50] [Batch 39/59] [D loss: 0.695431] [G loss: 0.703906]\n",
            "[Epoch 11/50] [Batch 40/59] [D loss: 0.695101] [G loss: 0.706584]\n",
            "[Epoch 11/50] [Batch 41/59] [D loss: 0.694505] [G loss: 0.706752]\n",
            "[Epoch 11/50] [Batch 42/59] [D loss: 0.694137] [G loss: 0.708998]\n",
            "[Epoch 11/50] [Batch 43/59] [D loss: 0.693273] [G loss: 0.711098]\n",
            "[Epoch 11/50] [Batch 44/59] [D loss: 0.692975] [G loss: 0.710990]\n",
            "[Epoch 11/50] [Batch 45/59] [D loss: 0.693061] [G loss: 0.711033]\n",
            "[Epoch 11/50] [Batch 46/59] [D loss: 0.692895] [G loss: 0.711541]\n",
            "[Epoch 11/50] [Batch 47/59] [D loss: 0.693004] [G loss: 0.710163]\n",
            "[Epoch 11/50] [Batch 48/59] [D loss: 0.693243] [G loss: 0.708645]\n",
            "[Epoch 11/50] [Batch 49/59] [D loss: 0.692737] [G loss: 0.707330]\n",
            "[Epoch 11/50] [Batch 50/59] [D loss: 0.693049] [G loss: 0.706355]\n",
            "[Epoch 11/50] [Batch 51/59] [D loss: 0.693441] [G loss: 0.704278]\n",
            "[Epoch 11/50] [Batch 52/59] [D loss: 0.693054] [G loss: 0.702899]\n",
            "[Epoch 11/50] [Batch 53/59] [D loss: 0.693410] [G loss: 0.700209]\n",
            "[Epoch 11/50] [Batch 54/59] [D loss: 0.693152] [G loss: 0.698558]\n",
            "[Epoch 11/50] [Batch 55/59] [D loss: 0.692969] [G loss: 0.697426]\n",
            "[Epoch 11/50] [Batch 56/59] [D loss: 0.692546] [G loss: 0.694839]\n",
            "[Epoch 11/50] [Batch 57/59] [D loss: 0.692605] [G loss: 0.692510]\n",
            "[Epoch 11/50] [Batch 58/59] [D loss: 0.692785] [G loss: 0.691052]\n",
            "[Epoch 12/50] [Batch 0/59] [D loss: 0.691665] [G loss: 0.689573]\n",
            "[Epoch 12/50] [Batch 1/59] [D loss: 0.691960] [G loss: 0.688007]\n",
            "[Epoch 12/50] [Batch 2/59] [D loss: 0.692005] [G loss: 0.687172]\n",
            "[Epoch 12/50] [Batch 3/59] [D loss: 0.691630] [G loss: 0.686569]\n",
            "[Epoch 12/50] [Batch 4/59] [D loss: 0.691497] [G loss: 0.686292]\n",
            "[Epoch 12/50] [Batch 5/59] [D loss: 0.690978] [G loss: 0.685510]\n",
            "[Epoch 12/50] [Batch 6/59] [D loss: 0.691133] [G loss: 0.685546]\n",
            "[Epoch 12/50] [Batch 7/59] [D loss: 0.691236] [G loss: 0.685031]\n",
            "[Epoch 12/50] [Batch 8/59] [D loss: 0.690562] [G loss: 0.685404]\n",
            "[Epoch 12/50] [Batch 9/59] [D loss: 0.689552] [G loss: 0.685199]\n",
            "[Epoch 12/50] [Batch 10/59] [D loss: 0.691356] [G loss: 0.683072]\n",
            "[Epoch 12/50] [Batch 11/59] [D loss: 0.691265] [G loss: 0.683993]\n",
            "[Epoch 12/50] [Batch 12/59] [D loss: 0.692231] [G loss: 0.685272]\n",
            "[Epoch 12/50] [Batch 13/59] [D loss: 0.693212] [G loss: 0.684456]\n",
            "[Epoch 12/50] [Batch 14/59] [D loss: 0.693538] [G loss: 0.685745]\n",
            "[Epoch 12/50] [Batch 15/59] [D loss: 0.695263] [G loss: 0.688150]\n",
            "[Epoch 12/50] [Batch 16/59] [D loss: 0.695505] [G loss: 0.690729]\n",
            "[Epoch 12/50] [Batch 17/59] [D loss: 0.696021] [G loss: 0.693702]\n",
            "[Epoch 12/50] [Batch 18/59] [D loss: 0.695955] [G loss: 0.695543]\n",
            "[Epoch 12/50] [Batch 19/59] [D loss: 0.696324] [G loss: 0.698176]\n",
            "[Epoch 12/50] [Batch 20/59] [D loss: 0.697299] [G loss: 0.699605]\n",
            "[Epoch 12/50] [Batch 21/59] [D loss: 0.696895] [G loss: 0.700793]\n",
            "[Epoch 12/50] [Batch 22/59] [D loss: 0.696152] [G loss: 0.702632]\n",
            "[Epoch 12/50] [Batch 23/59] [D loss: 0.695573] [G loss: 0.704433]\n",
            "[Epoch 12/50] [Batch 24/59] [D loss: 0.696017] [G loss: 0.704236]\n",
            "[Epoch 12/50] [Batch 25/59] [D loss: 0.695044] [G loss: 0.704873]\n",
            "[Epoch 12/50] [Batch 26/59] [D loss: 0.694852] [G loss: 0.704862]\n",
            "[Epoch 12/50] [Batch 27/59] [D loss: 0.694400] [G loss: 0.705114]\n",
            "[Epoch 12/50] [Batch 28/59] [D loss: 0.694264] [G loss: 0.705112]\n",
            "[Epoch 12/50] [Batch 29/59] [D loss: 0.693580] [G loss: 0.705890]\n",
            "[Epoch 12/50] [Batch 30/59] [D loss: 0.692933] [G loss: 0.706520]\n",
            "[Epoch 12/50] [Batch 31/59] [D loss: 0.692628] [G loss: 0.706110]\n",
            "[Epoch 12/50] [Batch 32/59] [D loss: 0.692419] [G loss: 0.705968]\n",
            "[Epoch 12/50] [Batch 33/59] [D loss: 0.691962] [G loss: 0.706303]\n",
            "[Epoch 12/50] [Batch 34/59] [D loss: 0.691517] [G loss: 0.705969]\n",
            "[Epoch 12/50] [Batch 35/59] [D loss: 0.691917] [G loss: 0.705215]\n",
            "[Epoch 12/50] [Batch 36/59] [D loss: 0.691377] [G loss: 0.704671]\n",
            "[Epoch 12/50] [Batch 37/59] [D loss: 0.690549] [G loss: 0.703546]\n",
            "[Epoch 12/50] [Batch 38/59] [D loss: 0.690682] [G loss: 0.702792]\n",
            "[Epoch 12/50] [Batch 39/59] [D loss: 0.690662] [G loss: 0.701711]\n",
            "[Epoch 12/50] [Batch 40/59] [D loss: 0.690341] [G loss: 0.700153]\n",
            "[Epoch 12/50] [Batch 41/59] [D loss: 0.690404] [G loss: 0.695834]\n",
            "[Epoch 12/50] [Batch 42/59] [D loss: 0.690020] [G loss: 0.692693]\n",
            "[Epoch 12/50] [Batch 43/59] [D loss: 0.689883] [G loss: 0.689880]\n",
            "[Epoch 12/50] [Batch 44/59] [D loss: 0.690040] [G loss: 0.685712]\n",
            "[Epoch 12/50] [Batch 45/59] [D loss: 0.690159] [G loss: 0.681894]\n",
            "[Epoch 12/50] [Batch 46/59] [D loss: 0.689638] [G loss: 0.677820]\n",
            "[Epoch 12/50] [Batch 47/59] [D loss: 0.689575] [G loss: 0.674436]\n",
            "[Epoch 12/50] [Batch 48/59] [D loss: 0.690570] [G loss: 0.669787]\n",
            "[Epoch 12/50] [Batch 49/59] [D loss: 0.691934] [G loss: 0.665917]\n",
            "[Epoch 12/50] [Batch 50/59] [D loss: 0.694440] [G loss: 0.661829]\n",
            "[Epoch 12/50] [Batch 51/59] [D loss: 0.695535] [G loss: 0.659742]\n",
            "[Epoch 12/50] [Batch 52/59] [D loss: 0.697192] [G loss: 0.660660]\n",
            "[Epoch 12/50] [Batch 53/59] [D loss: 0.698411] [G loss: 0.664800]\n",
            "[Epoch 12/50] [Batch 54/59] [D loss: 0.699695] [G loss: 0.669287]\n",
            "[Epoch 12/50] [Batch 55/59] [D loss: 0.697625] [G loss: 0.676867]\n",
            "[Epoch 12/50] [Batch 56/59] [D loss: 0.697626] [G loss: 0.682465]\n",
            "[Epoch 12/50] [Batch 57/59] [D loss: 0.697412] [G loss: 0.688191]\n",
            "[Epoch 12/50] [Batch 58/59] [D loss: 0.696038] [G loss: 0.691962]\n",
            "[Epoch 13/50] [Batch 0/59] [D loss: 0.695657] [G loss: 0.696630]\n",
            "[Epoch 13/50] [Batch 1/59] [D loss: 0.695399] [G loss: 0.699481]\n",
            "[Epoch 13/50] [Batch 2/59] [D loss: 0.694307] [G loss: 0.702202]\n",
            "[Epoch 13/50] [Batch 3/59] [D loss: 0.693491] [G loss: 0.704895]\n",
            "[Epoch 13/50] [Batch 4/59] [D loss: 0.693372] [G loss: 0.706654]\n",
            "[Epoch 13/50] [Batch 5/59] [D loss: 0.692764] [G loss: 0.708329]\n",
            "[Epoch 13/50] [Batch 6/59] [D loss: 0.692513] [G loss: 0.709893]\n",
            "[Epoch 13/50] [Batch 7/59] [D loss: 0.691883] [G loss: 0.712255]\n",
            "[Epoch 13/50] [Batch 8/59] [D loss: 0.691801] [G loss: 0.713600]\n",
            "[Epoch 13/50] [Batch 9/59] [D loss: 0.691214] [G loss: 0.716331]\n",
            "[Epoch 13/50] [Batch 10/59] [D loss: 0.691187] [G loss: 0.718251]\n",
            "[Epoch 13/50] [Batch 11/59] [D loss: 0.690774] [G loss: 0.719878]\n",
            "[Epoch 13/50] [Batch 12/59] [D loss: 0.690839] [G loss: 0.721905]\n",
            "[Epoch 13/50] [Batch 13/59] [D loss: 0.691194] [G loss: 0.723721]\n",
            "[Epoch 13/50] [Batch 14/59] [D loss: 0.691761] [G loss: 0.724923]\n",
            "[Epoch 13/50] [Batch 15/59] [D loss: 0.692641] [G loss: 0.723737]\n",
            "[Epoch 13/50] [Batch 16/59] [D loss: 0.693621] [G loss: 0.722683]\n",
            "[Epoch 13/50] [Batch 17/59] [D loss: 0.694354] [G loss: 0.722460]\n",
            "[Epoch 13/50] [Batch 18/59] [D loss: 0.696170] [G loss: 0.718077]\n",
            "[Epoch 13/50] [Batch 19/59] [D loss: 0.696692] [G loss: 0.714153]\n",
            "[Epoch 13/50] [Batch 20/59] [D loss: 0.696972] [G loss: 0.709031]\n",
            "[Epoch 13/50] [Batch 21/59] [D loss: 0.696396] [G loss: 0.704959]\n",
            "[Epoch 13/50] [Batch 22/59] [D loss: 0.696421] [G loss: 0.701631]\n",
            "[Epoch 13/50] [Batch 23/59] [D loss: 0.695764] [G loss: 0.699390]\n",
            "[Epoch 13/50] [Batch 24/59] [D loss: 0.694717] [G loss: 0.696953]\n",
            "[Epoch 13/50] [Batch 25/59] [D loss: 0.694211] [G loss: 0.695604]\n",
            "[Epoch 13/50] [Batch 26/59] [D loss: 0.693594] [G loss: 0.694393]\n",
            "[Epoch 13/50] [Batch 27/59] [D loss: 0.693007] [G loss: 0.694201]\n",
            "[Epoch 13/50] [Batch 28/59] [D loss: 0.692228] [G loss: 0.693300]\n",
            "[Epoch 13/50] [Batch 29/59] [D loss: 0.691860] [G loss: 0.693372]\n",
            "[Epoch 13/50] [Batch 30/59] [D loss: 0.691258] [G loss: 0.693073]\n",
            "[Epoch 13/50] [Batch 31/59] [D loss: 0.691163] [G loss: 0.692235]\n",
            "[Epoch 13/50] [Batch 32/59] [D loss: 0.690440] [G loss: 0.692473]\n",
            "[Epoch 13/50] [Batch 33/59] [D loss: 0.689677] [G loss: 0.692089]\n",
            "[Epoch 13/50] [Batch 34/59] [D loss: 0.689421] [G loss: 0.691363]\n",
            "[Epoch 13/50] [Batch 35/59] [D loss: 0.688861] [G loss: 0.691562]\n",
            "[Epoch 13/50] [Batch 36/59] [D loss: 0.688686] [G loss: 0.690255]\n",
            "[Epoch 13/50] [Batch 37/59] [D loss: 0.688145] [G loss: 0.688554]\n",
            "[Epoch 13/50] [Batch 38/59] [D loss: 0.687392] [G loss: 0.686652]\n",
            "[Epoch 13/50] [Batch 39/59] [D loss: 0.687640] [G loss: 0.684321]\n",
            "[Epoch 13/50] [Batch 40/59] [D loss: 0.687993] [G loss: 0.680594]\n",
            "[Epoch 13/50] [Batch 41/59] [D loss: 0.688563] [G loss: 0.677160]\n",
            "[Epoch 13/50] [Batch 42/59] [D loss: 0.688574] [G loss: 0.673231]\n",
            "[Epoch 13/50] [Batch 43/59] [D loss: 0.688266] [G loss: 0.668547]\n",
            "[Epoch 13/50] [Batch 44/59] [D loss: 0.689300] [G loss: 0.665656]\n",
            "[Epoch 13/50] [Batch 45/59] [D loss: 0.689073] [G loss: 0.662602]\n",
            "[Epoch 13/50] [Batch 46/59] [D loss: 0.689265] [G loss: 0.660386]\n",
            "[Epoch 13/50] [Batch 47/59] [D loss: 0.690112] [G loss: 0.657441]\n",
            "[Epoch 13/50] [Batch 48/59] [D loss: 0.690920] [G loss: 0.657427]\n",
            "[Epoch 13/50] [Batch 49/59] [D loss: 0.692812] [G loss: 0.657657]\n",
            "[Epoch 13/50] [Batch 50/59] [D loss: 0.693267] [G loss: 0.659092]\n",
            "[Epoch 13/50] [Batch 51/59] [D loss: 0.694677] [G loss: 0.662582]\n",
            "[Epoch 13/50] [Batch 52/59] [D loss: 0.696074] [G loss: 0.665335]\n",
            "[Epoch 13/50] [Batch 53/59] [D loss: 0.696088] [G loss: 0.672530]\n",
            "[Epoch 13/50] [Batch 54/59] [D loss: 0.697276] [G loss: 0.678579]\n",
            "[Epoch 13/50] [Batch 55/59] [D loss: 0.697263] [G loss: 0.685438]\n",
            "[Epoch 13/50] [Batch 56/59] [D loss: 0.697939] [G loss: 0.692014]\n",
            "[Epoch 13/50] [Batch 57/59] [D loss: 0.697446] [G loss: 0.698697]\n",
            "[Epoch 13/50] [Batch 58/59] [D loss: 0.697165] [G loss: 0.704274]\n",
            "[Epoch 14/50] [Batch 0/59] [D loss: 0.696621] [G loss: 0.707610]\n",
            "[Epoch 14/50] [Batch 1/59] [D loss: 0.696846] [G loss: 0.710945]\n",
            "[Epoch 14/50] [Batch 2/59] [D loss: 0.695468] [G loss: 0.713464]\n",
            "[Epoch 14/50] [Batch 3/59] [D loss: 0.695325] [G loss: 0.714994]\n",
            "[Epoch 14/50] [Batch 4/59] [D loss: 0.694802] [G loss: 0.716746]\n",
            "[Epoch 14/50] [Batch 5/59] [D loss: 0.694511] [G loss: 0.717594]\n",
            "[Epoch 14/50] [Batch 6/59] [D loss: 0.694616] [G loss: 0.717943]\n",
            "[Epoch 14/50] [Batch 7/59] [D loss: 0.693330] [G loss: 0.719238]\n",
            "[Epoch 14/50] [Batch 8/59] [D loss: 0.692957] [G loss: 0.719793]\n",
            "[Epoch 14/50] [Batch 9/59] [D loss: 0.692933] [G loss: 0.720052]\n",
            "[Epoch 14/50] [Batch 10/59] [D loss: 0.692753] [G loss: 0.719417]\n",
            "[Epoch 14/50] [Batch 11/59] [D loss: 0.692544] [G loss: 0.719476]\n",
            "[Epoch 14/50] [Batch 12/59] [D loss: 0.692237] [G loss: 0.719827]\n",
            "[Epoch 14/50] [Batch 13/59] [D loss: 0.691819] [G loss: 0.718982]\n",
            "[Epoch 14/50] [Batch 14/59] [D loss: 0.692031] [G loss: 0.718054]\n",
            "[Epoch 14/50] [Batch 15/59] [D loss: 0.691051] [G loss: 0.717863]\n",
            "[Epoch 14/50] [Batch 16/59] [D loss: 0.691324] [G loss: 0.717905]\n",
            "[Epoch 14/50] [Batch 17/59] [D loss: 0.691506] [G loss: 0.716069]\n",
            "[Epoch 14/50] [Batch 18/59] [D loss: 0.690357] [G loss: 0.715195]\n",
            "[Epoch 14/50] [Batch 19/59] [D loss: 0.690449] [G loss: 0.713355]\n",
            "[Epoch 14/50] [Batch 20/59] [D loss: 0.690635] [G loss: 0.712396]\n",
            "[Epoch 14/50] [Batch 21/59] [D loss: 0.690501] [G loss: 0.710667]\n",
            "[Epoch 14/50] [Batch 22/59] [D loss: 0.690363] [G loss: 0.709360]\n",
            "[Epoch 14/50] [Batch 23/59] [D loss: 0.690463] [G loss: 0.706158]\n",
            "[Epoch 14/50] [Batch 24/59] [D loss: 0.691162] [G loss: 0.701669]\n",
            "[Epoch 14/50] [Batch 25/59] [D loss: 0.691070] [G loss: 0.699302]\n",
            "[Epoch 14/50] [Batch 26/59] [D loss: 0.691275] [G loss: 0.695093]\n",
            "[Epoch 14/50] [Batch 27/59] [D loss: 0.692446] [G loss: 0.690832]\n",
            "[Epoch 14/50] [Batch 28/59] [D loss: 0.691687] [G loss: 0.687526]\n",
            "[Epoch 14/50] [Batch 29/59] [D loss: 0.691514] [G loss: 0.684207]\n",
            "[Epoch 14/50] [Batch 30/59] [D loss: 0.691058] [G loss: 0.681132]\n",
            "[Epoch 14/50] [Batch 31/59] [D loss: 0.690711] [G loss: 0.678591]\n",
            "[Epoch 14/50] [Batch 32/59] [D loss: 0.690422] [G loss: 0.676226]\n",
            "[Epoch 14/50] [Batch 33/59] [D loss: 0.690275] [G loss: 0.673346]\n",
            "[Epoch 14/50] [Batch 34/59] [D loss: 0.689574] [G loss: 0.672242]\n",
            "[Epoch 14/50] [Batch 35/59] [D loss: 0.688977] [G loss: 0.669526]\n",
            "[Epoch 14/50] [Batch 36/59] [D loss: 0.688736] [G loss: 0.666978]\n",
            "[Epoch 14/50] [Batch 37/59] [D loss: 0.688824] [G loss: 0.665721]\n",
            "[Epoch 14/50] [Batch 38/59] [D loss: 0.690363] [G loss: 0.662925]\n",
            "[Epoch 14/50] [Batch 39/59] [D loss: 0.689551] [G loss: 0.663451]\n",
            "[Epoch 14/50] [Batch 40/59] [D loss: 0.690822] [G loss: 0.661735]\n",
            "[Epoch 14/50] [Batch 41/59] [D loss: 0.691734] [G loss: 0.662373]\n",
            "[Epoch 14/50] [Batch 42/59] [D loss: 0.693881] [G loss: 0.662259]\n",
            "[Epoch 14/50] [Batch 43/59] [D loss: 0.694568] [G loss: 0.665765]\n",
            "[Epoch 14/50] [Batch 44/59] [D loss: 0.695566] [G loss: 0.667293]\n",
            "[Epoch 14/50] [Batch 45/59] [D loss: 0.696763] [G loss: 0.672763]\n",
            "[Epoch 14/50] [Batch 46/59] [D loss: 0.697039] [G loss: 0.679471]\n",
            "[Epoch 14/50] [Batch 47/59] [D loss: 0.697299] [G loss: 0.685099]\n",
            "[Epoch 14/50] [Batch 48/59] [D loss: 0.697516] [G loss: 0.690102]\n",
            "[Epoch 14/50] [Batch 49/59] [D loss: 0.697484] [G loss: 0.696833]\n",
            "[Epoch 14/50] [Batch 50/59] [D loss: 0.696684] [G loss: 0.702125]\n",
            "[Epoch 14/50] [Batch 51/59] [D loss: 0.696468] [G loss: 0.707559]\n",
            "[Epoch 14/50] [Batch 52/59] [D loss: 0.695515] [G loss: 0.712199]\n",
            "[Epoch 14/50] [Batch 53/59] [D loss: 0.695473] [G loss: 0.715181]\n",
            "[Epoch 14/50] [Batch 54/59] [D loss: 0.695392] [G loss: 0.718008]\n",
            "[Epoch 14/50] [Batch 55/59] [D loss: 0.694291] [G loss: 0.719719]\n",
            "[Epoch 14/50] [Batch 56/59] [D loss: 0.694246] [G loss: 0.720911]\n",
            "[Epoch 14/50] [Batch 57/59] [D loss: 0.693654] [G loss: 0.722669]\n",
            "[Epoch 14/50] [Batch 58/59] [D loss: 0.694068] [G loss: 0.723757]\n",
            "[Epoch 15/50] [Batch 0/59] [D loss: 0.693807] [G loss: 0.724082]\n",
            "[Epoch 15/50] [Batch 1/59] [D loss: 0.692733] [G loss: 0.724520]\n",
            "[Epoch 15/50] [Batch 2/59] [D loss: 0.692699] [G loss: 0.724145]\n",
            "[Epoch 15/50] [Batch 3/59] [D loss: 0.692937] [G loss: 0.723544]\n",
            "[Epoch 15/50] [Batch 4/59] [D loss: 0.692374] [G loss: 0.724185]\n",
            "[Epoch 15/50] [Batch 5/59] [D loss: 0.692629] [G loss: 0.723423]\n",
            "[Epoch 15/50] [Batch 6/59] [D loss: 0.693162] [G loss: 0.721936]\n",
            "[Epoch 15/50] [Batch 7/59] [D loss: 0.693135] [G loss: 0.720002]\n",
            "[Epoch 15/50] [Batch 8/59] [D loss: 0.693076] [G loss: 0.718388]\n",
            "[Epoch 15/50] [Batch 9/59] [D loss: 0.693345] [G loss: 0.715546]\n",
            "[Epoch 15/50] [Batch 10/59] [D loss: 0.694200] [G loss: 0.714337]\n",
            "[Epoch 15/50] [Batch 11/59] [D loss: 0.693963] [G loss: 0.711702]\n",
            "[Epoch 15/50] [Batch 12/59] [D loss: 0.693721] [G loss: 0.708003]\n",
            "[Epoch 15/50] [Batch 13/59] [D loss: 0.693651] [G loss: 0.706510]\n",
            "[Epoch 15/50] [Batch 14/59] [D loss: 0.693344] [G loss: 0.704226]\n",
            "[Epoch 15/50] [Batch 15/59] [D loss: 0.692800] [G loss: 0.701987]\n",
            "[Epoch 15/50] [Batch 16/59] [D loss: 0.692010] [G loss: 0.700271]\n",
            "[Epoch 15/50] [Batch 17/59] [D loss: 0.691028] [G loss: 0.699329]\n",
            "[Epoch 15/50] [Batch 18/59] [D loss: 0.690242] [G loss: 0.698916]\n",
            "[Epoch 15/50] [Batch 19/59] [D loss: 0.688377] [G loss: 0.698606]\n",
            "[Epoch 15/50] [Batch 20/59] [D loss: 0.687066] [G loss: 0.698303]\n",
            "[Epoch 15/50] [Batch 21/59] [D loss: 0.685153] [G loss: 0.696956]\n",
            "[Epoch 15/50] [Batch 22/59] [D loss: 0.684045] [G loss: 0.694829]\n",
            "[Epoch 15/50] [Batch 23/59] [D loss: 0.683473] [G loss: 0.691813]\n",
            "[Epoch 15/50] [Batch 24/59] [D loss: 0.683397] [G loss: 0.686249]\n",
            "[Epoch 15/50] [Batch 25/59] [D loss: 0.685455] [G loss: 0.679040]\n",
            "[Epoch 15/50] [Batch 26/59] [D loss: 0.689127] [G loss: 0.669705]\n",
            "[Epoch 15/50] [Batch 27/59] [D loss: 0.690488] [G loss: 0.664967]\n",
            "[Epoch 15/50] [Batch 28/59] [D loss: 0.696472] [G loss: 0.660003]\n",
            "[Epoch 15/50] [Batch 29/59] [D loss: 0.700781] [G loss: 0.660249]\n",
            "[Epoch 15/50] [Batch 30/59] [D loss: 0.702107] [G loss: 0.665736]\n",
            "[Epoch 15/50] [Batch 31/59] [D loss: 0.704520] [G loss: 0.673324]\n",
            "[Epoch 15/50] [Batch 32/59] [D loss: 0.704537] [G loss: 0.677810]\n",
            "[Epoch 15/50] [Batch 33/59] [D loss: 0.703045] [G loss: 0.685350]\n",
            "[Epoch 15/50] [Batch 34/59] [D loss: 0.701882] [G loss: 0.691339]\n",
            "[Epoch 15/50] [Batch 35/59] [D loss: 0.700049] [G loss: 0.698011]\n",
            "[Epoch 15/50] [Batch 36/59] [D loss: 0.698593] [G loss: 0.701508]\n",
            "[Epoch 15/50] [Batch 37/59] [D loss: 0.697528] [G loss: 0.705338]\n",
            "[Epoch 15/50] [Batch 38/59] [D loss: 0.695696] [G loss: 0.708799]\n",
            "[Epoch 15/50] [Batch 39/59] [D loss: 0.694358] [G loss: 0.711480]\n",
            "[Epoch 15/50] [Batch 40/59] [D loss: 0.692606] [G loss: 0.714778]\n",
            "[Epoch 15/50] [Batch 41/59] [D loss: 0.691289] [G loss: 0.718331]\n",
            "[Epoch 15/50] [Batch 42/59] [D loss: 0.690331] [G loss: 0.722473]\n",
            "[Epoch 15/50] [Batch 43/59] [D loss: 0.689576] [G loss: 0.725766]\n",
            "[Epoch 15/50] [Batch 44/59] [D loss: 0.687806] [G loss: 0.731265]\n",
            "[Epoch 15/50] [Batch 45/59] [D loss: 0.687325] [G loss: 0.734611]\n",
            "[Epoch 15/50] [Batch 46/59] [D loss: 0.684852] [G loss: 0.737527]\n",
            "[Epoch 15/50] [Batch 47/59] [D loss: 0.684710] [G loss: 0.741042]\n",
            "[Epoch 15/50] [Batch 48/59] [D loss: 0.682710] [G loss: 0.747099]\n",
            "[Epoch 15/50] [Batch 49/59] [D loss: 0.681754] [G loss: 0.751086]\n",
            "[Epoch 15/50] [Batch 50/59] [D loss: 0.681571] [G loss: 0.752920]\n",
            "[Epoch 15/50] [Batch 51/59] [D loss: 0.684875] [G loss: 0.753103]\n",
            "[Epoch 15/50] [Batch 52/59] [D loss: 0.684649] [G loss: 0.750793]\n",
            "[Epoch 15/50] [Batch 53/59] [D loss: 0.686574] [G loss: 0.737620]\n",
            "[Epoch 15/50] [Batch 54/59] [D loss: 0.693479] [G loss: 0.722812]\n",
            "[Epoch 15/50] [Batch 55/59] [D loss: 0.698059] [G loss: 0.702421]\n",
            "[Epoch 15/50] [Batch 56/59] [D loss: 0.701666] [G loss: 0.683158]\n",
            "[Epoch 15/50] [Batch 57/59] [D loss: 0.704386] [G loss: 0.666753]\n",
            "[Epoch 15/50] [Batch 58/59] [D loss: 0.701228] [G loss: 0.657571]\n",
            "[Epoch 16/50] [Batch 0/59] [D loss: 0.698162] [G loss: 0.651582]\n",
            "[Epoch 16/50] [Batch 1/59] [D loss: 0.693162] [G loss: 0.650700]\n",
            "[Epoch 16/50] [Batch 2/59] [D loss: 0.687946] [G loss: 0.651154]\n",
            "[Epoch 16/50] [Batch 3/59] [D loss: 0.683975] [G loss: 0.650923]\n",
            "[Epoch 16/50] [Batch 4/59] [D loss: 0.679950] [G loss: 0.651313]\n",
            "[Epoch 16/50] [Batch 5/59] [D loss: 0.676183] [G loss: 0.646810]\n",
            "[Epoch 16/50] [Batch 6/59] [D loss: 0.673220] [G loss: 0.640518]\n",
            "[Epoch 16/50] [Batch 7/59] [D loss: 0.673618] [G loss: 0.626525]\n",
            "[Epoch 16/50] [Batch 8/59] [D loss: 0.677462] [G loss: 0.607526]\n",
            "[Epoch 16/50] [Batch 9/59] [D loss: 0.686245] [G loss: 0.595080]\n",
            "[Epoch 16/50] [Batch 10/59] [D loss: 0.696069] [G loss: 0.587246]\n",
            "[Epoch 16/50] [Batch 11/59] [D loss: 0.702725] [G loss: 0.586455]\n",
            "[Epoch 16/50] [Batch 12/59] [D loss: 0.707758] [G loss: 0.603829]\n",
            "[Epoch 16/50] [Batch 13/59] [D loss: 0.707775] [G loss: 0.627485]\n",
            "[Epoch 16/50] [Batch 14/59] [D loss: 0.709025] [G loss: 0.645316]\n",
            "[Epoch 16/50] [Batch 15/59] [D loss: 0.706454] [G loss: 0.663195]\n",
            "[Epoch 16/50] [Batch 16/59] [D loss: 0.704978] [G loss: 0.677939]\n",
            "[Epoch 16/50] [Batch 17/59] [D loss: 0.703401] [G loss: 0.688589]\n",
            "[Epoch 16/50] [Batch 18/59] [D loss: 0.701607] [G loss: 0.698526]\n",
            "[Epoch 16/50] [Batch 19/59] [D loss: 0.699383] [G loss: 0.705828]\n",
            "[Epoch 16/50] [Batch 20/59] [D loss: 0.697599] [G loss: 0.710213]\n",
            "[Epoch 16/50] [Batch 21/59] [D loss: 0.697251] [G loss: 0.713791]\n",
            "[Epoch 16/50] [Batch 22/59] [D loss: 0.694586] [G loss: 0.718006]\n",
            "[Epoch 16/50] [Batch 23/59] [D loss: 0.693656] [G loss: 0.720979]\n",
            "[Epoch 16/50] [Batch 24/59] [D loss: 0.693102] [G loss: 0.723904]\n",
            "[Epoch 16/50] [Batch 25/59] [D loss: 0.691279] [G loss: 0.727469]\n",
            "[Epoch 16/50] [Batch 26/59] [D loss: 0.690718] [G loss: 0.729594]\n",
            "[Epoch 16/50] [Batch 27/59] [D loss: 0.689817] [G loss: 0.733847]\n",
            "[Epoch 16/50] [Batch 28/59] [D loss: 0.688600] [G loss: 0.737339]\n",
            "[Epoch 16/50] [Batch 29/59] [D loss: 0.687374] [G loss: 0.742073]\n",
            "[Epoch 16/50] [Batch 30/59] [D loss: 0.686963] [G loss: 0.746421]\n",
            "[Epoch 16/50] [Batch 31/59] [D loss: 0.686716] [G loss: 0.749587]\n",
            "[Epoch 16/50] [Batch 32/59] [D loss: 0.685764] [G loss: 0.752768]\n",
            "[Epoch 16/50] [Batch 33/59] [D loss: 0.687670] [G loss: 0.750185]\n",
            "[Epoch 16/50] [Batch 34/59] [D loss: 0.688160] [G loss: 0.748366]\n",
            "[Epoch 16/50] [Batch 35/59] [D loss: 0.689281] [G loss: 0.744806]\n",
            "[Epoch 16/50] [Batch 36/59] [D loss: 0.691539] [G loss: 0.733024]\n",
            "[Epoch 16/50] [Batch 37/59] [D loss: 0.694006] [G loss: 0.720304]\n",
            "[Epoch 16/50] [Batch 38/59] [D loss: 0.695987] [G loss: 0.710457]\n",
            "[Epoch 16/50] [Batch 39/59] [D loss: 0.693123] [G loss: 0.701946]\n",
            "[Epoch 16/50] [Batch 40/59] [D loss: 0.692413] [G loss: 0.695815]\n",
            "[Epoch 16/50] [Batch 41/59] [D loss: 0.689775] [G loss: 0.694755]\n",
            "[Epoch 16/50] [Batch 42/59] [D loss: 0.687434] [G loss: 0.693740]\n",
            "[Epoch 16/50] [Batch 43/59] [D loss: 0.685023] [G loss: 0.692820]\n",
            "[Epoch 16/50] [Batch 44/59] [D loss: 0.682198] [G loss: 0.692538]\n",
            "[Epoch 16/50] [Batch 45/59] [D loss: 0.680559] [G loss: 0.688298]\n",
            "[Epoch 16/50] [Batch 46/59] [D loss: 0.677635] [G loss: 0.683694]\n",
            "[Epoch 16/50] [Batch 47/59] [D loss: 0.675764] [G loss: 0.678185]\n",
            "[Epoch 16/50] [Batch 48/59] [D loss: 0.676884] [G loss: 0.669447]\n",
            "[Epoch 16/50] [Batch 49/59] [D loss: 0.679378] [G loss: 0.655191]\n",
            "[Epoch 16/50] [Batch 50/59] [D loss: 0.681266] [G loss: 0.641123]\n",
            "[Epoch 16/50] [Batch 51/59] [D loss: 0.686794] [G loss: 0.628494]\n",
            "[Epoch 16/50] [Batch 52/59] [D loss: 0.692887] [G loss: 0.624177]\n",
            "[Epoch 16/50] [Batch 53/59] [D loss: 0.697915] [G loss: 0.628038]\n",
            "[Epoch 16/50] [Batch 54/59] [D loss: 0.701762] [G loss: 0.638343]\n",
            "[Epoch 16/50] [Batch 55/59] [D loss: 0.703161] [G loss: 0.648208]\n",
            "[Epoch 16/50] [Batch 56/59] [D loss: 0.707901] [G loss: 0.659766]\n",
            "[Epoch 16/50] [Batch 57/59] [D loss: 0.708875] [G loss: 0.669790]\n",
            "[Epoch 16/50] [Batch 58/59] [D loss: 0.705879] [G loss: 0.683778]\n",
            "[Epoch 17/50] [Batch 0/59] [D loss: 0.704675] [G loss: 0.690304]\n",
            "[Epoch 17/50] [Batch 1/59] [D loss: 0.701036] [G loss: 0.697772]\n",
            "[Epoch 17/50] [Batch 2/59] [D loss: 0.698210] [G loss: 0.705525]\n",
            "[Epoch 17/50] [Batch 3/59] [D loss: 0.694525] [G loss: 0.709846]\n",
            "[Epoch 17/50] [Batch 4/59] [D loss: 0.692914] [G loss: 0.712637]\n",
            "[Epoch 17/50] [Batch 5/59] [D loss: 0.690659] [G loss: 0.717716]\n",
            "[Epoch 17/50] [Batch 6/59] [D loss: 0.688834] [G loss: 0.719170]\n",
            "[Epoch 17/50] [Batch 7/59] [D loss: 0.687352] [G loss: 0.721126]\n",
            "[Epoch 17/50] [Batch 8/59] [D loss: 0.687255] [G loss: 0.722725]\n",
            "[Epoch 17/50] [Batch 9/59] [D loss: 0.685880] [G loss: 0.723385]\n",
            "[Epoch 17/50] [Batch 10/59] [D loss: 0.684851] [G loss: 0.725309]\n",
            "[Epoch 17/50] [Batch 11/59] [D loss: 0.681993] [G loss: 0.727545]\n",
            "[Epoch 17/50] [Batch 12/59] [D loss: 0.684151] [G loss: 0.724914]\n",
            "[Epoch 17/50] [Batch 13/59] [D loss: 0.683436] [G loss: 0.726251]\n",
            "[Epoch 17/50] [Batch 14/59] [D loss: 0.685807] [G loss: 0.722593]\n",
            "[Epoch 17/50] [Batch 15/59] [D loss: 0.685810] [G loss: 0.721584]\n",
            "[Epoch 17/50] [Batch 16/59] [D loss: 0.688927] [G loss: 0.716627]\n",
            "[Epoch 17/50] [Batch 17/59] [D loss: 0.691409] [G loss: 0.712781]\n",
            "[Epoch 17/50] [Batch 18/59] [D loss: 0.692628] [G loss: 0.712396]\n",
            "[Epoch 17/50] [Batch 19/59] [D loss: 0.694865] [G loss: 0.708288]\n",
            "[Epoch 17/50] [Batch 20/59] [D loss: 0.698345] [G loss: 0.701962]\n",
            "[Epoch 17/50] [Batch 21/59] [D loss: 0.701324] [G loss: 0.694350]\n",
            "[Epoch 17/50] [Batch 22/59] [D loss: 0.703895] [G loss: 0.684153]\n",
            "[Epoch 17/50] [Batch 23/59] [D loss: 0.702992] [G loss: 0.683028]\n",
            "[Epoch 17/50] [Batch 24/59] [D loss: 0.704977] [G loss: 0.675850]\n",
            "[Epoch 17/50] [Batch 25/59] [D loss: 0.703846] [G loss: 0.674763]\n",
            "[Epoch 17/50] [Batch 26/59] [D loss: 0.700184] [G loss: 0.674028]\n",
            "[Epoch 17/50] [Batch 27/59] [D loss: 0.697740] [G loss: 0.674394]\n",
            "[Epoch 17/50] [Batch 28/59] [D loss: 0.694978] [G loss: 0.675071]\n",
            "[Epoch 17/50] [Batch 29/59] [D loss: 0.693868] [G loss: 0.675824]\n",
            "[Epoch 17/50] [Batch 30/59] [D loss: 0.691484] [G loss: 0.675226]\n",
            "[Epoch 17/50] [Batch 31/59] [D loss: 0.689777] [G loss: 0.675069]\n",
            "[Epoch 17/50] [Batch 32/59] [D loss: 0.687561] [G loss: 0.674002]\n",
            "[Epoch 17/50] [Batch 33/59] [D loss: 0.686519] [G loss: 0.672302]\n",
            "[Epoch 17/50] [Batch 34/59] [D loss: 0.686154] [G loss: 0.670396]\n",
            "[Epoch 17/50] [Batch 35/59] [D loss: 0.684860] [G loss: 0.668788]\n",
            "[Epoch 17/50] [Batch 36/59] [D loss: 0.683242] [G loss: 0.667029]\n",
            "[Epoch 17/50] [Batch 37/59] [D loss: 0.682368] [G loss: 0.663539]\n",
            "[Epoch 17/50] [Batch 38/59] [D loss: 0.682879] [G loss: 0.663168]\n",
            "[Epoch 17/50] [Batch 39/59] [D loss: 0.683346] [G loss: 0.662833]\n",
            "[Epoch 17/50] [Batch 40/59] [D loss: 0.684891] [G loss: 0.660047]\n",
            "[Epoch 17/50] [Batch 41/59] [D loss: 0.691831] [G loss: 0.657548]\n",
            "[Epoch 17/50] [Batch 42/59] [D loss: 0.692625] [G loss: 0.661114]\n",
            "[Epoch 17/50] [Batch 43/59] [D loss: 0.697679] [G loss: 0.670007]\n",
            "[Epoch 17/50] [Batch 44/59] [D loss: 0.698904] [G loss: 0.677368]\n",
            "[Epoch 17/50] [Batch 45/59] [D loss: 0.700355] [G loss: 0.686651]\n",
            "[Epoch 17/50] [Batch 46/59] [D loss: 0.703295] [G loss: 0.691123]\n",
            "[Epoch 17/50] [Batch 47/59] [D loss: 0.703040] [G loss: 0.696385]\n",
            "[Epoch 17/50] [Batch 48/59] [D loss: 0.703599] [G loss: 0.701699]\n",
            "[Epoch 17/50] [Batch 49/59] [D loss: 0.700732] [G loss: 0.704813]\n",
            "[Epoch 17/50] [Batch 50/59] [D loss: 0.700353] [G loss: 0.709824]\n",
            "[Epoch 17/50] [Batch 51/59] [D loss: 0.699859] [G loss: 0.709849]\n",
            "[Epoch 17/50] [Batch 52/59] [D loss: 0.698071] [G loss: 0.713248]\n",
            "[Epoch 17/50] [Batch 53/59] [D loss: 0.696890] [G loss: 0.714414]\n",
            "[Epoch 17/50] [Batch 54/59] [D loss: 0.696034] [G loss: 0.715635]\n",
            "[Epoch 17/50] [Batch 55/59] [D loss: 0.693990] [G loss: 0.717764]\n",
            "[Epoch 17/50] [Batch 56/59] [D loss: 0.693383] [G loss: 0.718507]\n",
            "[Epoch 17/50] [Batch 57/59] [D loss: 0.692899] [G loss: 0.718748]\n",
            "[Epoch 17/50] [Batch 58/59] [D loss: 0.691748] [G loss: 0.721008]\n",
            "[Epoch 18/50] [Batch 0/59] [D loss: 0.690749] [G loss: 0.721076]\n",
            "[Epoch 18/50] [Batch 1/59] [D loss: 0.690527] [G loss: 0.721453]\n",
            "[Epoch 18/50] [Batch 2/59] [D loss: 0.689423] [G loss: 0.721875]\n",
            "[Epoch 18/50] [Batch 3/59] [D loss: 0.688568] [G loss: 0.725119]\n",
            "[Epoch 18/50] [Batch 4/59] [D loss: 0.687662] [G loss: 0.726452]\n",
            "[Epoch 18/50] [Batch 5/59] [D loss: 0.686865] [G loss: 0.727962]\n",
            "[Epoch 18/50] [Batch 6/59] [D loss: 0.685251] [G loss: 0.730371]\n",
            "[Epoch 18/50] [Batch 7/59] [D loss: 0.684856] [G loss: 0.732339]\n",
            "[Epoch 18/50] [Batch 8/59] [D loss: 0.683816] [G loss: 0.734019]\n",
            "[Epoch 18/50] [Batch 9/59] [D loss: 0.682035] [G loss: 0.733846]\n",
            "[Epoch 18/50] [Batch 10/59] [D loss: 0.683099] [G loss: 0.730835]\n",
            "[Epoch 18/50] [Batch 11/59] [D loss: 0.684062] [G loss: 0.730007]\n",
            "[Epoch 18/50] [Batch 12/59] [D loss: 0.685182] [G loss: 0.720103]\n",
            "[Epoch 18/50] [Batch 13/59] [D loss: 0.689504] [G loss: 0.707430]\n",
            "[Epoch 18/50] [Batch 14/59] [D loss: 0.691723] [G loss: 0.694982]\n",
            "[Epoch 18/50] [Batch 15/59] [D loss: 0.695996] [G loss: 0.680269]\n",
            "[Epoch 18/50] [Batch 16/59] [D loss: 0.700552] [G loss: 0.662777]\n",
            "[Epoch 18/50] [Batch 17/59] [D loss: 0.704808] [G loss: 0.650209]\n",
            "[Epoch 18/50] [Batch 18/59] [D loss: 0.707763] [G loss: 0.646354]\n",
            "[Epoch 18/50] [Batch 19/59] [D loss: 0.706575] [G loss: 0.642158]\n",
            "[Epoch 18/50] [Batch 20/59] [D loss: 0.708200] [G loss: 0.647002]\n",
            "[Epoch 18/50] [Batch 21/59] [D loss: 0.706461] [G loss: 0.652618]\n",
            "[Epoch 18/50] [Batch 22/59] [D loss: 0.702358] [G loss: 0.663640]\n",
            "[Epoch 18/50] [Batch 23/59] [D loss: 0.701530] [G loss: 0.668695]\n",
            "[Epoch 18/50] [Batch 24/59] [D loss: 0.700428] [G loss: 0.674256]\n",
            "[Epoch 18/50] [Batch 25/59] [D loss: 0.699492] [G loss: 0.679343]\n",
            "[Epoch 18/50] [Batch 26/59] [D loss: 0.698187] [G loss: 0.683248]\n",
            "[Epoch 18/50] [Batch 27/59] [D loss: 0.697192] [G loss: 0.687434]\n",
            "[Epoch 18/50] [Batch 28/59] [D loss: 0.695628] [G loss: 0.690510]\n",
            "[Epoch 18/50] [Batch 29/59] [D loss: 0.694634] [G loss: 0.693789]\n",
            "[Epoch 18/50] [Batch 30/59] [D loss: 0.694265] [G loss: 0.695353]\n",
            "[Epoch 18/50] [Batch 31/59] [D loss: 0.694225] [G loss: 0.697672]\n",
            "[Epoch 18/50] [Batch 32/59] [D loss: 0.693317] [G loss: 0.700210]\n",
            "[Epoch 18/50] [Batch 33/59] [D loss: 0.692830] [G loss: 0.702302]\n",
            "[Epoch 18/50] [Batch 34/59] [D loss: 0.692414] [G loss: 0.703749]\n",
            "[Epoch 18/50] [Batch 35/59] [D loss: 0.691619] [G loss: 0.706114]\n",
            "[Epoch 18/50] [Batch 36/59] [D loss: 0.690726] [G loss: 0.709038]\n",
            "[Epoch 18/50] [Batch 37/59] [D loss: 0.689782] [G loss: 0.711812]\n",
            "[Epoch 18/50] [Batch 38/59] [D loss: 0.689888] [G loss: 0.716099]\n",
            "[Epoch 18/50] [Batch 39/59] [D loss: 0.689126] [G loss: 0.719411]\n",
            "[Epoch 18/50] [Batch 40/59] [D loss: 0.688204] [G loss: 0.723496]\n",
            "[Epoch 18/50] [Batch 41/59] [D loss: 0.687645] [G loss: 0.728178]\n",
            "[Epoch 18/50] [Batch 42/59] [D loss: 0.687840] [G loss: 0.730714]\n",
            "[Epoch 18/50] [Batch 43/59] [D loss: 0.686414] [G loss: 0.736573]\n",
            "[Epoch 18/50] [Batch 44/59] [D loss: 0.687165] [G loss: 0.740743]\n",
            "[Epoch 18/50] [Batch 45/59] [D loss: 0.686579] [G loss: 0.743767]\n",
            "[Epoch 18/50] [Batch 46/59] [D loss: 0.687475] [G loss: 0.743043]\n",
            "[Epoch 18/50] [Batch 47/59] [D loss: 0.688770] [G loss: 0.739474]\n",
            "[Epoch 18/50] [Batch 48/59] [D loss: 0.687516] [G loss: 0.739938]\n",
            "[Epoch 18/50] [Batch 49/59] [D loss: 0.689471] [G loss: 0.734655]\n",
            "[Epoch 18/50] [Batch 50/59] [D loss: 0.689820] [G loss: 0.727925]\n",
            "[Epoch 18/50] [Batch 51/59] [D loss: 0.688636] [G loss: 0.723775]\n",
            "[Epoch 18/50] [Batch 52/59] [D loss: 0.688988] [G loss: 0.721700]\n",
            "[Epoch 18/50] [Batch 53/59] [D loss: 0.688251] [G loss: 0.712196]\n",
            "[Epoch 18/50] [Batch 54/59] [D loss: 0.689059] [G loss: 0.707623]\n",
            "[Epoch 18/50] [Batch 55/59] [D loss: 0.690417] [G loss: 0.698251]\n",
            "[Epoch 18/50] [Batch 56/59] [D loss: 0.689508] [G loss: 0.689962]\n",
            "[Epoch 18/50] [Batch 57/59] [D loss: 0.687833] [G loss: 0.684502]\n",
            "[Epoch 18/50] [Batch 58/59] [D loss: 0.687152] [G loss: 0.680298]\n",
            "[Epoch 19/50] [Batch 0/59] [D loss: 0.686630] [G loss: 0.672200]\n",
            "[Epoch 19/50] [Batch 1/59] [D loss: 0.684251] [G loss: 0.666127]\n",
            "[Epoch 19/50] [Batch 2/59] [D loss: 0.683068] [G loss: 0.661016]\n",
            "[Epoch 19/50] [Batch 3/59] [D loss: 0.682005] [G loss: 0.658964]\n",
            "[Epoch 19/50] [Batch 4/59] [D loss: 0.679635] [G loss: 0.657534]\n",
            "[Epoch 19/50] [Batch 5/59] [D loss: 0.676097] [G loss: 0.659458]\n",
            "[Epoch 19/50] [Batch 6/59] [D loss: 0.671702] [G loss: 0.663133]\n",
            "[Epoch 19/50] [Batch 7/59] [D loss: 0.666393] [G loss: 0.666379]\n",
            "[Epoch 19/50] [Batch 8/59] [D loss: 0.666089] [G loss: 0.656629]\n",
            "[Epoch 19/50] [Batch 9/59] [D loss: 0.673652] [G loss: 0.643943]\n",
            "[Epoch 19/50] [Batch 10/59] [D loss: 0.687634] [G loss: 0.629608]\n",
            "[Epoch 19/50] [Batch 11/59] [D loss: 0.701222] [G loss: 0.620343]\n",
            "[Epoch 19/50] [Batch 12/59] [D loss: 0.716442] [G loss: 0.625118]\n",
            "[Epoch 19/50] [Batch 13/59] [D loss: 0.718217] [G loss: 0.651499]\n",
            "[Epoch 19/50] [Batch 14/59] [D loss: 0.719180] [G loss: 0.671541]\n",
            "[Epoch 19/50] [Batch 15/59] [D loss: 0.715163] [G loss: 0.692330]\n",
            "[Epoch 19/50] [Batch 16/59] [D loss: 0.713598] [G loss: 0.705826]\n",
            "[Epoch 19/50] [Batch 17/59] [D loss: 0.707386] [G loss: 0.718088]\n",
            "[Epoch 19/50] [Batch 18/59] [D loss: 0.704887] [G loss: 0.727168]\n",
            "[Epoch 19/50] [Batch 19/59] [D loss: 0.701089] [G loss: 0.732821]\n",
            "[Epoch 19/50] [Batch 20/59] [D loss: 0.697931] [G loss: 0.739095]\n",
            "[Epoch 19/50] [Batch 21/59] [D loss: 0.695572] [G loss: 0.742191]\n",
            "[Epoch 19/50] [Batch 22/59] [D loss: 0.693535] [G loss: 0.744832]\n",
            "[Epoch 19/50] [Batch 23/59] [D loss: 0.690661] [G loss: 0.750691]\n",
            "[Epoch 19/50] [Batch 24/59] [D loss: 0.688784] [G loss: 0.753690]\n",
            "[Epoch 19/50] [Batch 25/59] [D loss: 0.687702] [G loss: 0.759888]\n",
            "[Epoch 19/50] [Batch 26/59] [D loss: 0.685571] [G loss: 0.766336]\n",
            "[Epoch 19/50] [Batch 27/59] [D loss: 0.683326] [G loss: 0.773799]\n",
            "[Epoch 19/50] [Batch 28/59] [D loss: 0.682300] [G loss: 0.780528]\n",
            "[Epoch 19/50] [Batch 29/59] [D loss: 0.683645] [G loss: 0.786842]\n",
            "[Epoch 19/50] [Batch 30/59] [D loss: 0.683301] [G loss: 0.786120]\n",
            "[Epoch 19/50] [Batch 31/59] [D loss: 0.684887] [G loss: 0.781599]\n",
            "[Epoch 19/50] [Batch 32/59] [D loss: 0.687898] [G loss: 0.770609]\n",
            "[Epoch 19/50] [Batch 33/59] [D loss: 0.690113] [G loss: 0.760566]\n",
            "[Epoch 19/50] [Batch 34/59] [D loss: 0.692777] [G loss: 0.749704]\n",
            "[Epoch 19/50] [Batch 35/59] [D loss: 0.698950] [G loss: 0.733322]\n",
            "[Epoch 19/50] [Batch 36/59] [D loss: 0.699701] [G loss: 0.712936]\n",
            "[Epoch 19/50] [Batch 37/59] [D loss: 0.701669] [G loss: 0.699047]\n",
            "[Epoch 19/50] [Batch 38/59] [D loss: 0.702120] [G loss: 0.684673]\n",
            "[Epoch 19/50] [Batch 39/59] [D loss: 0.701894] [G loss: 0.674173]\n",
            "[Epoch 19/50] [Batch 40/59] [D loss: 0.700852] [G loss: 0.667461]\n",
            "[Epoch 19/50] [Batch 41/59] [D loss: 0.698183] [G loss: 0.661924]\n",
            "[Epoch 19/50] [Batch 42/59] [D loss: 0.695029] [G loss: 0.659665]\n",
            "[Epoch 19/50] [Batch 43/59] [D loss: 0.692174] [G loss: 0.658518]\n",
            "[Epoch 19/50] [Batch 44/59] [D loss: 0.689478] [G loss: 0.655542]\n",
            "[Epoch 19/50] [Batch 45/59] [D loss: 0.687081] [G loss: 0.653974]\n",
            "[Epoch 19/50] [Batch 46/59] [D loss: 0.683624] [G loss: 0.649805]\n",
            "[Epoch 19/50] [Batch 47/59] [D loss: 0.680736] [G loss: 0.644772]\n",
            "[Epoch 19/50] [Batch 48/59] [D loss: 0.678616] [G loss: 0.636373]\n",
            "[Epoch 19/50] [Batch 49/59] [D loss: 0.677788] [G loss: 0.625618]\n",
            "[Epoch 19/50] [Batch 50/59] [D loss: 0.678505] [G loss: 0.613360]\n",
            "[Epoch 19/50] [Batch 51/59] [D loss: 0.682650] [G loss: 0.605075]\n",
            "[Epoch 19/50] [Batch 52/59] [D loss: 0.688622] [G loss: 0.604040]\n",
            "[Epoch 19/50] [Batch 53/59] [D loss: 0.692078] [G loss: 0.617157]\n",
            "[Epoch 19/50] [Batch 54/59] [D loss: 0.694690] [G loss: 0.637303]\n",
            "[Epoch 19/50] [Batch 55/59] [D loss: 0.696958] [G loss: 0.657101]\n",
            "[Epoch 19/50] [Batch 56/59] [D loss: 0.699563] [G loss: 0.678325]\n",
            "[Epoch 19/50] [Batch 57/59] [D loss: 0.703572] [G loss: 0.689921]\n",
            "[Epoch 19/50] [Batch 58/59] [D loss: 0.703994] [G loss: 0.700540]\n",
            "[Epoch 20/50] [Batch 0/59] [D loss: 0.704594] [G loss: 0.709214]\n",
            "[Epoch 20/50] [Batch 1/59] [D loss: 0.704764] [G loss: 0.713752]\n",
            "[Epoch 20/50] [Batch 2/59] [D loss: 0.700395] [G loss: 0.718547]\n",
            "[Epoch 20/50] [Batch 3/59] [D loss: 0.700240] [G loss: 0.721221]\n",
            "[Epoch 20/50] [Batch 4/59] [D loss: 0.697207] [G loss: 0.722406]\n",
            "[Epoch 20/50] [Batch 5/59] [D loss: 0.695259] [G loss: 0.724495]\n",
            "[Epoch 20/50] [Batch 6/59] [D loss: 0.693190] [G loss: 0.725688]\n",
            "[Epoch 20/50] [Batch 7/59] [D loss: 0.691041] [G loss: 0.726906]\n",
            "[Epoch 20/50] [Batch 8/59] [D loss: 0.688562] [G loss: 0.728811]\n",
            "[Epoch 20/50] [Batch 9/59] [D loss: 0.687455] [G loss: 0.730425]\n",
            "[Epoch 20/50] [Batch 10/59] [D loss: 0.685253] [G loss: 0.731342]\n",
            "[Epoch 20/50] [Batch 11/59] [D loss: 0.683219] [G loss: 0.735197]\n",
            "[Epoch 20/50] [Batch 12/59] [D loss: 0.680650] [G loss: 0.738200]\n",
            "[Epoch 20/50] [Batch 13/59] [D loss: 0.679208] [G loss: 0.739404]\n",
            "[Epoch 20/50] [Batch 14/59] [D loss: 0.676183] [G loss: 0.743012]\n",
            "[Epoch 20/50] [Batch 15/59] [D loss: 0.675661] [G loss: 0.743308]\n",
            "[Epoch 20/50] [Batch 16/59] [D loss: 0.674773] [G loss: 0.742460]\n",
            "[Epoch 20/50] [Batch 17/59] [D loss: 0.674886] [G loss: 0.741527]\n",
            "[Epoch 20/50] [Batch 18/59] [D loss: 0.677273] [G loss: 0.733853]\n",
            "[Epoch 20/50] [Batch 19/59] [D loss: 0.684861] [G loss: 0.718086]\n",
            "[Epoch 20/50] [Batch 20/59] [D loss: 0.691952] [G loss: 0.704476]\n",
            "[Epoch 20/50] [Batch 21/59] [D loss: 0.696838] [G loss: 0.693006]\n",
            "[Epoch 20/50] [Batch 22/59] [D loss: 0.703217] [G loss: 0.679381]\n",
            "[Epoch 20/50] [Batch 23/59] [D loss: 0.707144] [G loss: 0.672629]\n",
            "[Epoch 20/50] [Batch 24/59] [D loss: 0.708723] [G loss: 0.670845]\n",
            "[Epoch 20/50] [Batch 25/59] [D loss: 0.706757] [G loss: 0.669166]\n",
            "[Epoch 20/50] [Batch 26/59] [D loss: 0.705444] [G loss: 0.669995]\n",
            "[Epoch 20/50] [Batch 27/59] [D loss: 0.701615] [G loss: 0.674258]\n",
            "[Epoch 20/50] [Batch 28/59] [D loss: 0.698640] [G loss: 0.678136]\n",
            "[Epoch 20/50] [Batch 29/59] [D loss: 0.695168] [G loss: 0.681635]\n",
            "[Epoch 20/50] [Batch 30/59] [D loss: 0.692363] [G loss: 0.684795]\n",
            "[Epoch 20/50] [Batch 31/59] [D loss: 0.690378] [G loss: 0.687703]\n",
            "[Epoch 20/50] [Batch 32/59] [D loss: 0.687765] [G loss: 0.687409]\n",
            "[Epoch 20/50] [Batch 33/59] [D loss: 0.684254] [G loss: 0.687571]\n",
            "[Epoch 20/50] [Batch 34/59] [D loss: 0.681116] [G loss: 0.687849]\n",
            "[Epoch 20/50] [Batch 35/59] [D loss: 0.677974] [G loss: 0.686858]\n",
            "[Epoch 20/50] [Batch 36/59] [D loss: 0.673724] [G loss: 0.683010]\n",
            "[Epoch 20/50] [Batch 37/59] [D loss: 0.669131] [G loss: 0.674913]\n",
            "[Epoch 20/50] [Batch 38/59] [D loss: 0.666073] [G loss: 0.663656]\n",
            "[Epoch 20/50] [Batch 39/59] [D loss: 0.666650] [G loss: 0.649542]\n",
            "[Epoch 20/50] [Batch 40/59] [D loss: 0.669418] [G loss: 0.629674]\n",
            "[Epoch 20/50] [Batch 41/59] [D loss: 0.677107] [G loss: 0.611710]\n",
            "[Epoch 20/50] [Batch 42/59] [D loss: 0.690366] [G loss: 0.609347]\n",
            "[Epoch 20/50] [Batch 43/59] [D loss: 0.702770] [G loss: 0.608099]\n",
            "[Epoch 20/50] [Batch 44/59] [D loss: 0.710486] [G loss: 0.619965]\n",
            "[Epoch 20/50] [Batch 45/59] [D loss: 0.716225] [G loss: 0.637655]\n",
            "[Epoch 20/50] [Batch 46/59] [D loss: 0.720547] [G loss: 0.648289]\n",
            "[Epoch 20/50] [Batch 47/59] [D loss: 0.718835] [G loss: 0.662221]\n",
            "[Epoch 20/50] [Batch 48/59] [D loss: 0.714985] [G loss: 0.669923]\n",
            "[Epoch 20/50] [Batch 49/59] [D loss: 0.709622] [G loss: 0.678232]\n",
            "[Epoch 20/50] [Batch 50/59] [D loss: 0.705191] [G loss: 0.684232]\n",
            "[Epoch 20/50] [Batch 51/59] [D loss: 0.699712] [G loss: 0.694042]\n",
            "[Epoch 20/50] [Batch 52/59] [D loss: 0.696204] [G loss: 0.701194]\n",
            "[Epoch 20/50] [Batch 53/59] [D loss: 0.693482] [G loss: 0.706439]\n",
            "[Epoch 20/50] [Batch 54/59] [D loss: 0.691905] [G loss: 0.710995]\n",
            "[Epoch 20/50] [Batch 55/59] [D loss: 0.691456] [G loss: 0.715550]\n",
            "[Epoch 20/50] [Batch 56/59] [D loss: 0.690555] [G loss: 0.719261]\n",
            "[Epoch 20/50] [Batch 57/59] [D loss: 0.689448] [G loss: 0.725200]\n",
            "[Epoch 20/50] [Batch 58/59] [D loss: 0.687751] [G loss: 0.730861]\n",
            "[Epoch 21/50] [Batch 0/59] [D loss: 0.688310] [G loss: 0.734681]\n",
            "[Epoch 21/50] [Batch 1/59] [D loss: 0.688000] [G loss: 0.740535]\n",
            "[Epoch 21/50] [Batch 2/59] [D loss: 0.686209] [G loss: 0.749266]\n",
            "[Epoch 21/50] [Batch 3/59] [D loss: 0.685585] [G loss: 0.753775]\n",
            "[Epoch 21/50] [Batch 4/59] [D loss: 0.686650] [G loss: 0.761924]\n",
            "[Epoch 21/50] [Batch 5/59] [D loss: 0.684853] [G loss: 0.768037]\n",
            "[Epoch 21/50] [Batch 6/59] [D loss: 0.684593] [G loss: 0.772362]\n",
            "[Epoch 21/50] [Batch 7/59] [D loss: 0.686779] [G loss: 0.776800]\n",
            "[Epoch 21/50] [Batch 8/59] [D loss: 0.687790] [G loss: 0.776567]\n",
            "[Epoch 21/50] [Batch 9/59] [D loss: 0.688110] [G loss: 0.773547]\n",
            "[Epoch 21/50] [Batch 10/59] [D loss: 0.690852] [G loss: 0.768852]\n",
            "[Epoch 21/50] [Batch 11/59] [D loss: 0.693162] [G loss: 0.764232]\n",
            "[Epoch 21/50] [Batch 12/59] [D loss: 0.695044] [G loss: 0.750334]\n",
            "[Epoch 21/50] [Batch 13/59] [D loss: 0.695604] [G loss: 0.741030]\n",
            "[Epoch 21/50] [Batch 14/59] [D loss: 0.699781] [G loss: 0.725750]\n",
            "[Epoch 21/50] [Batch 15/59] [D loss: 0.700200] [G loss: 0.713393]\n",
            "[Epoch 21/50] [Batch 16/59] [D loss: 0.699768] [G loss: 0.702139]\n",
            "[Epoch 21/50] [Batch 17/59] [D loss: 0.699888] [G loss: 0.692377]\n",
            "[Epoch 21/50] [Batch 18/59] [D loss: 0.698373] [G loss: 0.685080]\n",
            "[Epoch 21/50] [Batch 19/59] [D loss: 0.696899] [G loss: 0.680734]\n",
            "[Epoch 21/50] [Batch 20/59] [D loss: 0.695640] [G loss: 0.676941]\n",
            "[Epoch 21/50] [Batch 21/59] [D loss: 0.693629] [G loss: 0.675141]\n",
            "[Epoch 21/50] [Batch 22/59] [D loss: 0.692873] [G loss: 0.672235]\n",
            "[Epoch 21/50] [Batch 23/59] [D loss: 0.690548] [G loss: 0.671543]\n",
            "[Epoch 21/50] [Batch 24/59] [D loss: 0.688848] [G loss: 0.670766]\n",
            "[Epoch 21/50] [Batch 25/59] [D loss: 0.688125] [G loss: 0.668845]\n",
            "[Epoch 21/50] [Batch 26/59] [D loss: 0.686793] [G loss: 0.667066]\n",
            "[Epoch 21/50] [Batch 27/59] [D loss: 0.686029] [G loss: 0.664666]\n",
            "[Epoch 21/50] [Batch 28/59] [D loss: 0.685740] [G loss: 0.662465]\n",
            "[Epoch 21/50] [Batch 29/59] [D loss: 0.685152] [G loss: 0.658691]\n",
            "[Epoch 21/50] [Batch 30/59] [D loss: 0.684370] [G loss: 0.656220]\n",
            "[Epoch 21/50] [Batch 31/59] [D loss: 0.683878] [G loss: 0.653474]\n",
            "[Epoch 21/50] [Batch 32/59] [D loss: 0.685337] [G loss: 0.650189]\n",
            "[Epoch 21/50] [Batch 33/59] [D loss: 0.686097] [G loss: 0.646758]\n",
            "[Epoch 21/50] [Batch 34/59] [D loss: 0.686730] [G loss: 0.645766]\n",
            "[Epoch 21/50] [Batch 35/59] [D loss: 0.686484] [G loss: 0.647697]\n",
            "[Epoch 21/50] [Batch 36/59] [D loss: 0.688177] [G loss: 0.652396]\n",
            "[Epoch 21/50] [Batch 37/59] [D loss: 0.690556] [G loss: 0.656476]\n",
            "[Epoch 21/50] [Batch 38/59] [D loss: 0.690810] [G loss: 0.663258]\n",
            "[Epoch 21/50] [Batch 39/59] [D loss: 0.694351] [G loss: 0.666721]\n",
            "[Epoch 21/50] [Batch 40/59] [D loss: 0.696785] [G loss: 0.673114]\n",
            "[Epoch 21/50] [Batch 41/59] [D loss: 0.696948] [G loss: 0.682037]\n",
            "[Epoch 21/50] [Batch 42/59] [D loss: 0.700356] [G loss: 0.689527]\n",
            "[Epoch 21/50] [Batch 43/59] [D loss: 0.699261] [G loss: 0.698430]\n",
            "[Epoch 21/50] [Batch 44/59] [D loss: 0.702326] [G loss: 0.697871]\n",
            "[Epoch 21/50] [Batch 45/59] [D loss: 0.703281] [G loss: 0.704754]\n",
            "[Epoch 21/50] [Batch 46/59] [D loss: 0.703061] [G loss: 0.703988]\n",
            "[Epoch 21/50] [Batch 47/59] [D loss: 0.702291] [G loss: 0.705832]\n",
            "[Epoch 21/50] [Batch 48/59] [D loss: 0.701181] [G loss: 0.707410]\n",
            "[Epoch 21/50] [Batch 49/59] [D loss: 0.700387] [G loss: 0.708395]\n",
            "[Epoch 21/50] [Batch 50/59] [D loss: 0.699578] [G loss: 0.708606]\n",
            "[Epoch 21/50] [Batch 51/59] [D loss: 0.697654] [G loss: 0.708364]\n",
            "[Epoch 21/50] [Batch 52/59] [D loss: 0.697677] [G loss: 0.708752]\n",
            "[Epoch 21/50] [Batch 53/59] [D loss: 0.694955] [G loss: 0.710687]\n",
            "[Epoch 21/50] [Batch 54/59] [D loss: 0.694362] [G loss: 0.710572]\n",
            "[Epoch 21/50] [Batch 55/59] [D loss: 0.694130] [G loss: 0.710733]\n",
            "[Epoch 21/50] [Batch 56/59] [D loss: 0.692841] [G loss: 0.711641]\n",
            "[Epoch 21/50] [Batch 57/59] [D loss: 0.691209] [G loss: 0.713000]\n",
            "[Epoch 21/50] [Batch 58/59] [D loss: 0.690834] [G loss: 0.713280]\n",
            "[Epoch 22/50] [Batch 0/59] [D loss: 0.690002] [G loss: 0.714506]\n",
            "[Epoch 22/50] [Batch 1/59] [D loss: 0.689311] [G loss: 0.715125]\n",
            "[Epoch 22/50] [Batch 2/59] [D loss: 0.687831] [G loss: 0.717505]\n",
            "[Epoch 22/50] [Batch 3/59] [D loss: 0.685265] [G loss: 0.719310]\n",
            "[Epoch 22/50] [Batch 4/59] [D loss: 0.684446] [G loss: 0.721931]\n",
            "[Epoch 22/50] [Batch 5/59] [D loss: 0.682415] [G loss: 0.725181]\n",
            "[Epoch 22/50] [Batch 6/59] [D loss: 0.681296] [G loss: 0.728999]\n",
            "[Epoch 22/50] [Batch 7/59] [D loss: 0.678559] [G loss: 0.734206]\n",
            "[Epoch 22/50] [Batch 8/59] [D loss: 0.676643] [G loss: 0.735246]\n",
            "[Epoch 22/50] [Batch 9/59] [D loss: 0.675726] [G loss: 0.734513]\n",
            "[Epoch 22/50] [Batch 10/59] [D loss: 0.675119] [G loss: 0.732591]\n",
            "[Epoch 22/50] [Batch 11/59] [D loss: 0.677020] [G loss: 0.724555]\n",
            "[Epoch 22/50] [Batch 12/59] [D loss: 0.683048] [G loss: 0.713280]\n",
            "[Epoch 22/50] [Batch 13/59] [D loss: 0.692910] [G loss: 0.690252]\n",
            "[Epoch 22/50] [Batch 14/59] [D loss: 0.698872] [G loss: 0.675198]\n",
            "[Epoch 22/50] [Batch 15/59] [D loss: 0.709969] [G loss: 0.654939]\n",
            "[Epoch 22/50] [Batch 16/59] [D loss: 0.713251] [G loss: 0.647890]\n",
            "[Epoch 22/50] [Batch 17/59] [D loss: 0.714705] [G loss: 0.649975]\n",
            "[Epoch 22/50] [Batch 18/59] [D loss: 0.711745] [G loss: 0.655160]\n",
            "[Epoch 22/50] [Batch 19/59] [D loss: 0.706611] [G loss: 0.666683]\n",
            "[Epoch 22/50] [Batch 20/59] [D loss: 0.702480] [G loss: 0.680953]\n",
            "[Epoch 22/50] [Batch 21/59] [D loss: 0.696782] [G loss: 0.693909]\n",
            "[Epoch 22/50] [Batch 22/59] [D loss: 0.692202] [G loss: 0.707948]\n",
            "[Epoch 22/50] [Batch 23/59] [D loss: 0.687809] [G loss: 0.720649]\n",
            "[Epoch 22/50] [Batch 24/59] [D loss: 0.685206] [G loss: 0.728141]\n",
            "[Epoch 22/50] [Batch 25/59] [D loss: 0.683104] [G loss: 0.738344]\n",
            "[Epoch 22/50] [Batch 26/59] [D loss: 0.681087] [G loss: 0.742255]\n",
            "[Epoch 22/50] [Batch 27/59] [D loss: 0.678888] [G loss: 0.744003]\n",
            "[Epoch 22/50] [Batch 28/59] [D loss: 0.678289] [G loss: 0.743525]\n",
            "[Epoch 22/50] [Batch 29/59] [D loss: 0.680442] [G loss: 0.732041]\n",
            "[Epoch 22/50] [Batch 30/59] [D loss: 0.681574] [G loss: 0.718121]\n",
            "[Epoch 22/50] [Batch 31/59] [D loss: 0.684445] [G loss: 0.696921]\n",
            "[Epoch 22/50] [Batch 32/59] [D loss: 0.687182] [G loss: 0.676328]\n",
            "[Epoch 22/50] [Batch 33/59] [D loss: 0.689157] [G loss: 0.653051]\n",
            "[Epoch 22/50] [Batch 34/59] [D loss: 0.692527] [G loss: 0.628871]\n",
            "[Epoch 22/50] [Batch 35/59] [D loss: 0.696050] [G loss: 0.609464]\n",
            "[Epoch 22/50] [Batch 36/59] [D loss: 0.701823] [G loss: 0.593339]\n",
            "[Epoch 22/50] [Batch 37/59] [D loss: 0.703876] [G loss: 0.595443]\n",
            "[Epoch 22/50] [Batch 38/59] [D loss: 0.705097] [G loss: 0.606763]\n",
            "[Epoch 22/50] [Batch 39/59] [D loss: 0.703766] [G loss: 0.621485]\n",
            "[Epoch 22/50] [Batch 40/59] [D loss: 0.704538] [G loss: 0.638266]\n",
            "[Epoch 22/50] [Batch 41/59] [D loss: 0.702628] [G loss: 0.653927]\n",
            "[Epoch 22/50] [Batch 42/59] [D loss: 0.700118] [G loss: 0.670591]\n",
            "[Epoch 22/50] [Batch 43/59] [D loss: 0.699306] [G loss: 0.679687]\n",
            "[Epoch 22/50] [Batch 44/59] [D loss: 0.698177] [G loss: 0.690068]\n",
            "[Epoch 22/50] [Batch 45/59] [D loss: 0.696433] [G loss: 0.698822]\n",
            "[Epoch 22/50] [Batch 46/59] [D loss: 0.695079] [G loss: 0.707169]\n",
            "[Epoch 22/50] [Batch 47/59] [D loss: 0.693721] [G loss: 0.714239]\n",
            "[Epoch 22/50] [Batch 48/59] [D loss: 0.691601] [G loss: 0.721576]\n",
            "[Epoch 22/50] [Batch 49/59] [D loss: 0.691600] [G loss: 0.727289]\n",
            "[Epoch 22/50] [Batch 50/59] [D loss: 0.688880] [G loss: 0.733335]\n",
            "[Epoch 22/50] [Batch 51/59] [D loss: 0.688732] [G loss: 0.739195]\n",
            "[Epoch 22/50] [Batch 52/59] [D loss: 0.688252] [G loss: 0.747127]\n",
            "[Epoch 22/50] [Batch 53/59] [D loss: 0.686080] [G loss: 0.754076]\n",
            "[Epoch 22/50] [Batch 54/59] [D loss: 0.684800] [G loss: 0.761801]\n",
            "[Epoch 22/50] [Batch 55/59] [D loss: 0.684793] [G loss: 0.770829]\n",
            "[Epoch 22/50] [Batch 56/59] [D loss: 0.684307] [G loss: 0.775202]\n",
            "[Epoch 22/50] [Batch 57/59] [D loss: 0.682775] [G loss: 0.783368]\n",
            "[Epoch 22/50] [Batch 58/59] [D loss: 0.683983] [G loss: 0.786612]\n",
            "[Epoch 23/50] [Batch 0/59] [D loss: 0.683953] [G loss: 0.787596]\n",
            "[Epoch 23/50] [Batch 1/59] [D loss: 0.686614] [G loss: 0.786463]\n",
            "[Epoch 23/50] [Batch 2/59] [D loss: 0.687994] [G loss: 0.781963]\n",
            "[Epoch 23/50] [Batch 3/59] [D loss: 0.690758] [G loss: 0.771411]\n",
            "[Epoch 23/50] [Batch 4/59] [D loss: 0.692170] [G loss: 0.760236]\n",
            "[Epoch 23/50] [Batch 5/59] [D loss: 0.694366] [G loss: 0.747009]\n",
            "[Epoch 23/50] [Batch 6/59] [D loss: 0.695535] [G loss: 0.730363]\n",
            "[Epoch 23/50] [Batch 7/59] [D loss: 0.698825] [G loss: 0.718774]\n",
            "[Epoch 23/50] [Batch 8/59] [D loss: 0.701600] [G loss: 0.706089]\n",
            "[Epoch 23/50] [Batch 9/59] [D loss: 0.700031] [G loss: 0.695413]\n",
            "[Epoch 23/50] [Batch 10/59] [D loss: 0.699444] [G loss: 0.687654]\n",
            "[Epoch 23/50] [Batch 11/59] [D loss: 0.698045] [G loss: 0.681614]\n",
            "[Epoch 23/50] [Batch 12/59] [D loss: 0.696004] [G loss: 0.678934]\n",
            "[Epoch 23/50] [Batch 13/59] [D loss: 0.695057] [G loss: 0.675808]\n",
            "[Epoch 23/50] [Batch 14/59] [D loss: 0.693852] [G loss: 0.674951]\n",
            "[Epoch 23/50] [Batch 15/59] [D loss: 0.692513] [G loss: 0.673905]\n",
            "[Epoch 23/50] [Batch 16/59] [D loss: 0.691486] [G loss: 0.673298]\n",
            "[Epoch 23/50] [Batch 17/59] [D loss: 0.689529] [G loss: 0.672796]\n",
            "[Epoch 23/50] [Batch 18/59] [D loss: 0.688845] [G loss: 0.671327]\n",
            "[Epoch 23/50] [Batch 19/59] [D loss: 0.687558] [G loss: 0.670887]\n",
            "[Epoch 23/50] [Batch 20/59] [D loss: 0.686647] [G loss: 0.668881]\n",
            "[Epoch 23/50] [Batch 21/59] [D loss: 0.685371] [G loss: 0.667012]\n",
            "[Epoch 23/50] [Batch 22/59] [D loss: 0.684361] [G loss: 0.664594]\n",
            "[Epoch 23/50] [Batch 23/59] [D loss: 0.684716] [G loss: 0.660790]\n",
            "[Epoch 23/50] [Batch 24/59] [D loss: 0.684281] [G loss: 0.657508]\n",
            "[Epoch 23/50] [Batch 25/59] [D loss: 0.684904] [G loss: 0.652895]\n",
            "[Epoch 23/50] [Batch 26/59] [D loss: 0.684188] [G loss: 0.649530]\n",
            "[Epoch 23/50] [Batch 27/59] [D loss: 0.687505] [G loss: 0.644233]\n",
            "[Epoch 23/50] [Batch 28/59] [D loss: 0.686657] [G loss: 0.641502]\n",
            "[Epoch 23/50] [Batch 29/59] [D loss: 0.688344] [G loss: 0.639374]\n",
            "[Epoch 23/50] [Batch 30/59] [D loss: 0.690443] [G loss: 0.638264]\n",
            "[Epoch 23/50] [Batch 31/59] [D loss: 0.691613] [G loss: 0.640096]\n",
            "[Epoch 23/50] [Batch 32/59] [D loss: 0.692245] [G loss: 0.645331]\n",
            "[Epoch 23/50] [Batch 33/59] [D loss: 0.692988] [G loss: 0.649008]\n",
            "[Epoch 23/50] [Batch 34/59] [D loss: 0.694128] [G loss: 0.654757]\n",
            "[Epoch 23/50] [Batch 35/59] [D loss: 0.695552] [G loss: 0.660291]\n",
            "[Epoch 23/50] [Batch 36/59] [D loss: 0.693827] [G loss: 0.671166]\n",
            "[Epoch 23/50] [Batch 37/59] [D loss: 0.694351] [G loss: 0.678915]\n",
            "[Epoch 23/50] [Batch 38/59] [D loss: 0.693687] [G loss: 0.686661]\n",
            "[Epoch 23/50] [Batch 39/59] [D loss: 0.693598] [G loss: 0.690406]\n",
            "[Epoch 23/50] [Batch 40/59] [D loss: 0.693679] [G loss: 0.696697]\n",
            "[Epoch 23/50] [Batch 41/59] [D loss: 0.694644] [G loss: 0.701004]\n",
            "[Epoch 23/50] [Batch 42/59] [D loss: 0.694522] [G loss: 0.705777]\n",
            "[Epoch 23/50] [Batch 43/59] [D loss: 0.695048] [G loss: 0.709533]\n",
            "[Epoch 23/50] [Batch 44/59] [D loss: 0.693674] [G loss: 0.714183]\n",
            "[Epoch 23/50] [Batch 45/59] [D loss: 0.695052] [G loss: 0.713580]\n",
            "[Epoch 23/50] [Batch 46/59] [D loss: 0.694710] [G loss: 0.717241]\n",
            "[Epoch 23/50] [Batch 47/59] [D loss: 0.693836] [G loss: 0.719133]\n",
            "[Epoch 23/50] [Batch 48/59] [D loss: 0.693671] [G loss: 0.720709]\n",
            "[Epoch 23/50] [Batch 49/59] [D loss: 0.692651] [G loss: 0.723406]\n",
            "[Epoch 23/50] [Batch 50/59] [D loss: 0.692284] [G loss: 0.724337]\n",
            "[Epoch 23/50] [Batch 51/59] [D loss: 0.691352] [G loss: 0.726549]\n",
            "[Epoch 23/50] [Batch 52/59] [D loss: 0.692093] [G loss: 0.727007]\n",
            "[Epoch 23/50] [Batch 53/59] [D loss: 0.690513] [G loss: 0.727653]\n",
            "[Epoch 23/50] [Batch 54/59] [D loss: 0.691722] [G loss: 0.728544]\n",
            "[Epoch 23/50] [Batch 55/59] [D loss: 0.690029] [G loss: 0.729092]\n",
            "[Epoch 23/50] [Batch 56/59] [D loss: 0.690456] [G loss: 0.727900]\n",
            "[Epoch 23/50] [Batch 57/59] [D loss: 0.690616] [G loss: 0.726532]\n",
            "[Epoch 23/50] [Batch 58/59] [D loss: 0.691646] [G loss: 0.726408]\n",
            "[Epoch 24/50] [Batch 0/59] [D loss: 0.692015] [G loss: 0.718373]\n",
            "[Epoch 24/50] [Batch 1/59] [D loss: 0.692830] [G loss: 0.715205]\n",
            "[Epoch 24/50] [Batch 2/59] [D loss: 0.692085] [G loss: 0.710089]\n",
            "[Epoch 24/50] [Batch 3/59] [D loss: 0.692924] [G loss: 0.703242]\n",
            "[Epoch 24/50] [Batch 4/59] [D loss: 0.693357] [G loss: 0.695620]\n",
            "[Epoch 24/50] [Batch 5/59] [D loss: 0.692493] [G loss: 0.690884]\n",
            "[Epoch 24/50] [Batch 6/59] [D loss: 0.692323] [G loss: 0.684629]\n",
            "[Epoch 24/50] [Batch 7/59] [D loss: 0.691488] [G loss: 0.680254]\n",
            "[Epoch 24/50] [Batch 8/59] [D loss: 0.691234] [G loss: 0.675591]\n",
            "[Epoch 24/50] [Batch 9/59] [D loss: 0.690295] [G loss: 0.673445]\n",
            "[Epoch 24/50] [Batch 10/59] [D loss: 0.690716] [G loss: 0.669604]\n",
            "[Epoch 24/50] [Batch 11/59] [D loss: 0.689121] [G loss: 0.667535]\n",
            "[Epoch 24/50] [Batch 12/59] [D loss: 0.690097] [G loss: 0.665393]\n",
            "[Epoch 24/50] [Batch 13/59] [D loss: 0.690292] [G loss: 0.662199]\n",
            "[Epoch 24/50] [Batch 14/59] [D loss: 0.689736] [G loss: 0.662436]\n",
            "[Epoch 24/50] [Batch 15/59] [D loss: 0.690317] [G loss: 0.659036]\n",
            "[Epoch 24/50] [Batch 16/59] [D loss: 0.688977] [G loss: 0.660378]\n",
            "[Epoch 24/50] [Batch 17/59] [D loss: 0.692165] [G loss: 0.657046]\n",
            "[Epoch 24/50] [Batch 18/59] [D loss: 0.691601] [G loss: 0.659003]\n",
            "[Epoch 24/50] [Batch 19/59] [D loss: 0.691778] [G loss: 0.661523]\n",
            "[Epoch 24/50] [Batch 20/59] [D loss: 0.692563] [G loss: 0.662921]\n",
            "[Epoch 24/50] [Batch 21/59] [D loss: 0.692381] [G loss: 0.667521]\n",
            "[Epoch 24/50] [Batch 22/59] [D loss: 0.691911] [G loss: 0.670505]\n",
            "[Epoch 24/50] [Batch 23/59] [D loss: 0.692796] [G loss: 0.675545]\n",
            "[Epoch 24/50] [Batch 24/59] [D loss: 0.691771] [G loss: 0.681504]\n",
            "[Epoch 24/50] [Batch 25/59] [D loss: 0.691431] [G loss: 0.685862]\n",
            "[Epoch 24/50] [Batch 26/59] [D loss: 0.690777] [G loss: 0.692364]\n",
            "[Epoch 24/50] [Batch 27/59] [D loss: 0.691191] [G loss: 0.697980]\n",
            "[Epoch 24/50] [Batch 28/59] [D loss: 0.689555] [G loss: 0.704496]\n",
            "[Epoch 24/50] [Batch 29/59] [D loss: 0.689569] [G loss: 0.711070]\n",
            "[Epoch 24/50] [Batch 30/59] [D loss: 0.689271] [G loss: 0.716516]\n",
            "[Epoch 24/50] [Batch 31/59] [D loss: 0.689304] [G loss: 0.722480]\n",
            "[Epoch 24/50] [Batch 32/59] [D loss: 0.689639] [G loss: 0.726411]\n",
            "[Epoch 24/50] [Batch 33/59] [D loss: 0.690206] [G loss: 0.728558]\n",
            "[Epoch 24/50] [Batch 34/59] [D loss: 0.690451] [G loss: 0.731351]\n",
            "[Epoch 24/50] [Batch 35/59] [D loss: 0.692437] [G loss: 0.729820]\n",
            "[Epoch 24/50] [Batch 36/59] [D loss: 0.693436] [G loss: 0.727937]\n",
            "[Epoch 24/50] [Batch 37/59] [D loss: 0.693122] [G loss: 0.726747]\n",
            "[Epoch 24/50] [Batch 38/59] [D loss: 0.694325] [G loss: 0.723021]\n",
            "[Epoch 24/50] [Batch 39/59] [D loss: 0.695017] [G loss: 0.717567]\n",
            "[Epoch 24/50] [Batch 40/59] [D loss: 0.693284] [G loss: 0.715486]\n",
            "[Epoch 24/50] [Batch 41/59] [D loss: 0.692245] [G loss: 0.713050]\n",
            "[Epoch 24/50] [Batch 42/59] [D loss: 0.691456] [G loss: 0.713234]\n",
            "[Epoch 24/50] [Batch 43/59] [D loss: 0.690633] [G loss: 0.712916]\n",
            "[Epoch 24/50] [Batch 44/59] [D loss: 0.688720] [G loss: 0.713437]\n",
            "[Epoch 24/50] [Batch 45/59] [D loss: 0.687618] [G loss: 0.714688]\n",
            "[Epoch 24/50] [Batch 46/59] [D loss: 0.687159] [G loss: 0.711972]\n",
            "[Epoch 24/50] [Batch 47/59] [D loss: 0.687436] [G loss: 0.706729]\n",
            "[Epoch 24/50] [Batch 48/59] [D loss: 0.687474] [G loss: 0.704205]\n",
            "[Epoch 24/50] [Batch 49/59] [D loss: 0.685077] [G loss: 0.696742]\n",
            "[Epoch 24/50] [Batch 50/59] [D loss: 0.685167] [G loss: 0.686681]\n",
            "[Epoch 24/50] [Batch 51/59] [D loss: 0.683803] [G loss: 0.681216]\n",
            "[Epoch 24/50] [Batch 52/59] [D loss: 0.680987] [G loss: 0.670462]\n",
            "[Epoch 24/50] [Batch 53/59] [D loss: 0.682415] [G loss: 0.660580]\n",
            "[Epoch 24/50] [Batch 54/59] [D loss: 0.683013] [G loss: 0.649320]\n",
            "[Epoch 24/50] [Batch 55/59] [D loss: 0.688709] [G loss: 0.641622]\n",
            "[Epoch 24/50] [Batch 56/59] [D loss: 0.691389] [G loss: 0.633243]\n",
            "[Epoch 24/50] [Batch 57/59] [D loss: 0.696046] [G loss: 0.632741]\n",
            "[Epoch 24/50] [Batch 58/59] [D loss: 0.699355] [G loss: 0.636886]\n",
            "[Epoch 25/50] [Batch 0/59] [D loss: 0.699246] [G loss: 0.644176]\n",
            "[Epoch 25/50] [Batch 1/59] [D loss: 0.697926] [G loss: 0.654029]\n",
            "[Epoch 25/50] [Batch 2/59] [D loss: 0.697424] [G loss: 0.665961]\n",
            "[Epoch 25/50] [Batch 3/59] [D loss: 0.696226] [G loss: 0.681567]\n",
            "[Epoch 25/50] [Batch 4/59] [D loss: 0.693823] [G loss: 0.694683]\n",
            "[Epoch 25/50] [Batch 5/59] [D loss: 0.692016] [G loss: 0.710361]\n",
            "[Epoch 25/50] [Batch 6/59] [D loss: 0.689491] [G loss: 0.724896]\n",
            "[Epoch 25/50] [Batch 7/59] [D loss: 0.689521] [G loss: 0.738046]\n",
            "[Epoch 25/50] [Batch 8/59] [D loss: 0.688492] [G loss: 0.747771]\n",
            "[Epoch 25/50] [Batch 9/59] [D loss: 0.685551] [G loss: 0.758720]\n",
            "[Epoch 25/50] [Batch 10/59] [D loss: 0.686900] [G loss: 0.764331]\n",
            "[Epoch 25/50] [Batch 11/59] [D loss: 0.686005] [G loss: 0.771621]\n",
            "[Epoch 25/50] [Batch 12/59] [D loss: 0.687733] [G loss: 0.771581]\n",
            "[Epoch 25/50] [Batch 13/59] [D loss: 0.689491] [G loss: 0.768857]\n",
            "[Epoch 25/50] [Batch 14/59] [D loss: 0.689402] [G loss: 0.758122]\n",
            "[Epoch 25/50] [Batch 15/59] [D loss: 0.690636] [G loss: 0.751989]\n",
            "[Epoch 25/50] [Batch 16/59] [D loss: 0.694283] [G loss: 0.736966]\n",
            "[Epoch 25/50] [Batch 17/59] [D loss: 0.693770] [G loss: 0.717676]\n",
            "[Epoch 25/50] [Batch 18/59] [D loss: 0.695431] [G loss: 0.699555]\n",
            "[Epoch 25/50] [Batch 19/59] [D loss: 0.694858] [G loss: 0.686043]\n",
            "[Epoch 25/50] [Batch 20/59] [D loss: 0.689871] [G loss: 0.677849]\n",
            "[Epoch 25/50] [Batch 21/59] [D loss: 0.685751] [G loss: 0.670333]\n",
            "[Epoch 25/50] [Batch 22/59] [D loss: 0.682187] [G loss: 0.661433]\n",
            "[Epoch 25/50] [Batch 23/59] [D loss: 0.677270] [G loss: 0.653065]\n",
            "[Epoch 25/50] [Batch 24/59] [D loss: 0.676908] [G loss: 0.641776]\n",
            "[Epoch 25/50] [Batch 25/59] [D loss: 0.678098] [G loss: 0.632729]\n",
            "[Epoch 25/50] [Batch 26/59] [D loss: 0.682517] [G loss: 0.624970]\n",
            "[Epoch 25/50] [Batch 27/59] [D loss: 0.687467] [G loss: 0.623471]\n",
            "[Epoch 25/50] [Batch 28/59] [D loss: 0.690204] [G loss: 0.630177]\n",
            "[Epoch 25/50] [Batch 29/59] [D loss: 0.688171] [G loss: 0.650944]\n",
            "[Epoch 25/50] [Batch 30/59] [D loss: 0.691480] [G loss: 0.666679]\n",
            "[Epoch 25/50] [Batch 31/59] [D loss: 0.693071] [G loss: 0.685513]\n",
            "[Epoch 25/50] [Batch 32/59] [D loss: 0.694536] [G loss: 0.701642]\n",
            "[Epoch 25/50] [Batch 33/59] [D loss: 0.698041] [G loss: 0.709758]\n",
            "[Epoch 25/50] [Batch 34/59] [D loss: 0.699724] [G loss: 0.719057]\n",
            "[Epoch 25/50] [Batch 35/59] [D loss: 0.698209] [G loss: 0.725841]\n",
            "[Epoch 25/50] [Batch 36/59] [D loss: 0.699854] [G loss: 0.730369]\n",
            "[Epoch 25/50] [Batch 37/59] [D loss: 0.698055] [G loss: 0.731388]\n",
            "[Epoch 25/50] [Batch 38/59] [D loss: 0.697948] [G loss: 0.735159]\n",
            "[Epoch 25/50] [Batch 39/59] [D loss: 0.696424] [G loss: 0.733852]\n",
            "[Epoch 25/50] [Batch 40/59] [D loss: 0.693072] [G loss: 0.733941]\n",
            "[Epoch 25/50] [Batch 41/59] [D loss: 0.691344] [G loss: 0.733069]\n",
            "[Epoch 25/50] [Batch 42/59] [D loss: 0.687586] [G loss: 0.733775]\n",
            "[Epoch 25/50] [Batch 43/59] [D loss: 0.687524] [G loss: 0.732078]\n",
            "[Epoch 25/50] [Batch 44/59] [D loss: 0.686416] [G loss: 0.726306]\n",
            "[Epoch 25/50] [Batch 45/59] [D loss: 0.684406] [G loss: 0.723214]\n",
            "[Epoch 25/50] [Batch 46/59] [D loss: 0.684511] [G loss: 0.720029]\n",
            "[Epoch 25/50] [Batch 47/59] [D loss: 0.685429] [G loss: 0.715614]\n",
            "[Epoch 25/50] [Batch 48/59] [D loss: 0.686524] [G loss: 0.708429]\n",
            "[Epoch 25/50] [Batch 49/59] [D loss: 0.686295] [G loss: 0.701183]\n",
            "[Epoch 25/50] [Batch 50/59] [D loss: 0.684608] [G loss: 0.695888]\n",
            "[Epoch 25/50] [Batch 51/59] [D loss: 0.686595] [G loss: 0.688691]\n",
            "[Epoch 25/50] [Batch 52/59] [D loss: 0.685080] [G loss: 0.687216]\n",
            "[Epoch 25/50] [Batch 53/59] [D loss: 0.685498] [G loss: 0.679922]\n",
            "[Epoch 25/50] [Batch 54/59] [D loss: 0.686862] [G loss: 0.676637]\n",
            "[Epoch 25/50] [Batch 55/59] [D loss: 0.686731] [G loss: 0.672257]\n",
            "[Epoch 25/50] [Batch 56/59] [D loss: 0.689408] [G loss: 0.667767]\n",
            "[Epoch 25/50] [Batch 57/59] [D loss: 0.689313] [G loss: 0.672713]\n",
            "[Epoch 25/50] [Batch 58/59] [D loss: 0.688272] [G loss: 0.673349]\n",
            "[Epoch 26/50] [Batch 0/59] [D loss: 0.690762] [G loss: 0.669464]\n",
            "[Epoch 26/50] [Batch 1/59] [D loss: 0.691483] [G loss: 0.674007]\n",
            "[Epoch 26/50] [Batch 2/59] [D loss: 0.689927] [G loss: 0.675032]\n",
            "[Epoch 26/50] [Batch 3/59] [D loss: 0.693024] [G loss: 0.673920]\n",
            "[Epoch 26/50] [Batch 4/59] [D loss: 0.692544] [G loss: 0.669444]\n",
            "[Epoch 26/50] [Batch 5/59] [D loss: 0.693222] [G loss: 0.671383]\n",
            "[Epoch 26/50] [Batch 6/59] [D loss: 0.693482] [G loss: 0.671156]\n",
            "[Epoch 26/50] [Batch 7/59] [D loss: 0.692697] [G loss: 0.671138]\n",
            "[Epoch 26/50] [Batch 8/59] [D loss: 0.694651] [G loss: 0.673669]\n",
            "[Epoch 26/50] [Batch 9/59] [D loss: 0.693185] [G loss: 0.678111]\n",
            "[Epoch 26/50] [Batch 10/59] [D loss: 0.694419] [G loss: 0.681932]\n",
            "[Epoch 26/50] [Batch 11/59] [D loss: 0.694292] [G loss: 0.678345]\n",
            "[Epoch 26/50] [Batch 12/59] [D loss: 0.695346] [G loss: 0.682151]\n",
            "[Epoch 26/50] [Batch 13/59] [D loss: 0.697379] [G loss: 0.683176]\n",
            "[Epoch 26/50] [Batch 14/59] [D loss: 0.697297] [G loss: 0.689288]\n",
            "[Epoch 26/50] [Batch 15/59] [D loss: 0.697370] [G loss: 0.695348]\n",
            "[Epoch 26/50] [Batch 16/59] [D loss: 0.699606] [G loss: 0.700929]\n",
            "[Epoch 26/50] [Batch 17/59] [D loss: 0.698012] [G loss: 0.705549]\n",
            "[Epoch 26/50] [Batch 18/59] [D loss: 0.694559] [G loss: 0.716565]\n",
            "[Epoch 26/50] [Batch 19/59] [D loss: 0.689439] [G loss: 0.727015]\n",
            "[Epoch 26/50] [Batch 20/59] [D loss: 0.689272] [G loss: 0.729601]\n",
            "[Epoch 26/50] [Batch 21/59] [D loss: 0.687351] [G loss: 0.734810]\n",
            "[Epoch 26/50] [Batch 22/59] [D loss: 0.683797] [G loss: 0.731961]\n",
            "[Epoch 26/50] [Batch 23/59] [D loss: 0.684168] [G loss: 0.732533]\n",
            "[Epoch 26/50] [Batch 24/59] [D loss: 0.682752] [G loss: 0.725881]\n",
            "[Epoch 26/50] [Batch 25/59] [D loss: 0.681484] [G loss: 0.712161]\n",
            "[Epoch 26/50] [Batch 26/59] [D loss: 0.675916] [G loss: 0.702389]\n",
            "[Epoch 26/50] [Batch 27/59] [D loss: 0.667430] [G loss: 0.689662]\n",
            "[Epoch 26/50] [Batch 28/59] [D loss: 0.661895] [G loss: 0.672823]\n",
            "[Epoch 26/50] [Batch 29/59] [D loss: 0.662296] [G loss: 0.659000]\n",
            "[Epoch 26/50] [Batch 30/59] [D loss: 0.666436] [G loss: 0.635594]\n",
            "[Epoch 26/50] [Batch 31/59] [D loss: 0.675178] [G loss: 0.607843]\n",
            "[Epoch 26/50] [Batch 32/59] [D loss: 0.688401] [G loss: 0.606567]\n",
            "[Epoch 26/50] [Batch 33/59] [D loss: 0.705549] [G loss: 0.628039]\n",
            "[Epoch 26/50] [Batch 34/59] [D loss: 0.707513] [G loss: 0.656498]\n",
            "[Epoch 26/50] [Batch 35/59] [D loss: 0.708986] [G loss: 0.695004]\n",
            "[Epoch 26/50] [Batch 36/59] [D loss: 0.714373] [G loss: 0.722375]\n",
            "[Epoch 26/50] [Batch 37/59] [D loss: 0.713914] [G loss: 0.742089]\n",
            "[Epoch 26/50] [Batch 38/59] [D loss: 0.712084] [G loss: 0.741318]\n",
            "[Epoch 26/50] [Batch 39/59] [D loss: 0.705454] [G loss: 0.747698]\n",
            "[Epoch 26/50] [Batch 40/59] [D loss: 0.697215] [G loss: 0.746877]\n",
            "[Epoch 26/50] [Batch 41/59] [D loss: 0.693776] [G loss: 0.748942]\n",
            "[Epoch 26/50] [Batch 42/59] [D loss: 0.688084] [G loss: 0.744055]\n",
            "[Epoch 26/50] [Batch 43/59] [D loss: 0.687007] [G loss: 0.742676]\n",
            "[Epoch 26/50] [Batch 44/59] [D loss: 0.685884] [G loss: 0.734553]\n",
            "[Epoch 26/50] [Batch 45/59] [D loss: 0.683191] [G loss: 0.718614]\n",
            "[Epoch 26/50] [Batch 46/59] [D loss: 0.682095] [G loss: 0.707553]\n",
            "[Epoch 26/50] [Batch 47/59] [D loss: 0.679773] [G loss: 0.696948]\n",
            "[Epoch 26/50] [Batch 48/59] [D loss: 0.676617] [G loss: 0.686270]\n",
            "[Epoch 26/50] [Batch 49/59] [D loss: 0.670888] [G loss: 0.673806]\n",
            "[Epoch 26/50] [Batch 50/59] [D loss: 0.672492] [G loss: 0.658968]\n",
            "[Epoch 26/50] [Batch 51/59] [D loss: 0.674009] [G loss: 0.650068]\n",
            "[Epoch 26/50] [Batch 52/59] [D loss: 0.675777] [G loss: 0.638719]\n",
            "[Epoch 26/50] [Batch 53/59] [D loss: 0.683843] [G loss: 0.637321]\n",
            "[Epoch 26/50] [Batch 54/59] [D loss: 0.692409] [G loss: 0.639887]\n",
            "[Epoch 26/50] [Batch 55/59] [D loss: 0.698820] [G loss: 0.650454]\n",
            "[Epoch 26/50] [Batch 56/59] [D loss: 0.702393] [G loss: 0.662064]\n",
            "[Epoch 26/50] [Batch 57/59] [D loss: 0.706282] [G loss: 0.678128]\n",
            "[Epoch 26/50] [Batch 58/59] [D loss: 0.708836] [G loss: 0.692692]\n",
            "[Epoch 27/50] [Batch 0/59] [D loss: 0.704047] [G loss: 0.719252]\n",
            "[Epoch 27/50] [Batch 1/59] [D loss: 0.702642] [G loss: 0.734331]\n",
            "[Epoch 27/50] [Batch 2/59] [D loss: 0.695029] [G loss: 0.757878]\n",
            "[Epoch 27/50] [Batch 3/59] [D loss: 0.691905] [G loss: 0.773839]\n",
            "[Epoch 27/50] [Batch 4/59] [D loss: 0.687537] [G loss: 0.780493]\n",
            "[Epoch 27/50] [Batch 5/59] [D loss: 0.684031] [G loss: 0.792404]\n",
            "[Epoch 27/50] [Batch 6/59] [D loss: 0.686810] [G loss: 0.792935]\n",
            "[Epoch 27/50] [Batch 7/59] [D loss: 0.688634] [G loss: 0.778800]\n",
            "[Epoch 27/50] [Batch 8/59] [D loss: 0.693874] [G loss: 0.760850]\n",
            "[Epoch 27/50] [Batch 9/59] [D loss: 0.696285] [G loss: 0.734626]\n",
            "[Epoch 27/50] [Batch 10/59] [D loss: 0.695363] [G loss: 0.718523]\n",
            "[Epoch 27/50] [Batch 11/59] [D loss: 0.692054] [G loss: 0.697730]\n",
            "[Epoch 27/50] [Batch 12/59] [D loss: 0.687592] [G loss: 0.683766]\n",
            "[Epoch 27/50] [Batch 13/59] [D loss: 0.681233] [G loss: 0.671944]\n",
            "[Epoch 27/50] [Batch 14/59] [D loss: 0.677359] [G loss: 0.659726]\n",
            "[Epoch 27/50] [Batch 15/59] [D loss: 0.676343] [G loss: 0.644919]\n",
            "[Epoch 27/50] [Batch 16/59] [D loss: 0.680294] [G loss: 0.628110]\n",
            "[Epoch 27/50] [Batch 17/59] [D loss: 0.684646] [G loss: 0.618986]\n",
            "[Epoch 27/50] [Batch 18/59] [D loss: 0.691005] [G loss: 0.611826]\n",
            "[Epoch 27/50] [Batch 19/59] [D loss: 0.690859] [G loss: 0.627995]\n",
            "[Epoch 27/50] [Batch 20/59] [D loss: 0.692728] [G loss: 0.638640]\n",
            "[Epoch 27/50] [Batch 21/59] [D loss: 0.693617] [G loss: 0.660795]\n",
            "[Epoch 27/50] [Batch 22/59] [D loss: 0.691731] [G loss: 0.685337]\n",
            "[Epoch 27/50] [Batch 23/59] [D loss: 0.690484] [G loss: 0.710935]\n",
            "[Epoch 27/50] [Batch 24/59] [D loss: 0.686988] [G loss: 0.743493]\n",
            "[Epoch 27/50] [Batch 25/59] [D loss: 0.683088] [G loss: 0.772809]\n",
            "[Epoch 27/50] [Batch 26/59] [D loss: 0.684234] [G loss: 0.793674]\n",
            "[Epoch 27/50] [Batch 27/59] [D loss: 0.686245] [G loss: 0.814067]\n",
            "[Epoch 27/50] [Batch 28/59] [D loss: 0.685707] [G loss: 0.809248]\n",
            "[Epoch 27/50] [Batch 29/59] [D loss: 0.694042] [G loss: 0.795198]\n",
            "[Epoch 27/50] [Batch 30/59] [D loss: 0.699519] [G loss: 0.767918]\n",
            "[Epoch 27/50] [Batch 31/59] [D loss: 0.702995] [G loss: 0.731357]\n",
            "[Epoch 27/50] [Batch 32/59] [D loss: 0.699992] [G loss: 0.702334]\n",
            "[Epoch 27/50] [Batch 33/59] [D loss: 0.689918] [G loss: 0.683367]\n",
            "[Epoch 27/50] [Batch 34/59] [D loss: 0.684139] [G loss: 0.667990]\n",
            "[Epoch 27/50] [Batch 35/59] [D loss: 0.676790] [G loss: 0.659312]\n",
            "[Epoch 27/50] [Batch 36/59] [D loss: 0.671491] [G loss: 0.648115]\n",
            "[Epoch 27/50] [Batch 37/59] [D loss: 0.671846] [G loss: 0.633173]\n",
            "[Epoch 27/50] [Batch 38/59] [D loss: 0.670624] [G loss: 0.628803]\n",
            "[Epoch 27/50] [Batch 39/59] [D loss: 0.672606] [G loss: 0.623238]\n",
            "[Epoch 27/50] [Batch 40/59] [D loss: 0.674750] [G loss: 0.628637]\n",
            "[Epoch 27/50] [Batch 41/59] [D loss: 0.678271] [G loss: 0.638918]\n",
            "[Epoch 27/50] [Batch 42/59] [D loss: 0.681659] [G loss: 0.660568]\n",
            "[Epoch 27/50] [Batch 43/59] [D loss: 0.684353] [G loss: 0.685576]\n",
            "[Epoch 27/50] [Batch 44/59] [D loss: 0.691666] [G loss: 0.705202]\n",
            "[Epoch 27/50] [Batch 45/59] [D loss: 0.700708] [G loss: 0.716914]\n",
            "[Epoch 27/50] [Batch 46/59] [D loss: 0.704367] [G loss: 0.727386]\n",
            "[Epoch 27/50] [Batch 47/59] [D loss: 0.707755] [G loss: 0.727928]\n",
            "[Epoch 27/50] [Batch 48/59] [D loss: 0.708461] [G loss: 0.725909]\n",
            "[Epoch 27/50] [Batch 49/59] [D loss: 0.703835] [G loss: 0.721818]\n",
            "[Epoch 27/50] [Batch 50/59] [D loss: 0.699048] [G loss: 0.726837]\n",
            "[Epoch 27/50] [Batch 51/59] [D loss: 0.690795] [G loss: 0.733878]\n",
            "[Epoch 27/50] [Batch 52/59] [D loss: 0.685796] [G loss: 0.730764]\n",
            "[Epoch 27/50] [Batch 53/59] [D loss: 0.680508] [G loss: 0.722893]\n",
            "[Epoch 27/50] [Batch 54/59] [D loss: 0.674541] [G loss: 0.715060]\n",
            "[Epoch 27/50] [Batch 55/59] [D loss: 0.667746] [G loss: 0.704697]\n",
            "[Epoch 27/50] [Batch 56/59] [D loss: 0.660956] [G loss: 0.696592]\n",
            "[Epoch 27/50] [Batch 57/59] [D loss: 0.656779] [G loss: 0.690075]\n",
            "[Epoch 27/50] [Batch 58/59] [D loss: 0.651732] [G loss: 0.678680]\n",
            "[Epoch 28/50] [Batch 0/59] [D loss: 0.651431] [G loss: 0.673325]\n",
            "[Epoch 28/50] [Batch 1/59] [D loss: 0.651914] [G loss: 0.662039]\n",
            "[Epoch 28/50] [Batch 2/59] [D loss: 0.660901] [G loss: 0.660207]\n",
            "[Epoch 28/50] [Batch 3/59] [D loss: 0.671504] [G loss: 0.672478]\n",
            "[Epoch 28/50] [Batch 4/59] [D loss: 0.684930] [G loss: 0.678682]\n",
            "[Epoch 28/50] [Batch 5/59] [D loss: 0.700423] [G loss: 0.703557]\n",
            "[Epoch 28/50] [Batch 6/59] [D loss: 0.713115] [G loss: 0.710556]\n",
            "[Epoch 28/50] [Batch 7/59] [D loss: 0.729165] [G loss: 0.719555]\n",
            "[Epoch 28/50] [Batch 8/59] [D loss: 0.729029] [G loss: 0.724516]\n",
            "[Epoch 28/50] [Batch 9/59] [D loss: 0.720343] [G loss: 0.741649]\n",
            "[Epoch 28/50] [Batch 10/59] [D loss: 0.708294] [G loss: 0.753432]\n",
            "[Epoch 28/50] [Batch 11/59] [D loss: 0.696790] [G loss: 0.767313]\n",
            "[Epoch 28/50] [Batch 12/59] [D loss: 0.685459] [G loss: 0.771695]\n",
            "[Epoch 28/50] [Batch 13/59] [D loss: 0.677246] [G loss: 0.764181]\n",
            "[Epoch 28/50] [Batch 14/59] [D loss: 0.667770] [G loss: 0.759162]\n",
            "[Epoch 28/50] [Batch 15/59] [D loss: 0.663109] [G loss: 0.741570]\n",
            "[Epoch 28/50] [Batch 16/59] [D loss: 0.649929] [G loss: 0.720987]\n",
            "[Epoch 28/50] [Batch 17/59] [D loss: 0.648575] [G loss: 0.696612]\n",
            "[Epoch 28/50] [Batch 18/59] [D loss: 0.641527] [G loss: 0.673155]\n",
            "[Epoch 28/50] [Batch 19/59] [D loss: 0.639053] [G loss: 0.653198]\n",
            "[Epoch 28/50] [Batch 20/59] [D loss: 0.650320] [G loss: 0.620702]\n",
            "[Epoch 28/50] [Batch 21/59] [D loss: 0.662481] [G loss: 0.635281]\n",
            "[Epoch 28/50] [Batch 22/59] [D loss: 0.669635] [G loss: 0.665291]\n",
            "[Epoch 28/50] [Batch 23/59] [D loss: 0.689242] [G loss: 0.676535]\n",
            "[Epoch 28/50] [Batch 24/59] [D loss: 0.706680] [G loss: 0.680580]\n",
            "[Epoch 28/50] [Batch 25/59] [D loss: 0.720644] [G loss: 0.675113]\n",
            "[Epoch 28/50] [Batch 26/59] [D loss: 0.721868] [G loss: 0.670319]\n",
            "[Epoch 28/50] [Batch 27/59] [D loss: 0.718937] [G loss: 0.672491]\n",
            "[Epoch 28/50] [Batch 28/59] [D loss: 0.702614] [G loss: 0.684662]\n",
            "[Epoch 28/50] [Batch 29/59] [D loss: 0.691805] [G loss: 0.694817]\n",
            "[Epoch 28/50] [Batch 30/59] [D loss: 0.676448] [G loss: 0.719524]\n",
            "[Epoch 28/50] [Batch 31/59] [D loss: 0.665080] [G loss: 0.718460]\n",
            "[Epoch 28/50] [Batch 32/59] [D loss: 0.660609] [G loss: 0.724699]\n",
            "[Epoch 28/50] [Batch 33/59] [D loss: 0.658800] [G loss: 0.721508]\n",
            "[Epoch 28/50] [Batch 34/59] [D loss: 0.666111] [G loss: 0.714576]\n",
            "[Epoch 28/50] [Batch 35/59] [D loss: 0.674159] [G loss: 0.703069]\n",
            "[Epoch 28/50] [Batch 36/59] [D loss: 0.682048] [G loss: 0.701622]\n",
            "[Epoch 28/50] [Batch 37/59] [D loss: 0.697536] [G loss: 0.681514]\n",
            "[Epoch 28/50] [Batch 38/59] [D loss: 0.705390] [G loss: 0.670471]\n",
            "[Epoch 28/50] [Batch 39/59] [D loss: 0.710144] [G loss: 0.659157]\n",
            "[Epoch 28/50] [Batch 40/59] [D loss: 0.709545] [G loss: 0.655613]\n",
            "[Epoch 28/50] [Batch 41/59] [D loss: 0.710931] [G loss: 0.665747]\n",
            "[Epoch 28/50] [Batch 42/59] [D loss: 0.697492] [G loss: 0.705252]\n",
            "[Epoch 28/50] [Batch 43/59] [D loss: 0.690586] [G loss: 0.749554]\n",
            "[Epoch 28/50] [Batch 44/59] [D loss: 0.678129] [G loss: 0.800014]\n",
            "[Epoch 28/50] [Batch 45/59] [D loss: 0.670801] [G loss: 0.842519]\n",
            "[Epoch 28/50] [Batch 46/59] [D loss: 0.667694] [G loss: 0.845370]\n",
            "[Epoch 28/50] [Batch 47/59] [D loss: 0.669777] [G loss: 0.826608]\n",
            "[Epoch 28/50] [Batch 48/59] [D loss: 0.673363] [G loss: 0.785555]\n",
            "[Epoch 28/50] [Batch 49/59] [D loss: 0.675457] [G loss: 0.733167]\n",
            "[Epoch 28/50] [Batch 50/59] [D loss: 0.677728] [G loss: 0.696907]\n",
            "[Epoch 28/50] [Batch 51/59] [D loss: 0.682340] [G loss: 0.655343]\n",
            "[Epoch 28/50] [Batch 52/59] [D loss: 0.681747] [G loss: 0.634043]\n",
            "[Epoch 28/50] [Batch 53/59] [D loss: 0.689593] [G loss: 0.624152]\n",
            "[Epoch 28/50] [Batch 54/59] [D loss: 0.686103] [G loss: 0.643239]\n",
            "[Epoch 28/50] [Batch 55/59] [D loss: 0.685832] [G loss: 0.668695]\n",
            "[Epoch 28/50] [Batch 56/59] [D loss: 0.679987] [G loss: 0.689056]\n",
            "[Epoch 28/50] [Batch 57/59] [D loss: 0.683482] [G loss: 0.707883]\n",
            "[Epoch 28/50] [Batch 58/59] [D loss: 0.676275] [G loss: 0.730764]\n",
            "[Epoch 29/50] [Batch 0/59] [D loss: 0.676418] [G loss: 0.734781]\n",
            "[Epoch 29/50] [Batch 1/59] [D loss: 0.678503] [G loss: 0.722260]\n",
            "[Epoch 29/50] [Batch 2/59] [D loss: 0.675817] [G loss: 0.707474]\n",
            "[Epoch 29/50] [Batch 3/59] [D loss: 0.675515] [G loss: 0.702147]\n",
            "[Epoch 29/50] [Batch 4/59] [D loss: 0.677710] [G loss: 0.692160]\n",
            "[Epoch 29/50] [Batch 5/59] [D loss: 0.682467] [G loss: 0.682499]\n",
            "[Epoch 29/50] [Batch 6/59] [D loss: 0.677076] [G loss: 0.679140]\n",
            "[Epoch 29/50] [Batch 7/59] [D loss: 0.679453] [G loss: 0.677053]\n",
            "[Epoch 29/50] [Batch 8/59] [D loss: 0.682414] [G loss: 0.669145]\n",
            "[Epoch 29/50] [Batch 9/59] [D loss: 0.680789] [G loss: 0.672328]\n",
            "[Epoch 29/50] [Batch 10/59] [D loss: 0.683050] [G loss: 0.679353]\n",
            "[Epoch 29/50] [Batch 11/59] [D loss: 0.680246] [G loss: 0.693575]\n",
            "[Epoch 29/50] [Batch 12/59] [D loss: 0.676524] [G loss: 0.715528]\n",
            "[Epoch 29/50] [Batch 13/59] [D loss: 0.674210] [G loss: 0.738559]\n",
            "[Epoch 29/50] [Batch 14/59] [D loss: 0.666116] [G loss: 0.754852]\n",
            "[Epoch 29/50] [Batch 15/59] [D loss: 0.667090] [G loss: 0.747390]\n",
            "[Epoch 29/50] [Batch 16/59] [D loss: 0.666893] [G loss: 0.747138]\n",
            "[Epoch 29/50] [Batch 17/59] [D loss: 0.667437] [G loss: 0.726154]\n",
            "[Epoch 29/50] [Batch 18/59] [D loss: 0.669784] [G loss: 0.703193]\n",
            "[Epoch 29/50] [Batch 19/59] [D loss: 0.671142] [G loss: 0.677060]\n",
            "[Epoch 29/50] [Batch 20/59] [D loss: 0.676627] [G loss: 0.650256]\n",
            "[Epoch 29/50] [Batch 21/59] [D loss: 0.681322] [G loss: 0.659778]\n",
            "[Epoch 29/50] [Batch 22/59] [D loss: 0.686727] [G loss: 0.656526]\n",
            "[Epoch 29/50] [Batch 23/59] [D loss: 0.692228] [G loss: 0.686941]\n",
            "[Epoch 29/50] [Batch 24/59] [D loss: 0.687104] [G loss: 0.719200]\n",
            "[Epoch 29/50] [Batch 25/59] [D loss: 0.689882] [G loss: 0.752824]\n",
            "[Epoch 29/50] [Batch 26/59] [D loss: 0.684097] [G loss: 0.745883]\n",
            "[Epoch 29/50] [Batch 27/59] [D loss: 0.679882] [G loss: 0.729936]\n",
            "[Epoch 29/50] [Batch 28/59] [D loss: 0.678521] [G loss: 0.709182]\n",
            "[Epoch 29/50] [Batch 29/59] [D loss: 0.670489] [G loss: 0.690780]\n",
            "[Epoch 29/50] [Batch 30/59] [D loss: 0.663869] [G loss: 0.665582]\n",
            "[Epoch 29/50] [Batch 31/59] [D loss: 0.666270] [G loss: 0.649936]\n",
            "[Epoch 29/50] [Batch 32/59] [D loss: 0.669389] [G loss: 0.664043]\n",
            "[Epoch 29/50] [Batch 33/59] [D loss: 0.658813] [G loss: 0.721418]\n",
            "[Epoch 29/50] [Batch 34/59] [D loss: 0.667403] [G loss: 0.751590]\n",
            "[Epoch 29/50] [Batch 35/59] [D loss: 0.671737] [G loss: 0.765529]\n",
            "[Epoch 29/50] [Batch 36/59] [D loss: 0.673475] [G loss: 0.734105]\n",
            "[Epoch 29/50] [Batch 37/59] [D loss: 0.678644] [G loss: 0.686123]\n",
            "[Epoch 29/50] [Batch 38/59] [D loss: 0.673633] [G loss: 0.662035]\n",
            "[Epoch 29/50] [Batch 39/59] [D loss: 0.687179] [G loss: 0.671536]\n",
            "[Epoch 29/50] [Batch 40/59] [D loss: 0.684667] [G loss: 0.725954]\n",
            "[Epoch 29/50] [Batch 41/59] [D loss: 0.700899] [G loss: 0.749086]\n",
            "[Epoch 29/50] [Batch 42/59] [D loss: 0.695445] [G loss: 0.737919]\n",
            "[Epoch 29/50] [Batch 43/59] [D loss: 0.692403] [G loss: 0.699935]\n",
            "[Epoch 29/50] [Batch 44/59] [D loss: 0.691122] [G loss: 0.664513]\n",
            "[Epoch 29/50] [Batch 45/59] [D loss: 0.686052] [G loss: 0.649538]\n",
            "[Epoch 29/50] [Batch 46/59] [D loss: 0.681358] [G loss: 0.666810]\n",
            "[Epoch 29/50] [Batch 47/59] [D loss: 0.668849] [G loss: 0.707796]\n",
            "[Epoch 29/50] [Batch 48/59] [D loss: 0.659199] [G loss: 0.752091]\n",
            "[Epoch 29/50] [Batch 49/59] [D loss: 0.651428] [G loss: 0.782319]\n",
            "[Epoch 29/50] [Batch 50/59] [D loss: 0.654542] [G loss: 0.778298]\n",
            "[Epoch 29/50] [Batch 51/59] [D loss: 0.648971] [G loss: 0.737501]\n",
            "[Epoch 29/50] [Batch 52/59] [D loss: 0.641656] [G loss: 0.684256]\n",
            "[Epoch 29/50] [Batch 53/59] [D loss: 0.649673] [G loss: 0.660158]\n",
            "[Epoch 29/50] [Batch 54/59] [D loss: 0.652379] [G loss: 0.660932]\n",
            "[Epoch 29/50] [Batch 55/59] [D loss: 0.652951] [G loss: 0.730418]\n",
            "[Epoch 29/50] [Batch 56/59] [D loss: 0.660990] [G loss: 0.790836]\n",
            "[Epoch 29/50] [Batch 57/59] [D loss: 0.666876] [G loss: 0.788420]\n",
            "[Epoch 29/50] [Batch 58/59] [D loss: 0.674660] [G loss: 0.742929]\n",
            "[Epoch 30/50] [Batch 0/59] [D loss: 0.687995] [G loss: 0.697993]\n",
            "[Epoch 30/50] [Batch 1/59] [D loss: 0.691779] [G loss: 0.670621]\n",
            "[Epoch 30/50] [Batch 2/59] [D loss: 0.694514] [G loss: 0.657329]\n",
            "[Epoch 30/50] [Batch 3/59] [D loss: 0.691875] [G loss: 0.676100]\n",
            "[Epoch 30/50] [Batch 4/59] [D loss: 0.699835] [G loss: 0.707983]\n",
            "[Epoch 30/50] [Batch 5/59] [D loss: 0.689343] [G loss: 0.744748]\n",
            "[Epoch 30/50] [Batch 6/59] [D loss: 0.687685] [G loss: 0.776241]\n",
            "[Epoch 30/50] [Batch 7/59] [D loss: 0.681823] [G loss: 0.790856]\n",
            "[Epoch 30/50] [Batch 8/59] [D loss: 0.675427] [G loss: 0.786845]\n",
            "[Epoch 30/50] [Batch 9/59] [D loss: 0.670602] [G loss: 0.759904]\n",
            "[Epoch 30/50] [Batch 10/59] [D loss: 0.662142] [G loss: 0.771701]\n",
            "[Epoch 30/50] [Batch 11/59] [D loss: 0.671547] [G loss: 0.745171]\n",
            "[Epoch 30/50] [Batch 12/59] [D loss: 0.656267] [G loss: 0.745207]\n",
            "[Epoch 30/50] [Batch 13/59] [D loss: 0.660641] [G loss: 0.722267]\n",
            "[Epoch 30/50] [Batch 14/59] [D loss: 0.657096] [G loss: 0.689303]\n",
            "[Epoch 30/50] [Batch 15/59] [D loss: 0.658810] [G loss: 0.694269]\n",
            "[Epoch 30/50] [Batch 16/59] [D loss: 0.660991] [G loss: 0.681812]\n",
            "[Epoch 30/50] [Batch 17/59] [D loss: 0.667235] [G loss: 0.717183]\n",
            "[Epoch 30/50] [Batch 18/59] [D loss: 0.673118] [G loss: 0.736649]\n",
            "[Epoch 30/50] [Batch 19/59] [D loss: 0.684525] [G loss: 0.737690]\n",
            "[Epoch 30/50] [Batch 20/59] [D loss: 0.681519] [G loss: 0.744738]\n",
            "[Epoch 30/50] [Batch 21/59] [D loss: 0.680123] [G loss: 0.734654]\n",
            "[Epoch 30/50] [Batch 22/59] [D loss: 0.673993] [G loss: 0.724898]\n",
            "[Epoch 30/50] [Batch 23/59] [D loss: 0.660902] [G loss: 0.738814]\n",
            "[Epoch 30/50] [Batch 24/59] [D loss: 0.658092] [G loss: 0.736202]\n",
            "[Epoch 30/50] [Batch 25/59] [D loss: 0.658633] [G loss: 0.713919]\n",
            "[Epoch 30/50] [Batch 26/59] [D loss: 0.655632] [G loss: 0.723318]\n",
            "[Epoch 30/50] [Batch 27/59] [D loss: 0.670576] [G loss: 0.710612]\n",
            "[Epoch 30/50] [Batch 28/59] [D loss: 0.679875] [G loss: 0.706658]\n",
            "[Epoch 30/50] [Batch 29/59] [D loss: 0.689341] [G loss: 0.693627]\n",
            "[Epoch 30/50] [Batch 30/59] [D loss: 0.687190] [G loss: 0.705943]\n",
            "[Epoch 30/50] [Batch 31/59] [D loss: 0.685272] [G loss: 0.731280]\n",
            "[Epoch 30/50] [Batch 32/59] [D loss: 0.673771] [G loss: 0.727265]\n",
            "[Epoch 30/50] [Batch 33/59] [D loss: 0.664678] [G loss: 0.711094]\n",
            "[Epoch 30/50] [Batch 34/59] [D loss: 0.664194] [G loss: 0.683315]\n",
            "[Epoch 30/50] [Batch 35/59] [D loss: 0.681633] [G loss: 0.657937]\n",
            "[Epoch 30/50] [Batch 36/59] [D loss: 0.667754] [G loss: 0.696704]\n",
            "[Epoch 30/50] [Batch 37/59] [D loss: 0.661976] [G loss: 0.739274]\n",
            "[Epoch 30/50] [Batch 38/59] [D loss: 0.647842] [G loss: 0.776422]\n",
            "[Epoch 30/50] [Batch 39/59] [D loss: 0.642095] [G loss: 0.797413]\n",
            "[Epoch 30/50] [Batch 40/59] [D loss: 0.628078] [G loss: 0.824309]\n",
            "[Epoch 30/50] [Batch 41/59] [D loss: 0.627661] [G loss: 0.798216]\n",
            "[Epoch 30/50] [Batch 42/59] [D loss: 0.633794] [G loss: 0.788550]\n",
            "[Epoch 30/50] [Batch 43/59] [D loss: 0.631764] [G loss: 0.775166]\n",
            "[Epoch 30/50] [Batch 44/59] [D loss: 0.645649] [G loss: 0.708897]\n",
            "[Epoch 30/50] [Batch 45/59] [D loss: 0.672926] [G loss: 0.691531]\n",
            "[Epoch 30/50] [Batch 46/59] [D loss: 0.684735] [G loss: 0.653968]\n",
            "[Epoch 30/50] [Batch 47/59] [D loss: 0.690398] [G loss: 0.674298]\n",
            "[Epoch 30/50] [Batch 48/59] [D loss: 0.690271] [G loss: 0.703331]\n",
            "[Epoch 30/50] [Batch 49/59] [D loss: 0.692874] [G loss: 0.692867]\n",
            "[Epoch 30/50] [Batch 50/59] [D loss: 0.689364] [G loss: 0.691596]\n",
            "[Epoch 30/50] [Batch 51/59] [D loss: 0.696526] [G loss: 0.706498]\n",
            "[Epoch 30/50] [Batch 52/59] [D loss: 0.696371] [G loss: 0.706142]\n",
            "[Epoch 30/50] [Batch 53/59] [D loss: 0.708263] [G loss: 0.712390]\n",
            "[Epoch 30/50] [Batch 54/59] [D loss: 0.706709] [G loss: 0.738259]\n",
            "[Epoch 30/50] [Batch 55/59] [D loss: 0.701878] [G loss: 0.781241]\n",
            "[Epoch 30/50] [Batch 56/59] [D loss: 0.691930] [G loss: 0.797805]\n",
            "[Epoch 30/50] [Batch 57/59] [D loss: 0.679708] [G loss: 0.788346]\n",
            "[Epoch 30/50] [Batch 58/59] [D loss: 0.673619] [G loss: 0.759263]\n",
            "[Epoch 31/50] [Batch 0/59] [D loss: 0.671004] [G loss: 0.748842]\n",
            "[Epoch 31/50] [Batch 1/59] [D loss: 0.675416] [G loss: 0.748078]\n",
            "[Epoch 31/50] [Batch 2/59] [D loss: 0.676785] [G loss: 0.726470]\n",
            "[Epoch 31/50] [Batch 3/59] [D loss: 0.675260] [G loss: 0.739357]\n",
            "[Epoch 31/50] [Batch 4/59] [D loss: 0.672322] [G loss: 0.739329]\n",
            "[Epoch 31/50] [Batch 5/59] [D loss: 0.656098] [G loss: 0.757013]\n",
            "[Epoch 31/50] [Batch 6/59] [D loss: 0.661395] [G loss: 0.758493]\n",
            "[Epoch 31/50] [Batch 7/59] [D loss: 0.653518] [G loss: 0.752815]\n",
            "[Epoch 31/50] [Batch 8/59] [D loss: 0.663516] [G loss: 0.739335]\n",
            "[Epoch 31/50] [Batch 9/59] [D loss: 0.674275] [G loss: 0.751839]\n",
            "[Epoch 31/50] [Batch 10/59] [D loss: 0.673354] [G loss: 0.777326]\n",
            "[Epoch 31/50] [Batch 11/59] [D loss: 0.691095] [G loss: 0.767818]\n",
            "[Epoch 31/50] [Batch 12/59] [D loss: 0.684152] [G loss: 0.738139]\n",
            "[Epoch 31/50] [Batch 13/59] [D loss: 0.677261] [G loss: 0.728089]\n",
            "[Epoch 31/50] [Batch 14/59] [D loss: 0.679324] [G loss: 0.693261]\n",
            "[Epoch 31/50] [Batch 15/59] [D loss: 0.683661] [G loss: 0.672029]\n",
            "[Epoch 31/50] [Batch 16/59] [D loss: 0.682518] [G loss: 0.669132]\n",
            "[Epoch 31/50] [Batch 17/59] [D loss: 0.676235] [G loss: 0.704729]\n",
            "[Epoch 31/50] [Batch 18/59] [D loss: 0.683464] [G loss: 0.709630]\n",
            "[Epoch 31/50] [Batch 19/59] [D loss: 0.668593] [G loss: 0.713254]\n",
            "[Epoch 31/50] [Batch 20/59] [D loss: 0.655657] [G loss: 0.727960]\n",
            "[Epoch 31/50] [Batch 21/59] [D loss: 0.650933] [G loss: 0.727431]\n",
            "[Epoch 31/50] [Batch 22/59] [D loss: 0.643471] [G loss: 0.744667]\n",
            "[Epoch 31/50] [Batch 23/59] [D loss: 0.634627] [G loss: 0.759279]\n",
            "[Epoch 31/50] [Batch 24/59] [D loss: 0.635689] [G loss: 0.754534]\n",
            "[Epoch 31/50] [Batch 25/59] [D loss: 0.646877] [G loss: 0.733485]\n",
            "[Epoch 31/50] [Batch 26/59] [D loss: 0.648241] [G loss: 0.734501]\n",
            "[Epoch 31/50] [Batch 27/59] [D loss: 0.656977] [G loss: 0.717521]\n",
            "[Epoch 31/50] [Batch 28/59] [D loss: 0.655523] [G loss: 0.699930]\n",
            "[Epoch 31/50] [Batch 29/59] [D loss: 0.662774] [G loss: 0.695523]\n",
            "[Epoch 31/50] [Batch 30/59] [D loss: 0.664648] [G loss: 0.727304]\n",
            "[Epoch 31/50] [Batch 31/59] [D loss: 0.664450] [G loss: 0.750248]\n",
            "[Epoch 31/50] [Batch 32/59] [D loss: 0.681326] [G loss: 0.724245]\n",
            "[Epoch 31/50] [Batch 33/59] [D loss: 0.688437] [G loss: 0.722706]\n",
            "[Epoch 31/50] [Batch 34/59] [D loss: 0.698989] [G loss: 0.722032]\n",
            "[Epoch 31/50] [Batch 35/59] [D loss: 0.707257] [G loss: 0.748490]\n",
            "[Epoch 31/50] [Batch 36/59] [D loss: 0.708704] [G loss: 0.782431]\n",
            "[Epoch 31/50] [Batch 37/59] [D loss: 0.707465] [G loss: 0.782485]\n",
            "[Epoch 31/50] [Batch 38/59] [D loss: 0.689031] [G loss: 0.755647]\n",
            "[Epoch 31/50] [Batch 39/59] [D loss: 0.684276] [G loss: 0.747687]\n",
            "[Epoch 31/50] [Batch 40/59] [D loss: 0.670598] [G loss: 0.775050]\n",
            "[Epoch 31/50] [Batch 41/59] [D loss: 0.661107] [G loss: 0.805986]\n",
            "[Epoch 31/50] [Batch 42/59] [D loss: 0.652413] [G loss: 0.758655]\n",
            "[Epoch 31/50] [Batch 43/59] [D loss: 0.636451] [G loss: 0.726000]\n",
            "[Epoch 31/50] [Batch 44/59] [D loss: 0.646772] [G loss: 0.741421]\n",
            "[Epoch 31/50] [Batch 45/59] [D loss: 0.636806] [G loss: 0.799166]\n",
            "[Epoch 31/50] [Batch 46/59] [D loss: 0.644235] [G loss: 0.827684]\n",
            "[Epoch 31/50] [Batch 47/59] [D loss: 0.645249] [G loss: 0.783491]\n",
            "[Epoch 31/50] [Batch 48/59] [D loss: 0.658074] [G loss: 0.682927]\n",
            "[Epoch 31/50] [Batch 49/59] [D loss: 0.667146] [G loss: 0.667514]\n",
            "[Epoch 31/50] [Batch 50/59] [D loss: 0.678781] [G loss: 0.751453]\n",
            "[Epoch 31/50] [Batch 51/59] [D loss: 0.690036] [G loss: 0.779183]\n",
            "[Epoch 31/50] [Batch 52/59] [D loss: 0.698923] [G loss: 0.684016]\n",
            "[Epoch 31/50] [Batch 53/59] [D loss: 0.700772] [G loss: 0.590296]\n",
            "[Epoch 31/50] [Batch 54/59] [D loss: 0.707590] [G loss: 0.595520]\n",
            "[Epoch 31/50] [Batch 55/59] [D loss: 0.690426] [G loss: 0.705699]\n",
            "[Epoch 31/50] [Batch 56/59] [D loss: 0.674356] [G loss: 0.794094]\n",
            "[Epoch 31/50] [Batch 57/59] [D loss: 0.681696] [G loss: 0.767948]\n",
            "[Epoch 31/50] [Batch 58/59] [D loss: 0.683126] [G loss: 0.704953]\n",
            "[Epoch 32/50] [Batch 0/59] [D loss: 0.659528] [G loss: 0.664582]\n",
            "[Epoch 32/50] [Batch 1/59] [D loss: 0.663864] [G loss: 0.658928]\n",
            "[Epoch 32/50] [Batch 2/59] [D loss: 0.658730] [G loss: 0.701520]\n",
            "[Epoch 32/50] [Batch 3/59] [D loss: 0.642912] [G loss: 0.771017]\n",
            "[Epoch 32/50] [Batch 4/59] [D loss: 0.650308] [G loss: 0.796134]\n",
            "[Epoch 32/50] [Batch 5/59] [D loss: 0.642650] [G loss: 0.756826]\n",
            "[Epoch 32/50] [Batch 6/59] [D loss: 0.640898] [G loss: 0.720709]\n",
            "[Epoch 32/50] [Batch 7/59] [D loss: 0.632403] [G loss: 0.681052]\n",
            "[Epoch 32/50] [Batch 8/59] [D loss: 0.646945] [G loss: 0.706946]\n",
            "[Epoch 32/50] [Batch 9/59] [D loss: 0.638286] [G loss: 0.783487]\n",
            "[Epoch 32/50] [Batch 10/59] [D loss: 0.647992] [G loss: 0.806147]\n",
            "[Epoch 32/50] [Batch 11/59] [D loss: 0.664105] [G loss: 0.793824]\n",
            "[Epoch 32/50] [Batch 12/59] [D loss: 0.657359] [G loss: 0.720978]\n",
            "[Epoch 32/50] [Batch 13/59] [D loss: 0.681419] [G loss: 0.655555]\n",
            "[Epoch 32/50] [Batch 14/59] [D loss: 0.670893] [G loss: 0.694970]\n",
            "[Epoch 32/50] [Batch 15/59] [D loss: 0.681981] [G loss: 0.743485]\n",
            "[Epoch 32/50] [Batch 16/59] [D loss: 0.697779] [G loss: 0.756235]\n",
            "[Epoch 32/50] [Batch 17/59] [D loss: 0.697281] [G loss: 0.723595]\n",
            "[Epoch 32/50] [Batch 18/59] [D loss: 0.682509] [G loss: 0.737537]\n",
            "[Epoch 32/50] [Batch 19/59] [D loss: 0.698622] [G loss: 0.719596]\n",
            "[Epoch 32/50] [Batch 20/59] [D loss: 0.684406] [G loss: 0.777730]\n",
            "[Epoch 32/50] [Batch 21/59] [D loss: 0.667166] [G loss: 0.760444]\n",
            "[Epoch 32/50] [Batch 22/59] [D loss: 0.669664] [G loss: 0.758575]\n",
            "[Epoch 32/50] [Batch 23/59] [D loss: 0.660042] [G loss: 0.807765]\n",
            "[Epoch 32/50] [Batch 24/59] [D loss: 0.669517] [G loss: 0.794833]\n",
            "[Epoch 32/50] [Batch 25/59] [D loss: 0.661199] [G loss: 0.771496]\n",
            "[Epoch 32/50] [Batch 26/59] [D loss: 0.663163] [G loss: 0.744206]\n",
            "[Epoch 32/50] [Batch 27/59] [D loss: 0.670127] [G loss: 0.730105]\n",
            "[Epoch 32/50] [Batch 28/59] [D loss: 0.674520] [G loss: 0.712004]\n",
            "[Epoch 32/50] [Batch 29/59] [D loss: 0.685492] [G loss: 0.773921]\n",
            "[Epoch 32/50] [Batch 30/59] [D loss: 0.675930] [G loss: 0.700643]\n",
            "[Epoch 32/50] [Batch 31/59] [D loss: 0.663581] [G loss: 0.695213]\n",
            "[Epoch 32/50] [Batch 32/59] [D loss: 0.656657] [G loss: 0.707094]\n",
            "[Epoch 32/50] [Batch 33/59] [D loss: 0.642882] [G loss: 0.755245]\n",
            "[Epoch 32/50] [Batch 34/59] [D loss: 0.646472] [G loss: 0.811998]\n",
            "[Epoch 32/50] [Batch 35/59] [D loss: 0.629822] [G loss: 0.796072]\n",
            "[Epoch 32/50] [Batch 36/59] [D loss: 0.624857] [G loss: 0.760668]\n",
            "[Epoch 32/50] [Batch 37/59] [D loss: 0.629516] [G loss: 0.743913]\n",
            "[Epoch 32/50] [Batch 38/59] [D loss: 0.643981] [G loss: 0.695955]\n",
            "[Epoch 32/50] [Batch 39/59] [D loss: 0.634951] [G loss: 0.747995]\n",
            "[Epoch 32/50] [Batch 40/59] [D loss: 0.656420] [G loss: 0.805284]\n",
            "[Epoch 32/50] [Batch 41/59] [D loss: 0.668279] [G loss: 0.759742]\n",
            "[Epoch 32/50] [Batch 42/59] [D loss: 0.695892] [G loss: 0.722166]\n",
            "[Epoch 32/50] [Batch 43/59] [D loss: 0.700288] [G loss: 0.691321]\n",
            "[Epoch 32/50] [Batch 44/59] [D loss: 0.697006] [G loss: 0.723101]\n",
            "[Epoch 32/50] [Batch 45/59] [D loss: 0.701188] [G loss: 0.774406]\n",
            "[Epoch 32/50] [Batch 46/59] [D loss: 0.684378] [G loss: 0.753611]\n",
            "[Epoch 32/50] [Batch 47/59] [D loss: 0.672706] [G loss: 0.715593]\n",
            "[Epoch 32/50] [Batch 48/59] [D loss: 0.676661] [G loss: 0.692557]\n",
            "[Epoch 32/50] [Batch 49/59] [D loss: 0.660637] [G loss: 0.742321]\n",
            "[Epoch 32/50] [Batch 50/59] [D loss: 0.656315] [G loss: 0.769745]\n",
            "[Epoch 32/50] [Batch 51/59] [D loss: 0.649627] [G loss: 0.781604]\n",
            "[Epoch 32/50] [Batch 52/59] [D loss: 0.654001] [G loss: 0.715837]\n",
            "[Epoch 32/50] [Batch 53/59] [D loss: 0.657849] [G loss: 0.652312]\n",
            "[Epoch 32/50] [Batch 54/59] [D loss: 0.667866] [G loss: 0.695319]\n",
            "[Epoch 32/50] [Batch 55/59] [D loss: 0.648311] [G loss: 0.740283]\n",
            "[Epoch 32/50] [Batch 56/59] [D loss: 0.659582] [G loss: 0.729609]\n",
            "[Epoch 32/50] [Batch 57/59] [D loss: 0.654117] [G loss: 0.719045]\n",
            "[Epoch 32/50] [Batch 58/59] [D loss: 0.669875] [G loss: 0.676483]\n",
            "[Epoch 33/50] [Batch 0/59] [D loss: 0.665029] [G loss: 0.770967]\n",
            "[Epoch 33/50] [Batch 1/59] [D loss: 0.675065] [G loss: 0.778762]\n",
            "[Epoch 33/50] [Batch 2/59] [D loss: 0.672942] [G loss: 0.765028]\n",
            "[Epoch 33/50] [Batch 3/59] [D loss: 0.675245] [G loss: 0.734310]\n",
            "[Epoch 33/50] [Batch 4/59] [D loss: 0.676242] [G loss: 0.719877]\n",
            "[Epoch 33/50] [Batch 5/59] [D loss: 0.684329] [G loss: 0.733647]\n",
            "[Epoch 33/50] [Batch 6/59] [D loss: 0.686391] [G loss: 0.742932]\n",
            "[Epoch 33/50] [Batch 7/59] [D loss: 0.689236] [G loss: 0.722625]\n",
            "[Epoch 33/50] [Batch 8/59] [D loss: 0.695418] [G loss: 0.738598]\n",
            "[Epoch 33/50] [Batch 9/59] [D loss: 0.691399] [G loss: 0.724894]\n",
            "[Epoch 33/50] [Batch 10/59] [D loss: 0.682890] [G loss: 0.776229]\n",
            "[Epoch 33/50] [Batch 11/59] [D loss: 0.681507] [G loss: 0.745184]\n",
            "[Epoch 33/50] [Batch 12/59] [D loss: 0.677530] [G loss: 0.740048]\n",
            "[Epoch 33/50] [Batch 13/59] [D loss: 0.668153] [G loss: 0.745170]\n",
            "[Epoch 33/50] [Batch 14/59] [D loss: 0.655432] [G loss: 0.771247]\n",
            "[Epoch 33/50] [Batch 15/59] [D loss: 0.646447] [G loss: 0.749378]\n",
            "[Epoch 33/50] [Batch 16/59] [D loss: 0.637621] [G loss: 0.763438]\n",
            "[Epoch 33/50] [Batch 17/59] [D loss: 0.628955] [G loss: 0.772768]\n",
            "[Epoch 33/50] [Batch 18/59] [D loss: 0.630575] [G loss: 0.784802]\n",
            "[Epoch 33/50] [Batch 19/59] [D loss: 0.622041] [G loss: 0.798607]\n",
            "[Epoch 33/50] [Batch 20/59] [D loss: 0.636994] [G loss: 0.773505]\n",
            "[Epoch 33/50] [Batch 21/59] [D loss: 0.646229] [G loss: 0.794463]\n",
            "[Epoch 33/50] [Batch 22/59] [D loss: 0.649625] [G loss: 0.791372]\n",
            "[Epoch 33/50] [Batch 23/59] [D loss: 0.656688] [G loss: 0.769080]\n",
            "[Epoch 33/50] [Batch 24/59] [D loss: 0.664311] [G loss: 0.742514]\n",
            "[Epoch 33/50] [Batch 25/59] [D loss: 0.674091] [G loss: 0.793021]\n",
            "[Epoch 33/50] [Batch 26/59] [D loss: 0.683708] [G loss: 0.744854]\n",
            "[Epoch 33/50] [Batch 27/59] [D loss: 0.687397] [G loss: 0.729623]\n",
            "[Epoch 33/50] [Batch 28/59] [D loss: 0.686530] [G loss: 0.698339]\n",
            "[Epoch 33/50] [Batch 29/59] [D loss: 0.683198] [G loss: 0.720546]\n",
            "[Epoch 33/50] [Batch 30/59] [D loss: 0.689455] [G loss: 0.752325]\n",
            "[Epoch 33/50] [Batch 31/59] [D loss: 0.678626] [G loss: 0.726381]\n",
            "[Epoch 33/50] [Batch 32/59] [D loss: 0.678898] [G loss: 0.724808]\n",
            "[Epoch 33/50] [Batch 33/59] [D loss: 0.658769] [G loss: 0.737633]\n",
            "[Epoch 33/50] [Batch 34/59] [D loss: 0.663900] [G loss: 0.788649]\n",
            "[Epoch 33/50] [Batch 35/59] [D loss: 0.658762] [G loss: 0.780664]\n",
            "[Epoch 33/50] [Batch 36/59] [D loss: 0.675105] [G loss: 0.712279]\n",
            "[Epoch 33/50] [Batch 37/59] [D loss: 0.657653] [G loss: 0.710051]\n",
            "[Epoch 33/50] [Batch 38/59] [D loss: 0.659040] [G loss: 0.694127]\n",
            "[Epoch 33/50] [Batch 39/59] [D loss: 0.659241] [G loss: 0.738280]\n",
            "[Epoch 33/50] [Batch 40/59] [D loss: 0.653648] [G loss: 0.744398]\n",
            "[Epoch 33/50] [Batch 41/59] [D loss: 0.652382] [G loss: 0.708680]\n",
            "[Epoch 33/50] [Batch 42/59] [D loss: 0.647869] [G loss: 0.722695]\n",
            "[Epoch 33/50] [Batch 43/59] [D loss: 0.658216] [G loss: 0.713172]\n",
            "[Epoch 33/50] [Batch 44/59] [D loss: 0.654240] [G loss: 0.771849]\n",
            "[Epoch 33/50] [Batch 45/59] [D loss: 0.640176] [G loss: 0.784218]\n",
            "[Epoch 33/50] [Batch 46/59] [D loss: 0.649906] [G loss: 0.743701]\n",
            "[Epoch 33/50] [Batch 47/59] [D loss: 0.671724] [G loss: 0.702212]\n",
            "[Epoch 33/50] [Batch 48/59] [D loss: 0.671467] [G loss: 0.801524]\n",
            "[Epoch 33/50] [Batch 49/59] [D loss: 0.680683] [G loss: 0.826814]\n",
            "[Epoch 33/50] [Batch 50/59] [D loss: 0.677152] [G loss: 0.761967]\n",
            "[Epoch 33/50] [Batch 51/59] [D loss: 0.702421] [G loss: 0.636667]\n",
            "[Epoch 33/50] [Batch 52/59] [D loss: 0.679854] [G loss: 0.745628]\n",
            "[Epoch 33/50] [Batch 53/59] [D loss: 0.696691] [G loss: 0.784622]\n",
            "[Epoch 33/50] [Batch 54/59] [D loss: 0.699269] [G loss: 0.779470]\n",
            "[Epoch 33/50] [Batch 55/59] [D loss: 0.679088] [G loss: 0.730807]\n",
            "[Epoch 33/50] [Batch 56/59] [D loss: 0.691117] [G loss: 0.697413]\n",
            "[Epoch 33/50] [Batch 57/59] [D loss: 0.680362] [G loss: 0.770998]\n",
            "[Epoch 33/50] [Batch 58/59] [D loss: 0.665812] [G loss: 0.875130]\n",
            "[Epoch 34/50] [Batch 0/59] [D loss: 0.651992] [G loss: 0.838640]\n",
            "[Epoch 34/50] [Batch 1/59] [D loss: 0.647721] [G loss: 0.791203]\n",
            "[Epoch 34/50] [Batch 2/59] [D loss: 0.645337] [G loss: 0.711411]\n",
            "[Epoch 34/50] [Batch 3/59] [D loss: 0.638248] [G loss: 0.799275]\n",
            "[Epoch 34/50] [Batch 4/59] [D loss: 0.630572] [G loss: 0.900082]\n",
            "[Epoch 34/50] [Batch 5/59] [D loss: 0.634845] [G loss: 0.858117]\n",
            "[Epoch 34/50] [Batch 6/59] [D loss: 0.643221] [G loss: 0.744513]\n",
            "[Epoch 34/50] [Batch 7/59] [D loss: 0.650394] [G loss: 0.656352]\n",
            "[Epoch 34/50] [Batch 8/59] [D loss: 0.660799] [G loss: 0.685322]\n",
            "[Epoch 34/50] [Batch 9/59] [D loss: 0.652776] [G loss: 0.794540]\n",
            "[Epoch 34/50] [Batch 10/59] [D loss: 0.668744] [G loss: 0.856434]\n",
            "[Epoch 34/50] [Batch 11/59] [D loss: 0.689862] [G loss: 0.780183]\n",
            "[Epoch 34/50] [Batch 12/59] [D loss: 0.682236] [G loss: 0.693644]\n",
            "[Epoch 34/50] [Batch 13/59] [D loss: 0.685112] [G loss: 0.626560]\n",
            "[Epoch 34/50] [Batch 14/59] [D loss: 0.680520] [G loss: 0.693435]\n",
            "[Epoch 34/50] [Batch 15/59] [D loss: 0.682944] [G loss: 0.788886]\n",
            "[Epoch 34/50] [Batch 16/59] [D loss: 0.662719] [G loss: 0.838506]\n",
            "[Epoch 34/50] [Batch 17/59] [D loss: 0.673655] [G loss: 0.757266]\n",
            "[Epoch 34/50] [Batch 18/59] [D loss: 0.667977] [G loss: 0.671078]\n",
            "[Epoch 34/50] [Batch 19/59] [D loss: 0.667902] [G loss: 0.708269]\n",
            "[Epoch 34/50] [Batch 20/59] [D loss: 0.651903] [G loss: 0.811264]\n",
            "[Epoch 34/50] [Batch 21/59] [D loss: 0.648601] [G loss: 0.790879]\n",
            "[Epoch 34/50] [Batch 22/59] [D loss: 0.645635] [G loss: 0.716258]\n",
            "[Epoch 34/50] [Batch 23/59] [D loss: 0.655696] [G loss: 0.703019]\n",
            "[Epoch 34/50] [Batch 24/59] [D loss: 0.658952] [G loss: 0.763052]\n",
            "[Epoch 34/50] [Batch 25/59] [D loss: 0.650365] [G loss: 0.753183]\n",
            "[Epoch 34/50] [Batch 26/59] [D loss: 0.652005] [G loss: 0.709362]\n",
            "[Epoch 34/50] [Batch 27/59] [D loss: 0.676475] [G loss: 0.731498]\n",
            "[Epoch 34/50] [Batch 28/59] [D loss: 0.668991] [G loss: 0.746626]\n",
            "[Epoch 34/50] [Batch 29/59] [D loss: 0.654923] [G loss: 0.712658]\n",
            "[Epoch 34/50] [Batch 30/59] [D loss: 0.676844] [G loss: 0.684118]\n",
            "[Epoch 34/50] [Batch 31/59] [D loss: 0.658917] [G loss: 0.750043]\n",
            "[Epoch 34/50] [Batch 32/59] [D loss: 0.671297] [G loss: 0.799487]\n",
            "[Epoch 34/50] [Batch 33/59] [D loss: 0.676611] [G loss: 0.808384]\n",
            "[Epoch 34/50] [Batch 34/59] [D loss: 0.660752] [G loss: 0.742066]\n",
            "[Epoch 34/50] [Batch 35/59] [D loss: 0.681313] [G loss: 0.677526]\n",
            "[Epoch 34/50] [Batch 36/59] [D loss: 0.672249] [G loss: 0.809888]\n",
            "[Epoch 34/50] [Batch 37/59] [D loss: 0.666805] [G loss: 0.845370]\n",
            "[Epoch 34/50] [Batch 38/59] [D loss: 0.657678] [G loss: 0.822560]\n",
            "[Epoch 34/50] [Batch 39/59] [D loss: 0.661863] [G loss: 0.716374]\n",
            "[Epoch 34/50] [Batch 40/59] [D loss: 0.653265] [G loss: 0.750125]\n",
            "[Epoch 34/50] [Batch 41/59] [D loss: 0.641638] [G loss: 0.862256]\n",
            "[Epoch 34/50] [Batch 42/59] [D loss: 0.660218] [G loss: 0.845352]\n",
            "[Epoch 34/50] [Batch 43/59] [D loss: 0.649620] [G loss: 0.780334]\n",
            "[Epoch 34/50] [Batch 44/59] [D loss: 0.670228] [G loss: 0.715194]\n",
            "[Epoch 34/50] [Batch 45/59] [D loss: 0.672302] [G loss: 0.712898]\n",
            "[Epoch 34/50] [Batch 46/59] [D loss: 0.669284] [G loss: 0.830356]\n",
            "[Epoch 34/50] [Batch 47/59] [D loss: 0.655904] [G loss: 0.841632]\n",
            "[Epoch 34/50] [Batch 48/59] [D loss: 0.656046] [G loss: 0.758670]\n",
            "[Epoch 34/50] [Batch 49/59] [D loss: 0.669847] [G loss: 0.700519]\n",
            "[Epoch 34/50] [Batch 50/59] [D loss: 0.661456] [G loss: 0.665958]\n",
            "[Epoch 34/50] [Batch 51/59] [D loss: 0.670315] [G loss: 0.739971]\n",
            "[Epoch 34/50] [Batch 52/59] [D loss: 0.673644] [G loss: 0.765619]\n",
            "[Epoch 34/50] [Batch 53/59] [D loss: 0.661941] [G loss: 0.761976]\n",
            "[Epoch 34/50] [Batch 54/59] [D loss: 0.668179] [G loss: 0.721903]\n",
            "[Epoch 34/50] [Batch 55/59] [D loss: 0.665751] [G loss: 0.672473]\n",
            "[Epoch 34/50] [Batch 56/59] [D loss: 0.661788] [G loss: 0.687494]\n",
            "[Epoch 34/50] [Batch 57/59] [D loss: 0.671797] [G loss: 0.739214]\n",
            "[Epoch 34/50] [Batch 58/59] [D loss: 0.664404] [G loss: 0.738185]\n",
            "[Epoch 35/50] [Batch 0/59] [D loss: 0.662755] [G loss: 0.753440]\n",
            "[Epoch 35/50] [Batch 1/59] [D loss: 0.666343] [G loss: 0.725987]\n",
            "[Epoch 35/50] [Batch 2/59] [D loss: 0.665601] [G loss: 0.735794]\n",
            "[Epoch 35/50] [Batch 3/59] [D loss: 0.665550] [G loss: 0.746627]\n",
            "[Epoch 35/50] [Batch 4/59] [D loss: 0.663944] [G loss: 0.794389]\n",
            "[Epoch 35/50] [Batch 5/59] [D loss: 0.661692] [G loss: 0.766546]\n",
            "[Epoch 35/50] [Batch 6/59] [D loss: 0.651842] [G loss: 0.710952]\n",
            "[Epoch 35/50] [Batch 7/59] [D loss: 0.650444] [G loss: 0.693947]\n",
            "[Epoch 35/50] [Batch 8/59] [D loss: 0.664034] [G loss: 0.759902]\n",
            "[Epoch 35/50] [Batch 9/59] [D loss: 0.670206] [G loss: 0.824598]\n",
            "[Epoch 35/50] [Batch 10/59] [D loss: 0.663926] [G loss: 0.764919]\n",
            "[Epoch 35/50] [Batch 11/59] [D loss: 0.656013] [G loss: 0.693894]\n",
            "[Epoch 35/50] [Batch 12/59] [D loss: 0.685639] [G loss: 0.652846]\n",
            "[Epoch 35/50] [Batch 13/59] [D loss: 0.666524] [G loss: 0.795092]\n",
            "[Epoch 35/50] [Batch 14/59] [D loss: 0.685468] [G loss: 0.764624]\n",
            "[Epoch 35/50] [Batch 15/59] [D loss: 0.681905] [G loss: 0.715477]\n",
            "[Epoch 35/50] [Batch 16/59] [D loss: 0.678671] [G loss: 0.699449]\n",
            "[Epoch 35/50] [Batch 17/59] [D loss: 0.676051] [G loss: 0.742444]\n",
            "[Epoch 35/50] [Batch 18/59] [D loss: 0.666563] [G loss: 0.777561]\n",
            "[Epoch 35/50] [Batch 19/59] [D loss: 0.661396] [G loss: 0.769064]\n",
            "[Epoch 35/50] [Batch 20/59] [D loss: 0.664099] [G loss: 0.739533]\n",
            "[Epoch 35/50] [Batch 21/59] [D loss: 0.654465] [G loss: 0.755497]\n",
            "[Epoch 35/50] [Batch 22/59] [D loss: 0.642228] [G loss: 0.779607]\n",
            "[Epoch 35/50] [Batch 23/59] [D loss: 0.657370] [G loss: 0.811746]\n",
            "[Epoch 35/50] [Batch 24/59] [D loss: 0.655187] [G loss: 0.754912]\n",
            "[Epoch 35/50] [Batch 25/59] [D loss: 0.657805] [G loss: 0.702929]\n",
            "[Epoch 35/50] [Batch 26/59] [D loss: 0.645982] [G loss: 0.771634]\n",
            "[Epoch 35/50] [Batch 27/59] [D loss: 0.649438] [G loss: 0.832474]\n",
            "[Epoch 35/50] [Batch 28/59] [D loss: 0.656571] [G loss: 0.823683]\n",
            "[Epoch 35/50] [Batch 29/59] [D loss: 0.651821] [G loss: 0.737491]\n",
            "[Epoch 35/50] [Batch 30/59] [D loss: 0.654348] [G loss: 0.693514]\n",
            "[Epoch 35/50] [Batch 31/59] [D loss: 0.661509] [G loss: 0.739111]\n",
            "[Epoch 35/50] [Batch 32/59] [D loss: 0.665431] [G loss: 0.849821]\n",
            "[Epoch 35/50] [Batch 33/59] [D loss: 0.668458] [G loss: 0.794932]\n",
            "[Epoch 35/50] [Batch 34/59] [D loss: 0.672157] [G loss: 0.719728]\n",
            "[Epoch 35/50] [Batch 35/59] [D loss: 0.660417] [G loss: 0.681263]\n",
            "[Epoch 35/50] [Batch 36/59] [D loss: 0.674322] [G loss: 0.713981]\n",
            "[Epoch 35/50] [Batch 37/59] [D loss: 0.688174] [G loss: 0.780290]\n",
            "[Epoch 35/50] [Batch 38/59] [D loss: 0.683356] [G loss: 0.751915]\n",
            "[Epoch 35/50] [Batch 39/59] [D loss: 0.656662] [G loss: 0.712044]\n",
            "[Epoch 35/50] [Batch 40/59] [D loss: 0.656364] [G loss: 0.689007]\n",
            "[Epoch 35/50] [Batch 41/59] [D loss: 0.646369] [G loss: 0.727609]\n",
            "[Epoch 35/50] [Batch 42/59] [D loss: 0.655778] [G loss: 0.749249]\n",
            "[Epoch 35/50] [Batch 43/59] [D loss: 0.648848] [G loss: 0.779969]\n",
            "[Epoch 35/50] [Batch 44/59] [D loss: 0.638366] [G loss: 0.769534]\n",
            "[Epoch 35/50] [Batch 45/59] [D loss: 0.635573] [G loss: 0.748778]\n",
            "[Epoch 35/50] [Batch 46/59] [D loss: 0.625582] [G loss: 0.747450]\n",
            "[Epoch 35/50] [Batch 47/59] [D loss: 0.631956] [G loss: 0.740218]\n",
            "[Epoch 35/50] [Batch 48/59] [D loss: 0.641953] [G loss: 0.790179]\n",
            "[Epoch 35/50] [Batch 49/59] [D loss: 0.624971] [G loss: 0.745903]\n",
            "[Epoch 35/50] [Batch 50/59] [D loss: 0.638425] [G loss: 0.780566]\n",
            "[Epoch 35/50] [Batch 51/59] [D loss: 0.649524] [G loss: 0.754000]\n",
            "[Epoch 35/50] [Batch 52/59] [D loss: 0.658064] [G loss: 0.734100]\n",
            "[Epoch 35/50] [Batch 53/59] [D loss: 0.661944] [G loss: 0.785375]\n",
            "[Epoch 35/50] [Batch 54/59] [D loss: 0.675712] [G loss: 0.763124]\n",
            "[Epoch 35/50] [Batch 55/59] [D loss: 0.684313] [G loss: 0.716818]\n",
            "[Epoch 35/50] [Batch 56/59] [D loss: 0.679899] [G loss: 0.744071]\n",
            "[Epoch 35/50] [Batch 57/59] [D loss: 0.686576] [G loss: 0.757393]\n",
            "[Epoch 35/50] [Batch 58/59] [D loss: 0.683307] [G loss: 0.750562]\n",
            "[Epoch 36/50] [Batch 0/59] [D loss: 0.671535] [G loss: 0.731109]\n",
            "[Epoch 36/50] [Batch 1/59] [D loss: 0.666131] [G loss: 0.768880]\n",
            "[Epoch 36/50] [Batch 2/59] [D loss: 0.656988] [G loss: 0.794847]\n",
            "[Epoch 36/50] [Batch 3/59] [D loss: 0.646205] [G loss: 0.827302]\n",
            "[Epoch 36/50] [Batch 4/59] [D loss: 0.644315] [G loss: 0.742835]\n",
            "[Epoch 36/50] [Batch 5/59] [D loss: 0.654177] [G loss: 0.674943]\n",
            "[Epoch 36/50] [Batch 6/59] [D loss: 0.649337] [G loss: 0.749381]\n",
            "[Epoch 36/50] [Batch 7/59] [D loss: 0.645804] [G loss: 0.856160]\n",
            "[Epoch 36/50] [Batch 8/59] [D loss: 0.635598] [G loss: 0.811802]\n",
            "[Epoch 36/50] [Batch 9/59] [D loss: 0.644662] [G loss: 0.689118]\n",
            "[Epoch 36/50] [Batch 10/59] [D loss: 0.655215] [G loss: 0.686043]\n",
            "[Epoch 36/50] [Batch 11/59] [D loss: 0.659626] [G loss: 0.764287]\n",
            "[Epoch 36/50] [Batch 12/59] [D loss: 0.650236] [G loss: 0.844057]\n",
            "[Epoch 36/50] [Batch 13/59] [D loss: 0.662892] [G loss: 0.749907]\n",
            "[Epoch 36/50] [Batch 14/59] [D loss: 0.647563] [G loss: 0.690871]\n",
            "[Epoch 36/50] [Batch 15/59] [D loss: 0.658493] [G loss: 0.694041]\n",
            "[Epoch 36/50] [Batch 16/59] [D loss: 0.644566] [G loss: 0.862200]\n",
            "[Epoch 36/50] [Batch 17/59] [D loss: 0.669615] [G loss: 0.801212]\n",
            "[Epoch 36/50] [Batch 18/59] [D loss: 0.677093] [G loss: 0.728651]\n",
            "[Epoch 36/50] [Batch 19/59] [D loss: 0.648384] [G loss: 0.716305]\n",
            "[Epoch 36/50] [Batch 20/59] [D loss: 0.657864] [G loss: 0.818033]\n",
            "[Epoch 36/50] [Batch 21/59] [D loss: 0.648866] [G loss: 0.809869]\n",
            "[Epoch 36/50] [Batch 22/59] [D loss: 0.660206] [G loss: 0.745018]\n",
            "[Epoch 36/50] [Batch 23/59] [D loss: 0.646263] [G loss: 0.766967]\n",
            "[Epoch 36/50] [Batch 24/59] [D loss: 0.649558] [G loss: 0.771333]\n",
            "[Epoch 36/50] [Batch 25/59] [D loss: 0.650965] [G loss: 0.737058]\n",
            "[Epoch 36/50] [Batch 26/59] [D loss: 0.655969] [G loss: 0.780730]\n",
            "[Epoch 36/50] [Batch 27/59] [D loss: 0.660159] [G loss: 0.752072]\n",
            "[Epoch 36/50] [Batch 28/59] [D loss: 0.667304] [G loss: 0.753900]\n",
            "[Epoch 36/50] [Batch 29/59] [D loss: 0.664566] [G loss: 0.718409]\n",
            "[Epoch 36/50] [Batch 30/59] [D loss: 0.673287] [G loss: 0.674330]\n",
            "[Epoch 36/50] [Batch 31/59] [D loss: 0.662463] [G loss: 0.737355]\n",
            "[Epoch 36/50] [Batch 32/59] [D loss: 0.661257] [G loss: 0.779414]\n",
            "[Epoch 36/50] [Batch 33/59] [D loss: 0.662864] [G loss: 0.787209]\n",
            "[Epoch 36/50] [Batch 34/59] [D loss: 0.672839] [G loss: 0.749479]\n",
            "[Epoch 36/50] [Batch 35/59] [D loss: 0.674367] [G loss: 0.718919]\n",
            "[Epoch 36/50] [Batch 36/59] [D loss: 0.661599] [G loss: 0.758523]\n",
            "[Epoch 36/50] [Batch 37/59] [D loss: 0.654875] [G loss: 0.757980]\n",
            "[Epoch 36/50] [Batch 38/59] [D loss: 0.641702] [G loss: 0.779388]\n",
            "[Epoch 36/50] [Batch 39/59] [D loss: 0.650076] [G loss: 0.803881]\n",
            "[Epoch 36/50] [Batch 40/59] [D loss: 0.660879] [G loss: 0.748861]\n",
            "[Epoch 36/50] [Batch 41/59] [D loss: 0.661160] [G loss: 0.725398]\n",
            "[Epoch 36/50] [Batch 42/59] [D loss: 0.653884] [G loss: 0.736770]\n",
            "[Epoch 36/50] [Batch 43/59] [D loss: 0.658138] [G loss: 0.778752]\n",
            "[Epoch 36/50] [Batch 44/59] [D loss: 0.656127] [G loss: 0.741570]\n",
            "[Epoch 36/50] [Batch 45/59] [D loss: 0.662607] [G loss: 0.771124]\n",
            "[Epoch 36/50] [Batch 46/59] [D loss: 0.653112] [G loss: 0.756629]\n",
            "[Epoch 36/50] [Batch 47/59] [D loss: 0.650401] [G loss: 0.741313]\n",
            "[Epoch 36/50] [Batch 48/59] [D loss: 0.661114] [G loss: 0.789210]\n",
            "[Epoch 36/50] [Batch 49/59] [D loss: 0.645453] [G loss: 0.777597]\n",
            "[Epoch 36/50] [Batch 50/59] [D loss: 0.621426] [G loss: 0.740517]\n",
            "[Epoch 36/50] [Batch 51/59] [D loss: 0.641684] [G loss: 0.753234]\n",
            "[Epoch 36/50] [Batch 52/59] [D loss: 0.631670] [G loss: 0.771710]\n",
            "[Epoch 36/50] [Batch 53/59] [D loss: 0.631919] [G loss: 0.838878]\n",
            "[Epoch 36/50] [Batch 54/59] [D loss: 0.627660] [G loss: 0.800232]\n",
            "[Epoch 36/50] [Batch 55/59] [D loss: 0.616755] [G loss: 0.745387]\n",
            "[Epoch 36/50] [Batch 56/59] [D loss: 0.621142] [G loss: 0.832984]\n",
            "[Epoch 36/50] [Batch 57/59] [D loss: 0.621812] [G loss: 0.872873]\n",
            "[Epoch 36/50] [Batch 58/59] [D loss: 0.625100] [G loss: 0.782646]\n",
            "[Epoch 37/50] [Batch 0/59] [D loss: 0.648189] [G loss: 0.744493]\n",
            "[Epoch 37/50] [Batch 1/59] [D loss: 0.669331] [G loss: 0.762400]\n",
            "[Epoch 37/50] [Batch 2/59] [D loss: 0.705497] [G loss: 0.728923]\n",
            "[Epoch 37/50] [Batch 3/59] [D loss: 0.700329] [G loss: 0.762154]\n",
            "[Epoch 37/50] [Batch 4/59] [D loss: 0.699610] [G loss: 0.755009]\n",
            "[Epoch 37/50] [Batch 5/59] [D loss: 0.714750] [G loss: 0.694821]\n",
            "[Epoch 37/50] [Batch 6/59] [D loss: 0.704207] [G loss: 0.781506]\n",
            "[Epoch 37/50] [Batch 7/59] [D loss: 0.684968] [G loss: 0.796633]\n",
            "[Epoch 37/50] [Batch 8/59] [D loss: 0.666445] [G loss: 0.722303]\n",
            "[Epoch 37/50] [Batch 9/59] [D loss: 0.689229] [G loss: 0.651131]\n",
            "[Epoch 37/50] [Batch 10/59] [D loss: 0.655224] [G loss: 0.895536]\n",
            "[Epoch 37/50] [Batch 11/59] [D loss: 0.661680] [G loss: 0.852529]\n",
            "[Epoch 37/50] [Batch 12/59] [D loss: 0.663427] [G loss: 0.652363]\n",
            "[Epoch 37/50] [Batch 13/59] [D loss: 0.641003] [G loss: 0.772214]\n",
            "[Epoch 37/50] [Batch 14/59] [D loss: 0.622604] [G loss: 0.910044]\n",
            "[Epoch 37/50] [Batch 15/59] [D loss: 0.608274] [G loss: 0.831198]\n",
            "[Epoch 37/50] [Batch 16/59] [D loss: 0.607725] [G loss: 0.764785]\n",
            "[Epoch 37/50] [Batch 17/59] [D loss: 0.615620] [G loss: 0.894747]\n",
            "[Epoch 37/50] [Batch 18/59] [D loss: 0.608946] [G loss: 0.826818]\n",
            "[Epoch 37/50] [Batch 19/59] [D loss: 0.629628] [G loss: 0.793510]\n",
            "[Epoch 37/50] [Batch 20/59] [D loss: 0.621813] [G loss: 0.862182]\n",
            "[Epoch 37/50] [Batch 21/59] [D loss: 0.652549] [G loss: 0.763937]\n",
            "[Epoch 37/50] [Batch 22/59] [D loss: 0.660882] [G loss: 0.676687]\n",
            "[Epoch 37/50] [Batch 23/59] [D loss: 0.662120] [G loss: 0.740579]\n",
            "[Epoch 37/50] [Batch 24/59] [D loss: 0.683308] [G loss: 0.812990]\n",
            "[Epoch 37/50] [Batch 25/59] [D loss: 0.675979] [G loss: 0.770005]\n",
            "[Epoch 37/50] [Batch 26/59] [D loss: 0.687616] [G loss: 0.668180]\n",
            "[Epoch 37/50] [Batch 27/59] [D loss: 0.706357] [G loss: 0.587463]\n",
            "[Epoch 37/50] [Batch 28/59] [D loss: 0.661643] [G loss: 0.788852]\n",
            "[Epoch 37/50] [Batch 29/59] [D loss: 0.693416] [G loss: 0.850641]\n",
            "[Epoch 37/50] [Batch 30/59] [D loss: 0.684584] [G loss: 0.763675]\n",
            "[Epoch 37/50] [Batch 31/59] [D loss: 0.662683] [G loss: 0.693838]\n",
            "[Epoch 37/50] [Batch 32/59] [D loss: 0.640763] [G loss: 0.776065]\n",
            "[Epoch 37/50] [Batch 33/59] [D loss: 0.661661] [G loss: 0.839288]\n",
            "[Epoch 37/50] [Batch 34/59] [D loss: 0.641102] [G loss: 0.786483]\n",
            "[Epoch 37/50] [Batch 35/59] [D loss: 0.627113] [G loss: 0.730328]\n",
            "[Epoch 37/50] [Batch 36/59] [D loss: 0.640006] [G loss: 0.774819]\n",
            "[Epoch 37/50] [Batch 37/59] [D loss: 0.645490] [G loss: 0.801532]\n",
            "[Epoch 37/50] [Batch 38/59] [D loss: 0.632503] [G loss: 0.831434]\n",
            "[Epoch 37/50] [Batch 39/59] [D loss: 0.626740] [G loss: 0.770472]\n",
            "[Epoch 37/50] [Batch 40/59] [D loss: 0.633871] [G loss: 0.711565]\n",
            "[Epoch 37/50] [Batch 41/59] [D loss: 0.648388] [G loss: 0.753545]\n",
            "[Epoch 37/50] [Batch 42/59] [D loss: 0.666096] [G loss: 0.740571]\n",
            "[Epoch 37/50] [Batch 43/59] [D loss: 0.648577] [G loss: 0.807963]\n",
            "[Epoch 37/50] [Batch 44/59] [D loss: 0.646574] [G loss: 0.814509]\n",
            "[Epoch 37/50] [Batch 45/59] [D loss: 0.652912] [G loss: 0.744002]\n",
            "[Epoch 37/50] [Batch 46/59] [D loss: 0.650052] [G loss: 0.708631]\n",
            "[Epoch 37/50] [Batch 47/59] [D loss: 0.669091] [G loss: 0.796611]\n",
            "[Epoch 37/50] [Batch 48/59] [D loss: 0.650480] [G loss: 0.849549]\n",
            "[Epoch 37/50] [Batch 49/59] [D loss: 0.663097] [G loss: 0.793690]\n",
            "[Epoch 37/50] [Batch 50/59] [D loss: 0.670701] [G loss: 0.755218]\n",
            "[Epoch 37/50] [Batch 51/59] [D loss: 0.639775] [G loss: 0.763675]\n",
            "[Epoch 37/50] [Batch 52/59] [D loss: 0.653824] [G loss: 0.843386]\n",
            "[Epoch 37/50] [Batch 53/59] [D loss: 0.646790] [G loss: 0.762710]\n",
            "[Epoch 37/50] [Batch 54/59] [D loss: 0.649593] [G loss: 0.745257]\n",
            "[Epoch 37/50] [Batch 55/59] [D loss: 0.652255] [G loss: 0.760433]\n",
            "[Epoch 37/50] [Batch 56/59] [D loss: 0.659828] [G loss: 0.837675]\n",
            "[Epoch 37/50] [Batch 57/59] [D loss: 0.660365] [G loss: 0.797236]\n",
            "[Epoch 37/50] [Batch 58/59] [D loss: 0.661943] [G loss: 0.759329]\n",
            "[Epoch 38/50] [Batch 0/59] [D loss: 0.659665] [G loss: 0.733699]\n",
            "[Epoch 38/50] [Batch 1/59] [D loss: 0.659310] [G loss: 0.836892]\n",
            "[Epoch 38/50] [Batch 2/59] [D loss: 0.636841] [G loss: 0.799092]\n",
            "[Epoch 38/50] [Batch 3/59] [D loss: 0.651878] [G loss: 0.712637]\n",
            "[Epoch 38/50] [Batch 4/59] [D loss: 0.650100] [G loss: 0.833332]\n",
            "[Epoch 38/50] [Batch 5/59] [D loss: 0.674615] [G loss: 0.823009]\n",
            "[Epoch 38/50] [Batch 6/59] [D loss: 0.675013] [G loss: 0.690018]\n",
            "[Epoch 38/50] [Batch 7/59] [D loss: 0.673458] [G loss: 0.729978]\n",
            "[Epoch 38/50] [Batch 8/59] [D loss: 0.658016] [G loss: 0.800410]\n",
            "[Epoch 38/50] [Batch 9/59] [D loss: 0.676169] [G loss: 0.731205]\n",
            "[Epoch 38/50] [Batch 10/59] [D loss: 0.661454] [G loss: 0.696698]\n",
            "[Epoch 38/50] [Batch 11/59] [D loss: 0.649729] [G loss: 0.825884]\n",
            "[Epoch 38/50] [Batch 12/59] [D loss: 0.647625] [G loss: 0.814151]\n",
            "[Epoch 38/50] [Batch 13/59] [D loss: 0.656388] [G loss: 0.727361]\n",
            "[Epoch 38/50] [Batch 14/59] [D loss: 0.649741] [G loss: 0.745755]\n",
            "[Epoch 38/50] [Batch 15/59] [D loss: 0.636376] [G loss: 0.832676]\n",
            "[Epoch 38/50] [Batch 16/59] [D loss: 0.628877] [G loss: 0.846734]\n",
            "[Epoch 38/50] [Batch 17/59] [D loss: 0.622510] [G loss: 0.729510]\n",
            "[Epoch 38/50] [Batch 18/59] [D loss: 0.633663] [G loss: 0.701981]\n",
            "[Epoch 38/50] [Batch 19/59] [D loss: 0.643291] [G loss: 0.782439]\n",
            "[Epoch 38/50] [Batch 20/59] [D loss: 0.650799] [G loss: 0.804442]\n",
            "[Epoch 38/50] [Batch 21/59] [D loss: 0.654169] [G loss: 0.728530]\n",
            "[Epoch 38/50] [Batch 22/59] [D loss: 0.646819] [G loss: 0.755319]\n",
            "[Epoch 38/50] [Batch 23/59] [D loss: 0.646797] [G loss: 0.836218]\n",
            "[Epoch 38/50] [Batch 24/59] [D loss: 0.671450] [G loss: 0.780926]\n",
            "[Epoch 38/50] [Batch 25/59] [D loss: 0.656189] [G loss: 0.735631]\n",
            "[Epoch 38/50] [Batch 26/59] [D loss: 0.662859] [G loss: 0.715859]\n",
            "[Epoch 38/50] [Batch 27/59] [D loss: 0.685321] [G loss: 0.816601]\n",
            "[Epoch 38/50] [Batch 28/59] [D loss: 0.665647] [G loss: 0.788658]\n",
            "[Epoch 38/50] [Batch 29/59] [D loss: 0.664982] [G loss: 0.769531]\n",
            "[Epoch 38/50] [Batch 30/59] [D loss: 0.666704] [G loss: 0.640425]\n",
            "[Epoch 38/50] [Batch 31/59] [D loss: 0.677281] [G loss: 0.761399]\n",
            "[Epoch 38/50] [Batch 32/59] [D loss: 0.656479] [G loss: 0.873286]\n",
            "[Epoch 38/50] [Batch 33/59] [D loss: 0.653915] [G loss: 0.793713]\n",
            "[Epoch 38/50] [Batch 34/59] [D loss: 0.661112] [G loss: 0.690499]\n",
            "[Epoch 38/50] [Batch 35/59] [D loss: 0.655987] [G loss: 0.699572]\n",
            "[Epoch 38/50] [Batch 36/59] [D loss: 0.653438] [G loss: 0.899748]\n",
            "[Epoch 38/50] [Batch 37/59] [D loss: 0.631677] [G loss: 0.810897]\n",
            "[Epoch 38/50] [Batch 38/59] [D loss: 0.627111] [G loss: 0.722352]\n",
            "[Epoch 38/50] [Batch 39/59] [D loss: 0.646860] [G loss: 0.685015]\n",
            "[Epoch 38/50] [Batch 40/59] [D loss: 0.648403] [G loss: 0.796225]\n",
            "[Epoch 38/50] [Batch 41/59] [D loss: 0.632197] [G loss: 0.805025]\n",
            "[Epoch 38/50] [Batch 42/59] [D loss: 0.630257] [G loss: 0.818311]\n",
            "[Epoch 38/50] [Batch 43/59] [D loss: 0.645304] [G loss: 0.700927]\n",
            "[Epoch 38/50] [Batch 44/59] [D loss: 0.664099] [G loss: 0.775535]\n",
            "[Epoch 38/50] [Batch 45/59] [D loss: 0.659401] [G loss: 0.848408]\n",
            "[Epoch 38/50] [Batch 46/59] [D loss: 0.669470] [G loss: 0.740326]\n",
            "[Epoch 38/50] [Batch 47/59] [D loss: 0.667628] [G loss: 0.723108]\n",
            "[Epoch 38/50] [Batch 48/59] [D loss: 0.656822] [G loss: 0.776965]\n",
            "[Epoch 38/50] [Batch 49/59] [D loss: 0.678315] [G loss: 0.776076]\n",
            "[Epoch 38/50] [Batch 50/59] [D loss: 0.669112] [G loss: 0.826693]\n",
            "[Epoch 38/50] [Batch 51/59] [D loss: 0.675464] [G loss: 0.710277]\n",
            "[Epoch 38/50] [Batch 52/59] [D loss: 0.681541] [G loss: 0.769735]\n",
            "[Epoch 38/50] [Batch 53/59] [D loss: 0.662462] [G loss: 0.821557]\n",
            "[Epoch 38/50] [Batch 54/59] [D loss: 0.655804] [G loss: 0.780265]\n",
            "[Epoch 38/50] [Batch 55/59] [D loss: 0.650110] [G loss: 0.734684]\n",
            "[Epoch 38/50] [Batch 56/59] [D loss: 0.652123] [G loss: 0.717501]\n",
            "[Epoch 38/50] [Batch 57/59] [D loss: 0.661377] [G loss: 0.801587]\n",
            "[Epoch 38/50] [Batch 58/59] [D loss: 0.643716] [G loss: 0.817134]\n",
            "[Epoch 39/50] [Batch 0/59] [D loss: 0.623504] [G loss: 0.793201]\n",
            "[Epoch 39/50] [Batch 1/59] [D loss: 0.630784] [G loss: 0.753875]\n",
            "[Epoch 39/50] [Batch 2/59] [D loss: 0.651370] [G loss: 0.724076]\n",
            "[Epoch 39/50] [Batch 3/59] [D loss: 0.625273] [G loss: 0.858946]\n",
            "[Epoch 39/50] [Batch 4/59] [D loss: 0.639895] [G loss: 0.837120]\n",
            "[Epoch 39/50] [Batch 5/59] [D loss: 0.621597] [G loss: 0.814645]\n",
            "[Epoch 39/50] [Batch 6/59] [D loss: 0.634330] [G loss: 0.723527]\n",
            "[Epoch 39/50] [Batch 7/59] [D loss: 0.646909] [G loss: 0.796574]\n",
            "[Epoch 39/50] [Batch 8/59] [D loss: 0.631509] [G loss: 0.883958]\n",
            "[Epoch 39/50] [Batch 9/59] [D loss: 0.633807] [G loss: 0.829589]\n",
            "[Epoch 39/50] [Batch 10/59] [D loss: 0.651131] [G loss: 0.698370]\n",
            "[Epoch 39/50] [Batch 11/59] [D loss: 0.649932] [G loss: 0.724627]\n",
            "[Epoch 39/50] [Batch 12/59] [D loss: 0.676621] [G loss: 0.875000]\n",
            "[Epoch 39/50] [Batch 13/59] [D loss: 0.654770] [G loss: 0.817848]\n",
            "[Epoch 39/50] [Batch 14/59] [D loss: 0.676089] [G loss: 0.744359]\n",
            "[Epoch 39/50] [Batch 15/59] [D loss: 0.678617] [G loss: 0.744184]\n",
            "[Epoch 39/50] [Batch 16/59] [D loss: 0.674722] [G loss: 0.722277]\n",
            "[Epoch 39/50] [Batch 17/59] [D loss: 0.675201] [G loss: 0.723835]\n",
            "[Epoch 39/50] [Batch 18/59] [D loss: 0.679342] [G loss: 0.797741]\n",
            "[Epoch 39/50] [Batch 19/59] [D loss: 0.656723] [G loss: 0.736994]\n",
            "[Epoch 39/50] [Batch 20/59] [D loss: 0.638974] [G loss: 0.738277]\n",
            "[Epoch 39/50] [Batch 21/59] [D loss: 0.644864] [G loss: 0.730272]\n",
            "[Epoch 39/50] [Batch 22/59] [D loss: 0.636943] [G loss: 0.785303]\n",
            "[Epoch 39/50] [Batch 23/59] [D loss: 0.628748] [G loss: 0.810805]\n",
            "[Epoch 39/50] [Batch 24/59] [D loss: 0.624425] [G loss: 0.782670]\n",
            "[Epoch 39/50] [Batch 25/59] [D loss: 0.617806] [G loss: 0.784257]\n",
            "[Epoch 39/50] [Batch 26/59] [D loss: 0.640904] [G loss: 0.783193]\n",
            "[Epoch 39/50] [Batch 27/59] [D loss: 0.644979] [G loss: 0.792744]\n",
            "[Epoch 39/50] [Batch 28/59] [D loss: 0.635338] [G loss: 0.749938]\n",
            "[Epoch 39/50] [Batch 29/59] [D loss: 0.629735] [G loss: 0.760490]\n",
            "[Epoch 39/50] [Batch 30/59] [D loss: 0.644744] [G loss: 0.826711]\n",
            "[Epoch 39/50] [Batch 31/59] [D loss: 0.661770] [G loss: 0.779520]\n",
            "[Epoch 39/50] [Batch 32/59] [D loss: 0.665414] [G loss: 0.660816]\n",
            "[Epoch 39/50] [Batch 33/59] [D loss: 0.671560] [G loss: 0.762012]\n",
            "[Epoch 39/50] [Batch 34/59] [D loss: 0.681870] [G loss: 0.795019]\n",
            "[Epoch 39/50] [Batch 35/59] [D loss: 0.689081] [G loss: 0.706239]\n",
            "[Epoch 39/50] [Batch 36/59] [D loss: 0.688033] [G loss: 0.735133]\n",
            "[Epoch 39/50] [Batch 37/59] [D loss: 0.682211] [G loss: 0.770303]\n",
            "[Epoch 39/50] [Batch 38/59] [D loss: 0.695750] [G loss: 0.727312]\n",
            "[Epoch 39/50] [Batch 39/59] [D loss: 0.695247] [G loss: 0.755497]\n",
            "[Epoch 39/50] [Batch 40/59] [D loss: 0.677720] [G loss: 0.714552]\n",
            "[Epoch 39/50] [Batch 41/59] [D loss: 0.645647] [G loss: 0.747747]\n",
            "[Epoch 39/50] [Batch 42/59] [D loss: 0.654824] [G loss: 0.794727]\n",
            "[Epoch 39/50] [Batch 43/59] [D loss: 0.647749] [G loss: 0.791263]\n",
            "[Epoch 39/50] [Batch 44/59] [D loss: 0.628803] [G loss: 0.761385]\n",
            "[Epoch 39/50] [Batch 45/59] [D loss: 0.644179] [G loss: 0.805217]\n",
            "[Epoch 39/50] [Batch 46/59] [D loss: 0.645676] [G loss: 0.827779]\n",
            "[Epoch 39/50] [Batch 47/59] [D loss: 0.614340] [G loss: 0.918118]\n",
            "[Epoch 39/50] [Batch 48/59] [D loss: 0.627272] [G loss: 0.837304]\n",
            "[Epoch 39/50] [Batch 49/59] [D loss: 0.626752] [G loss: 0.744836]\n",
            "[Epoch 39/50] [Batch 50/59] [D loss: 0.615331] [G loss: 0.791033]\n",
            "[Epoch 39/50] [Batch 51/59] [D loss: 0.627148] [G loss: 0.862427]\n",
            "[Epoch 39/50] [Batch 52/59] [D loss: 0.628458] [G loss: 0.815211]\n",
            "[Epoch 39/50] [Batch 53/59] [D loss: 0.630368] [G loss: 0.770046]\n",
            "[Epoch 39/50] [Batch 54/59] [D loss: 0.632319] [G loss: 0.724339]\n",
            "[Epoch 39/50] [Batch 55/59] [D loss: 0.645887] [G loss: 0.742734]\n",
            "[Epoch 39/50] [Batch 56/59] [D loss: 0.674484] [G loss: 0.778630]\n",
            "[Epoch 39/50] [Batch 57/59] [D loss: 0.671572] [G loss: 0.799079]\n",
            "[Epoch 39/50] [Batch 58/59] [D loss: 0.677304] [G loss: 0.770699]\n",
            "[Epoch 40/50] [Batch 0/59] [D loss: 0.660964] [G loss: 0.752636]\n",
            "[Epoch 40/50] [Batch 1/59] [D loss: 0.654118] [G loss: 0.768700]\n",
            "[Epoch 40/50] [Batch 2/59] [D loss: 0.670691] [G loss: 0.729347]\n",
            "[Epoch 40/50] [Batch 3/59] [D loss: 0.662110] [G loss: 0.764381]\n",
            "[Epoch 40/50] [Batch 4/59] [D loss: 0.672337] [G loss: 0.828811]\n",
            "[Epoch 40/50] [Batch 5/59] [D loss: 0.677483] [G loss: 0.710601]\n",
            "[Epoch 40/50] [Batch 6/59] [D loss: 0.658039] [G loss: 0.729727]\n",
            "[Epoch 40/50] [Batch 7/59] [D loss: 0.656631] [G loss: 0.803906]\n",
            "[Epoch 40/50] [Batch 8/59] [D loss: 0.640555] [G loss: 0.789294]\n",
            "[Epoch 40/50] [Batch 9/59] [D loss: 0.645752] [G loss: 0.732129]\n",
            "[Epoch 40/50] [Batch 10/59] [D loss: 0.643884] [G loss: 0.781459]\n",
            "[Epoch 40/50] [Batch 11/59] [D loss: 0.627770] [G loss: 0.761398]\n",
            "[Epoch 40/50] [Batch 12/59] [D loss: 0.636166] [G loss: 0.812787]\n",
            "[Epoch 40/50] [Batch 13/59] [D loss: 0.641427] [G loss: 0.758387]\n",
            "[Epoch 40/50] [Batch 14/59] [D loss: 0.647010] [G loss: 0.772440]\n",
            "[Epoch 40/50] [Batch 15/59] [D loss: 0.629495] [G loss: 0.770620]\n",
            "[Epoch 40/50] [Batch 16/59] [D loss: 0.625288] [G loss: 0.767850]\n",
            "[Epoch 40/50] [Batch 17/59] [D loss: 0.624844] [G loss: 0.772864]\n",
            "[Epoch 40/50] [Batch 18/59] [D loss: 0.645340] [G loss: 0.785012]\n",
            "[Epoch 40/50] [Batch 19/59] [D loss: 0.647059] [G loss: 0.764837]\n",
            "[Epoch 40/50] [Batch 20/59] [D loss: 0.642048] [G loss: 0.796209]\n",
            "[Epoch 40/50] [Batch 21/59] [D loss: 0.668659] [G loss: 0.799945]\n",
            "[Epoch 40/50] [Batch 22/59] [D loss: 0.656397] [G loss: 0.717345]\n",
            "[Epoch 40/50] [Batch 23/59] [D loss: 0.657866] [G loss: 0.797235]\n",
            "[Epoch 40/50] [Batch 24/59] [D loss: 0.656501] [G loss: 0.804075]\n",
            "[Epoch 40/50] [Batch 25/59] [D loss: 0.648811] [G loss: 0.755172]\n",
            "[Epoch 40/50] [Batch 26/59] [D loss: 0.680712] [G loss: 0.660184]\n",
            "[Epoch 40/50] [Batch 27/59] [D loss: 0.669417] [G loss: 0.781361]\n",
            "[Epoch 40/50] [Batch 28/59] [D loss: 0.660057] [G loss: 0.800618]\n",
            "[Epoch 40/50] [Batch 29/59] [D loss: 0.671974] [G loss: 0.738054]\n",
            "[Epoch 40/50] [Batch 30/59] [D loss: 0.679973] [G loss: 0.725935]\n",
            "[Epoch 40/50] [Batch 31/59] [D loss: 0.642608] [G loss: 0.831935]\n",
            "[Epoch 40/50] [Batch 32/59] [D loss: 0.644917] [G loss: 0.749281]\n",
            "[Epoch 40/50] [Batch 33/59] [D loss: 0.648494] [G loss: 0.715370]\n",
            "[Epoch 40/50] [Batch 34/59] [D loss: 0.632541] [G loss: 0.797140]\n",
            "[Epoch 40/50] [Batch 35/59] [D loss: 0.639656] [G loss: 0.847816]\n",
            "[Epoch 40/50] [Batch 36/59] [D loss: 0.648355] [G loss: 0.793473]\n",
            "[Epoch 40/50] [Batch 37/59] [D loss: 0.628760] [G loss: 0.719980]\n",
            "[Epoch 40/50] [Batch 38/59] [D loss: 0.629804] [G loss: 0.777996]\n",
            "[Epoch 40/50] [Batch 39/59] [D loss: 0.641646] [G loss: 0.878641]\n",
            "[Epoch 40/50] [Batch 40/59] [D loss: 0.663193] [G loss: 0.818333]\n",
            "[Epoch 40/50] [Batch 41/59] [D loss: 0.650281] [G loss: 0.707024]\n",
            "[Epoch 40/50] [Batch 42/59] [D loss: 0.662846] [G loss: 0.716027]\n",
            "[Epoch 40/50] [Batch 43/59] [D loss: 0.639655] [G loss: 0.761311]\n",
            "[Epoch 40/50] [Batch 44/59] [D loss: 0.659353] [G loss: 0.775032]\n",
            "[Epoch 40/50] [Batch 45/59] [D loss: 0.682269] [G loss: 0.700390]\n",
            "[Epoch 40/50] [Batch 46/59] [D loss: 0.645760] [G loss: 0.765755]\n",
            "[Epoch 40/50] [Batch 47/59] [D loss: 0.655389] [G loss: 0.791003]\n",
            "[Epoch 40/50] [Batch 48/59] [D loss: 0.671802] [G loss: 0.801283]\n",
            "[Epoch 40/50] [Batch 49/59] [D loss: 0.638874] [G loss: 0.753422]\n",
            "[Epoch 40/50] [Batch 50/59] [D loss: 0.631808] [G loss: 0.786087]\n",
            "[Epoch 40/50] [Batch 51/59] [D loss: 0.636793] [G loss: 0.800111]\n",
            "[Epoch 40/50] [Batch 52/59] [D loss: 0.634816] [G loss: 0.752218]\n",
            "[Epoch 40/50] [Batch 53/59] [D loss: 0.635212] [G loss: 0.778621]\n",
            "[Epoch 40/50] [Batch 54/59] [D loss: 0.637908] [G loss: 0.839492]\n",
            "[Epoch 40/50] [Batch 55/59] [D loss: 0.667339] [G loss: 0.673700]\n",
            "[Epoch 40/50] [Batch 56/59] [D loss: 0.645075] [G loss: 0.773272]\n",
            "[Epoch 40/50] [Batch 57/59] [D loss: 0.651990] [G loss: 0.849061]\n",
            "[Epoch 40/50] [Batch 58/59] [D loss: 0.645352] [G loss: 0.705062]\n",
            "[Epoch 41/50] [Batch 0/59] [D loss: 0.655417] [G loss: 0.718191]\n",
            "[Epoch 41/50] [Batch 1/59] [D loss: 0.676484] [G loss: 0.773579]\n",
            "[Epoch 41/50] [Batch 2/59] [D loss: 0.652111] [G loss: 0.783391]\n",
            "[Epoch 41/50] [Batch 3/59] [D loss: 0.646679] [G loss: 0.767192]\n",
            "[Epoch 41/50] [Batch 4/59] [D loss: 0.661959] [G loss: 0.825042]\n",
            "[Epoch 41/50] [Batch 5/59] [D loss: 0.657967] [G loss: 0.761659]\n",
            "[Epoch 41/50] [Batch 6/59] [D loss: 0.654632] [G loss: 0.722301]\n",
            "[Epoch 41/50] [Batch 7/59] [D loss: 0.649575] [G loss: 0.786111]\n",
            "[Epoch 41/50] [Batch 8/59] [D loss: 0.646777] [G loss: 0.777441]\n",
            "[Epoch 41/50] [Batch 9/59] [D loss: 0.633767] [G loss: 0.737867]\n",
            "[Epoch 41/50] [Batch 10/59] [D loss: 0.655258] [G loss: 0.832405]\n",
            "[Epoch 41/50] [Batch 11/59] [D loss: 0.655813] [G loss: 0.773645]\n",
            "[Epoch 41/50] [Batch 12/59] [D loss: 0.626091] [G loss: 0.771235]\n",
            "[Epoch 41/50] [Batch 13/59] [D loss: 0.643005] [G loss: 0.787269]\n",
            "[Epoch 41/50] [Batch 14/59] [D loss: 0.636904] [G loss: 0.824466]\n",
            "[Epoch 41/50] [Batch 15/59] [D loss: 0.643262] [G loss: 0.771448]\n",
            "[Epoch 41/50] [Batch 16/59] [D loss: 0.634411] [G loss: 0.810284]\n",
            "[Epoch 41/50] [Batch 17/59] [D loss: 0.664504] [G loss: 0.737785]\n",
            "[Epoch 41/50] [Batch 18/59] [D loss: 0.644472] [G loss: 0.760553]\n",
            "[Epoch 41/50] [Batch 19/59] [D loss: 0.653575] [G loss: 0.859529]\n",
            "[Epoch 41/50] [Batch 20/59] [D loss: 0.668974] [G loss: 0.747212]\n",
            "[Epoch 41/50] [Batch 21/59] [D loss: 0.655894] [G loss: 0.755924]\n",
            "[Epoch 41/50] [Batch 22/59] [D loss: 0.653250] [G loss: 0.737632]\n",
            "[Epoch 41/50] [Batch 23/59] [D loss: 0.640470] [G loss: 0.782544]\n",
            "[Epoch 41/50] [Batch 24/59] [D loss: 0.647487] [G loss: 0.849976]\n",
            "[Epoch 41/50] [Batch 25/59] [D loss: 0.650261] [G loss: 0.787065]\n",
            "[Epoch 41/50] [Batch 26/59] [D loss: 0.667420] [G loss: 0.678999]\n",
            "[Epoch 41/50] [Batch 27/59] [D loss: 0.625838] [G loss: 0.791223]\n",
            "[Epoch 41/50] [Batch 28/59] [D loss: 0.651144] [G loss: 0.830820]\n",
            "[Epoch 41/50] [Batch 29/59] [D loss: 0.637814] [G loss: 0.798415]\n",
            "[Epoch 41/50] [Batch 30/59] [D loss: 0.661788] [G loss: 0.690242]\n",
            "[Epoch 41/50] [Batch 31/59] [D loss: 0.659893] [G loss: 0.770224]\n",
            "[Epoch 41/50] [Batch 32/59] [D loss: 0.658920] [G loss: 0.777405]\n",
            "[Epoch 41/50] [Batch 33/59] [D loss: 0.656657] [G loss: 0.799144]\n",
            "[Epoch 41/50] [Batch 34/59] [D loss: 0.642201] [G loss: 0.684889]\n",
            "[Epoch 41/50] [Batch 35/59] [D loss: 0.680538] [G loss: 0.714260]\n",
            "[Epoch 41/50] [Batch 36/59] [D loss: 0.661720] [G loss: 0.805476]\n",
            "[Epoch 41/50] [Batch 37/59] [D loss: 0.657050] [G loss: 0.796514]\n",
            "[Epoch 41/50] [Batch 38/59] [D loss: 0.657861] [G loss: 0.645750]\n",
            "[Epoch 41/50] [Batch 39/59] [D loss: 0.670454] [G loss: 0.736790]\n",
            "[Epoch 41/50] [Batch 40/59] [D loss: 0.644989] [G loss: 0.860293]\n",
            "[Epoch 41/50] [Batch 41/59] [D loss: 0.625736] [G loss: 0.800926]\n",
            "[Epoch 41/50] [Batch 42/59] [D loss: 0.642121] [G loss: 0.703352]\n",
            "[Epoch 41/50] [Batch 43/59] [D loss: 0.626228] [G loss: 0.813945]\n",
            "[Epoch 41/50] [Batch 44/59] [D loss: 0.603746] [G loss: 0.869379]\n",
            "[Epoch 41/50] [Batch 45/59] [D loss: 0.637260] [G loss: 0.780272]\n",
            "[Epoch 41/50] [Batch 46/59] [D loss: 0.626734] [G loss: 0.672777]\n",
            "[Epoch 41/50] [Batch 47/59] [D loss: 0.645866] [G loss: 0.845043]\n",
            "[Epoch 41/50] [Batch 48/59] [D loss: 0.657173] [G loss: 0.851613]\n",
            "[Epoch 41/50] [Batch 49/59] [D loss: 0.670242] [G loss: 0.731668]\n",
            "[Epoch 41/50] [Batch 50/59] [D loss: 0.676311] [G loss: 0.687852]\n",
            "[Epoch 41/50] [Batch 51/59] [D loss: 0.667475] [G loss: 0.871382]\n",
            "[Epoch 41/50] [Batch 52/59] [D loss: 0.674994] [G loss: 0.793946]\n",
            "[Epoch 41/50] [Batch 53/59] [D loss: 0.667970] [G loss: 0.689242]\n",
            "[Epoch 41/50] [Batch 54/59] [D loss: 0.671493] [G loss: 0.696388]\n",
            "[Epoch 41/50] [Batch 55/59] [D loss: 0.652627] [G loss: 0.842465]\n",
            "[Epoch 41/50] [Batch 56/59] [D loss: 0.656431] [G loss: 0.860827]\n",
            "[Epoch 41/50] [Batch 57/59] [D loss: 0.649293] [G loss: 0.762389]\n",
            "[Epoch 41/50] [Batch 58/59] [D loss: 0.630285] [G loss: 0.774682]\n",
            "[Epoch 42/50] [Batch 0/59] [D loss: 0.620774] [G loss: 0.869193]\n",
            "[Epoch 42/50] [Batch 1/59] [D loss: 0.606255] [G loss: 0.884928]\n",
            "[Epoch 42/50] [Batch 2/59] [D loss: 0.634674] [G loss: 0.829874]\n",
            "[Epoch 42/50] [Batch 3/59] [D loss: 0.616154] [G loss: 0.817696]\n",
            "[Epoch 42/50] [Batch 4/59] [D loss: 0.624985] [G loss: 0.813300]\n",
            "[Epoch 42/50] [Batch 5/59] [D loss: 0.624131] [G loss: 0.849902]\n",
            "[Epoch 42/50] [Batch 6/59] [D loss: 0.645141] [G loss: 0.793550]\n",
            "[Epoch 42/50] [Batch 7/59] [D loss: 0.652976] [G loss: 0.776615]\n",
            "[Epoch 42/50] [Batch 8/59] [D loss: 0.660371] [G loss: 0.752061]\n",
            "[Epoch 42/50] [Batch 9/59] [D loss: 0.650701] [G loss: 0.742220]\n",
            "[Epoch 42/50] [Batch 10/59] [D loss: 0.667256] [G loss: 0.779050]\n",
            "[Epoch 42/50] [Batch 11/59] [D loss: 0.661355] [G loss: 0.772299]\n",
            "[Epoch 42/50] [Batch 12/59] [D loss: 0.632370] [G loss: 0.769649]\n",
            "[Epoch 42/50] [Batch 13/59] [D loss: 0.653661] [G loss: 0.710889]\n",
            "[Epoch 42/50] [Batch 14/59] [D loss: 0.647416] [G loss: 0.821024]\n",
            "[Epoch 42/50] [Batch 15/59] [D loss: 0.646783] [G loss: 0.854645]\n",
            "[Epoch 42/50] [Batch 16/59] [D loss: 0.626583] [G loss: 0.783653]\n",
            "[Epoch 42/50] [Batch 17/59] [D loss: 0.605873] [G loss: 0.738191]\n",
            "[Epoch 42/50] [Batch 18/59] [D loss: 0.607722] [G loss: 0.810387]\n",
            "[Epoch 42/50] [Batch 19/59] [D loss: 0.625868] [G loss: 0.671156]\n",
            "[Epoch 42/50] [Batch 20/59] [D loss: 0.645677] [G loss: 0.834909]\n",
            "[Epoch 42/50] [Batch 21/59] [D loss: 0.654325] [G loss: 0.774474]\n",
            "[Epoch 42/50] [Batch 22/59] [D loss: 0.637591] [G loss: 0.754152]\n",
            "[Epoch 42/50] [Batch 23/59] [D loss: 0.668254] [G loss: 0.746649]\n",
            "[Epoch 42/50] [Batch 24/59] [D loss: 0.671718] [G loss: 0.805780]\n",
            "[Epoch 42/50] [Batch 25/59] [D loss: 0.671056] [G loss: 0.707853]\n",
            "[Epoch 42/50] [Batch 26/59] [D loss: 0.669810] [G loss: 0.681752]\n",
            "[Epoch 42/50] [Batch 27/59] [D loss: 0.668134] [G loss: 0.714625]\n",
            "[Epoch 42/50] [Batch 28/59] [D loss: 0.680967] [G loss: 0.836241]\n",
            "[Epoch 42/50] [Batch 29/59] [D loss: 0.665723] [G loss: 0.761079]\n",
            "[Epoch 42/50] [Batch 30/59] [D loss: 0.649836] [G loss: 0.756957]\n",
            "[Epoch 42/50] [Batch 31/59] [D loss: 0.636926] [G loss: 0.778515]\n",
            "[Epoch 42/50] [Batch 32/59] [D loss: 0.622980] [G loss: 0.864468]\n",
            "[Epoch 42/50] [Batch 33/59] [D loss: 0.624437] [G loss: 0.837050]\n",
            "[Epoch 42/50] [Batch 34/59] [D loss: 0.602496] [G loss: 0.711211]\n",
            "[Epoch 42/50] [Batch 35/59] [D loss: 0.605984] [G loss: 0.813930]\n",
            "[Epoch 42/50] [Batch 36/59] [D loss: 0.617921] [G loss: 0.901310]\n",
            "[Epoch 42/50] [Batch 37/59] [D loss: 0.621718] [G loss: 0.814931]\n",
            "[Epoch 42/50] [Batch 38/59] [D loss: 0.614139] [G loss: 0.737368]\n",
            "[Epoch 42/50] [Batch 39/59] [D loss: 0.636338] [G loss: 0.790168]\n",
            "[Epoch 42/50] [Batch 40/59] [D loss: 0.636517] [G loss: 0.821620]\n",
            "[Epoch 42/50] [Batch 41/59] [D loss: 0.644379] [G loss: 0.804673]\n",
            "[Epoch 42/50] [Batch 42/59] [D loss: 0.683747] [G loss: 0.727377]\n",
            "[Epoch 42/50] [Batch 43/59] [D loss: 0.675238] [G loss: 0.785343]\n",
            "[Epoch 42/50] [Batch 44/59] [D loss: 0.643314] [G loss: 0.818636]\n",
            "[Epoch 42/50] [Batch 45/59] [D loss: 0.678056] [G loss: 0.704042]\n",
            "[Epoch 42/50] [Batch 46/59] [D loss: 0.664253] [G loss: 0.779089]\n",
            "[Epoch 42/50] [Batch 47/59] [D loss: 0.651016] [G loss: 0.852729]\n",
            "[Epoch 42/50] [Batch 48/59] [D loss: 0.672651] [G loss: 0.808368]\n",
            "[Epoch 42/50] [Batch 49/59] [D loss: 0.648266] [G loss: 0.766409]\n",
            "[Epoch 42/50] [Batch 50/59] [D loss: 0.641125] [G loss: 0.782820]\n",
            "[Epoch 42/50] [Batch 51/59] [D loss: 0.626673] [G loss: 0.858299]\n",
            "[Epoch 42/50] [Batch 52/59] [D loss: 0.608668] [G loss: 0.808461]\n",
            "[Epoch 42/50] [Batch 53/59] [D loss: 0.624630] [G loss: 0.778209]\n",
            "[Epoch 42/50] [Batch 54/59] [D loss: 0.628875] [G loss: 0.766838]\n",
            "[Epoch 42/50] [Batch 55/59] [D loss: 0.646219] [G loss: 0.710343]\n",
            "[Epoch 42/50] [Batch 56/59] [D loss: 0.662945] [G loss: 0.806621]\n",
            "[Epoch 42/50] [Batch 57/59] [D loss: 0.652844] [G loss: 0.769718]\n",
            "[Epoch 42/50] [Batch 58/59] [D loss: 0.641787] [G loss: 0.728288]\n",
            "[Epoch 43/50] [Batch 0/59] [D loss: 0.640480] [G loss: 0.800830]\n",
            "[Epoch 43/50] [Batch 1/59] [D loss: 0.657252] [G loss: 0.784452]\n",
            "[Epoch 43/50] [Batch 2/59] [D loss: 0.667674] [G loss: 0.741589]\n",
            "[Epoch 43/50] [Batch 3/59] [D loss: 0.622009] [G loss: 0.801738]\n",
            "[Epoch 43/50] [Batch 4/59] [D loss: 0.642151] [G loss: 0.792311]\n",
            "[Epoch 43/50] [Batch 5/59] [D loss: 0.619693] [G loss: 0.860781]\n",
            "[Epoch 43/50] [Batch 6/59] [D loss: 0.625905] [G loss: 0.849627]\n",
            "[Epoch 43/50] [Batch 7/59] [D loss: 0.605706] [G loss: 0.859357]\n",
            "[Epoch 43/50] [Batch 8/59] [D loss: 0.607163] [G loss: 0.803473]\n",
            "[Epoch 43/50] [Batch 9/59] [D loss: 0.593786] [G loss: 0.832349]\n",
            "[Epoch 43/50] [Batch 10/59] [D loss: 0.597896] [G loss: 0.858531]\n",
            "[Epoch 43/50] [Batch 11/59] [D loss: 0.591495] [G loss: 0.807456]\n",
            "[Epoch 43/50] [Batch 12/59] [D loss: 0.624070] [G loss: 0.786049]\n",
            "[Epoch 43/50] [Batch 13/59] [D loss: 0.639035] [G loss: 0.764172]\n",
            "[Epoch 43/50] [Batch 14/59] [D loss: 0.659174] [G loss: 0.802507]\n",
            "[Epoch 43/50] [Batch 15/59] [D loss: 0.661204] [G loss: 0.806170]\n",
            "[Epoch 43/50] [Batch 16/59] [D loss: 0.646122] [G loss: 0.717174]\n",
            "[Epoch 43/50] [Batch 17/59] [D loss: 0.684499] [G loss: 0.764507]\n",
            "[Epoch 43/50] [Batch 18/59] [D loss: 0.676476] [G loss: 0.739416]\n",
            "[Epoch 43/50] [Batch 19/59] [D loss: 0.654042] [G loss: 0.714805]\n",
            "[Epoch 43/50] [Batch 20/59] [D loss: 0.694942] [G loss: 0.702783]\n",
            "[Epoch 43/50] [Batch 21/59] [D loss: 0.687975] [G loss: 0.670012]\n",
            "[Epoch 43/50] [Batch 22/59] [D loss: 0.673272] [G loss: 0.788555]\n",
            "[Epoch 43/50] [Batch 23/59] [D loss: 0.648957] [G loss: 0.763863]\n",
            "[Epoch 43/50] [Batch 24/59] [D loss: 0.633430] [G loss: 0.679248]\n",
            "[Epoch 43/50] [Batch 25/59] [D loss: 0.645271] [G loss: 0.824290]\n",
            "[Epoch 43/50] [Batch 26/59] [D loss: 0.615991] [G loss: 0.864329]\n",
            "[Epoch 43/50] [Batch 27/59] [D loss: 0.606603] [G loss: 0.825681]\n",
            "[Epoch 43/50] [Batch 28/59] [D loss: 0.596354] [G loss: 0.784478]\n",
            "[Epoch 43/50] [Batch 29/59] [D loss: 0.622867] [G loss: 0.808640]\n",
            "[Epoch 43/50] [Batch 30/59] [D loss: 0.608603] [G loss: 0.866872]\n",
            "[Epoch 43/50] [Batch 31/59] [D loss: 0.604668] [G loss: 0.766750]\n",
            "[Epoch 43/50] [Batch 32/59] [D loss: 0.633950] [G loss: 0.730890]\n",
            "[Epoch 43/50] [Batch 33/59] [D loss: 0.643472] [G loss: 0.821107]\n",
            "[Epoch 43/50] [Batch 34/59] [D loss: 0.657555] [G loss: 0.854229]\n",
            "[Epoch 43/50] [Batch 35/59] [D loss: 0.677555] [G loss: 0.636505]\n",
            "[Epoch 43/50] [Batch 36/59] [D loss: 0.673360] [G loss: 0.815629]\n",
            "[Epoch 43/50] [Batch 37/59] [D loss: 0.686214] [G loss: 0.864959]\n",
            "[Epoch 43/50] [Batch 38/59] [D loss: 0.649053] [G loss: 0.718138]\n",
            "[Epoch 43/50] [Batch 39/59] [D loss: 0.661853] [G loss: 0.820310]\n",
            "[Epoch 43/50] [Batch 40/59] [D loss: 0.654319] [G loss: 0.823815]\n",
            "[Epoch 43/50] [Batch 41/59] [D loss: 0.646488] [G loss: 0.794169]\n",
            "[Epoch 43/50] [Batch 42/59] [D loss: 0.618976] [G loss: 0.862504]\n",
            "[Epoch 43/50] [Batch 43/59] [D loss: 0.598213] [G loss: 0.835864]\n",
            "[Epoch 43/50] [Batch 44/59] [D loss: 0.637617] [G loss: 0.806586]\n",
            "[Epoch 43/50] [Batch 45/59] [D loss: 0.617046] [G loss: 0.858643]\n",
            "[Epoch 43/50] [Batch 46/59] [D loss: 0.611940] [G loss: 0.793366]\n",
            "[Epoch 43/50] [Batch 47/59] [D loss: 0.653896] [G loss: 0.759614]\n",
            "[Epoch 43/50] [Batch 48/59] [D loss: 0.636774] [G loss: 0.816226]\n",
            "[Epoch 43/50] [Batch 49/59] [D loss: 0.660488] [G loss: 0.751447]\n",
            "[Epoch 43/50] [Batch 50/59] [D loss: 0.662725] [G loss: 0.755936]\n",
            "[Epoch 43/50] [Batch 51/59] [D loss: 0.672820] [G loss: 0.760692]\n",
            "[Epoch 43/50] [Batch 52/59] [D loss: 0.669145] [G loss: 0.776871]\n",
            "[Epoch 43/50] [Batch 53/59] [D loss: 0.703339] [G loss: 0.757343]\n",
            "[Epoch 43/50] [Batch 54/59] [D loss: 0.668275] [G loss: 0.734952]\n",
            "[Epoch 43/50] [Batch 55/59] [D loss: 0.656116] [G loss: 0.774788]\n",
            "[Epoch 43/50] [Batch 56/59] [D loss: 0.643424] [G loss: 0.799630]\n",
            "[Epoch 43/50] [Batch 57/59] [D loss: 0.647580] [G loss: 0.791005]\n",
            "[Epoch 43/50] [Batch 58/59] [D loss: 0.624116] [G loss: 0.750198]\n",
            "[Epoch 44/50] [Batch 0/59] [D loss: 0.640907] [G loss: 0.847962]\n",
            "[Epoch 44/50] [Batch 1/59] [D loss: 0.618130] [G loss: 0.842463]\n",
            "[Epoch 44/50] [Batch 2/59] [D loss: 0.586901] [G loss: 0.747395]\n",
            "[Epoch 44/50] [Batch 3/59] [D loss: 0.615530] [G loss: 0.786938]\n",
            "[Epoch 44/50] [Batch 4/59] [D loss: 0.616878] [G loss: 0.892713]\n",
            "[Epoch 44/50] [Batch 5/59] [D loss: 0.624298] [G loss: 0.860773]\n",
            "[Epoch 44/50] [Batch 6/59] [D loss: 0.634556] [G loss: 0.795349]\n",
            "[Epoch 44/50] [Batch 7/59] [D loss: 0.617488] [G loss: 0.798948]\n",
            "[Epoch 44/50] [Batch 8/59] [D loss: 0.633697] [G loss: 0.758750]\n",
            "[Epoch 44/50] [Batch 9/59] [D loss: 0.671682] [G loss: 0.808649]\n",
            "[Epoch 44/50] [Batch 10/59] [D loss: 0.692872] [G loss: 0.749938]\n",
            "[Epoch 44/50] [Batch 11/59] [D loss: 0.685539] [G loss: 0.746470]\n",
            "[Epoch 44/50] [Batch 12/59] [D loss: 0.703779] [G loss: 0.659949]\n",
            "[Epoch 44/50] [Batch 13/59] [D loss: 0.666951] [G loss: 0.817355]\n",
            "[Epoch 44/50] [Batch 14/59] [D loss: 0.665007] [G loss: 0.796263]\n",
            "[Epoch 44/50] [Batch 15/59] [D loss: 0.658771] [G loss: 0.662124]\n",
            "[Epoch 44/50] [Batch 16/59] [D loss: 0.646334] [G loss: 0.724527]\n",
            "[Epoch 44/50] [Batch 17/59] [D loss: 0.638835] [G loss: 0.983630]\n",
            "[Epoch 44/50] [Batch 18/59] [D loss: 0.617554] [G loss: 0.793468]\n",
            "[Epoch 44/50] [Batch 19/59] [D loss: 0.633887] [G loss: 0.737633]\n",
            "[Epoch 44/50] [Batch 20/59] [D loss: 0.593641] [G loss: 0.827595]\n",
            "[Epoch 44/50] [Batch 21/59] [D loss: 0.627405] [G loss: 0.888665]\n",
            "[Epoch 44/50] [Batch 22/59] [D loss: 0.632410] [G loss: 0.772448]\n",
            "[Epoch 44/50] [Batch 23/59] [D loss: 0.627238] [G loss: 0.735421]\n",
            "[Epoch 44/50] [Batch 24/59] [D loss: 0.664407] [G loss: 0.787132]\n",
            "[Epoch 44/50] [Batch 25/59] [D loss: 0.694148] [G loss: 0.725590]\n",
            "[Epoch 44/50] [Batch 26/59] [D loss: 0.680581] [G loss: 0.802571]\n",
            "[Epoch 44/50] [Batch 27/59] [D loss: 0.654946] [G loss: 0.736320]\n",
            "[Epoch 44/50] [Batch 28/59] [D loss: 0.661613] [G loss: 0.768046]\n",
            "[Epoch 44/50] [Batch 29/59] [D loss: 0.631967] [G loss: 0.742262]\n",
            "[Epoch 44/50] [Batch 30/59] [D loss: 0.643356] [G loss: 0.710028]\n",
            "[Epoch 44/50] [Batch 31/59] [D loss: 0.641243] [G loss: 0.835389]\n",
            "[Epoch 44/50] [Batch 32/59] [D loss: 0.629483] [G loss: 0.796062]\n",
            "[Epoch 44/50] [Batch 33/59] [D loss: 0.611717] [G loss: 0.741662]\n",
            "[Epoch 44/50] [Batch 34/59] [D loss: 0.619103] [G loss: 0.801937]\n",
            "[Epoch 44/50] [Batch 35/59] [D loss: 0.627366] [G loss: 0.810357]\n",
            "[Epoch 44/50] [Batch 36/59] [D loss: 0.634253] [G loss: 0.796619]\n",
            "[Epoch 44/50] [Batch 37/59] [D loss: 0.650449] [G loss: 0.877303]\n",
            "[Epoch 44/50] [Batch 38/59] [D loss: 0.612563] [G loss: 0.776535]\n",
            "[Epoch 44/50] [Batch 39/59] [D loss: 0.649265] [G loss: 0.732716]\n",
            "[Epoch 44/50] [Batch 40/59] [D loss: 0.632927] [G loss: 0.794359]\n",
            "[Epoch 44/50] [Batch 41/59] [D loss: 0.654551] [G loss: 0.897525]\n",
            "[Epoch 44/50] [Batch 42/59] [D loss: 0.664059] [G loss: 0.656996]\n",
            "[Epoch 44/50] [Batch 43/59] [D loss: 0.690303] [G loss: 0.705545]\n",
            "[Epoch 44/50] [Batch 44/59] [D loss: 0.696342] [G loss: 0.973015]\n",
            "[Epoch 44/50] [Batch 45/59] [D loss: 0.649854] [G loss: 0.734727]\n",
            "[Epoch 44/50] [Batch 46/59] [D loss: 0.643786] [G loss: 0.756985]\n",
            "[Epoch 44/50] [Batch 47/59] [D loss: 0.641528] [G loss: 0.830453]\n",
            "[Epoch 44/50] [Batch 48/59] [D loss: 0.622445] [G loss: 0.879454]\n",
            "[Epoch 44/50] [Batch 49/59] [D loss: 0.630106] [G loss: 0.832354]\n",
            "[Epoch 44/50] [Batch 50/59] [D loss: 0.607433] [G loss: 0.865820]\n",
            "[Epoch 44/50] [Batch 51/59] [D loss: 0.621960] [G loss: 0.810274]\n",
            "[Epoch 44/50] [Batch 52/59] [D loss: 0.619309] [G loss: 0.758895]\n",
            "[Epoch 44/50] [Batch 53/59] [D loss: 0.623095] [G loss: 0.892349]\n",
            "[Epoch 44/50] [Batch 54/59] [D loss: 0.613359] [G loss: 0.767188]\n",
            "[Epoch 44/50] [Batch 55/59] [D loss: 0.647664] [G loss: 0.801918]\n",
            "[Epoch 44/50] [Batch 56/59] [D loss: 0.632077] [G loss: 0.775224]\n",
            "[Epoch 44/50] [Batch 57/59] [D loss: 0.659057] [G loss: 0.807055]\n",
            "[Epoch 44/50] [Batch 58/59] [D loss: 0.629954] [G loss: 0.723492]\n",
            "[Epoch 45/50] [Batch 0/59] [D loss: 0.651561] [G loss: 0.807750]\n",
            "[Epoch 45/50] [Batch 1/59] [D loss: 0.663355] [G loss: 0.759259]\n",
            "[Epoch 45/50] [Batch 2/59] [D loss: 0.673957] [G loss: 0.689654]\n",
            "[Epoch 45/50] [Batch 3/59] [D loss: 0.634607] [G loss: 0.748164]\n",
            "[Epoch 45/50] [Batch 4/59] [D loss: 0.636467] [G loss: 0.772237]\n",
            "[Epoch 45/50] [Batch 5/59] [D loss: 0.648051] [G loss: 0.783827]\n",
            "[Epoch 45/50] [Batch 6/59] [D loss: 0.655290] [G loss: 0.770663]\n",
            "[Epoch 45/50] [Batch 7/59] [D loss: 0.636592] [G loss: 0.784480]\n",
            "[Epoch 45/50] [Batch 8/59] [D loss: 0.611790] [G loss: 0.753570]\n",
            "[Epoch 45/50] [Batch 9/59] [D loss: 0.631954] [G loss: 0.784217]\n",
            "[Epoch 45/50] [Batch 10/59] [D loss: 0.640674] [G loss: 0.776150]\n",
            "[Epoch 45/50] [Batch 11/59] [D loss: 0.613956] [G loss: 0.860448]\n",
            "[Epoch 45/50] [Batch 12/59] [D loss: 0.609535] [G loss: 0.808090]\n",
            "[Epoch 45/50] [Batch 13/59] [D loss: 0.645331] [G loss: 0.702551]\n",
            "[Epoch 45/50] [Batch 14/59] [D loss: 0.663344] [G loss: 0.802735]\n",
            "[Epoch 45/50] [Batch 15/59] [D loss: 0.667159] [G loss: 0.878130]\n",
            "[Epoch 45/50] [Batch 16/59] [D loss: 0.672417] [G loss: 0.715136]\n",
            "[Epoch 45/50] [Batch 17/59] [D loss: 0.664992] [G loss: 0.729094]\n",
            "[Epoch 45/50] [Batch 18/59] [D loss: 0.660720] [G loss: 0.776181]\n",
            "[Epoch 45/50] [Batch 19/59] [D loss: 0.662328] [G loss: 0.897043]\n",
            "[Epoch 45/50] [Batch 20/59] [D loss: 0.647217] [G loss: 0.750552]\n",
            "[Epoch 45/50] [Batch 21/59] [D loss: 0.628031] [G loss: 0.809114]\n",
            "[Epoch 45/50] [Batch 22/59] [D loss: 0.632109] [G loss: 0.871816]\n",
            "[Epoch 45/50] [Batch 23/59] [D loss: 0.647782] [G loss: 0.814806]\n",
            "[Epoch 45/50] [Batch 24/59] [D loss: 0.632733] [G loss: 0.855916]\n",
            "[Epoch 45/50] [Batch 25/59] [D loss: 0.626572] [G loss: 0.750624]\n",
            "[Epoch 45/50] [Batch 26/59] [D loss: 0.613617] [G loss: 0.890817]\n",
            "[Epoch 45/50] [Batch 27/59] [D loss: 0.627552] [G loss: 0.841415]\n",
            "[Epoch 45/50] [Batch 28/59] [D loss: 0.630193] [G loss: 0.722620]\n",
            "[Epoch 45/50] [Batch 29/59] [D loss: 0.636353] [G loss: 0.726673]\n",
            "[Epoch 45/50] [Batch 30/59] [D loss: 0.662119] [G loss: 0.847486]\n",
            "[Epoch 45/50] [Batch 31/59] [D loss: 0.642979] [G loss: 0.755175]\n",
            "[Epoch 45/50] [Batch 32/59] [D loss: 0.662988] [G loss: 0.739367]\n",
            "[Epoch 45/50] [Batch 33/59] [D loss: 0.685160] [G loss: 0.746085]\n",
            "[Epoch 45/50] [Batch 34/59] [D loss: 0.682944] [G loss: 0.748641]\n",
            "[Epoch 45/50] [Batch 35/59] [D loss: 0.664563] [G loss: 0.786371]\n",
            "[Epoch 45/50] [Batch 36/59] [D loss: 0.652357] [G loss: 0.763593]\n",
            "[Epoch 45/50] [Batch 37/59] [D loss: 0.632977] [G loss: 0.773808]\n",
            "[Epoch 45/50] [Batch 38/59] [D loss: 0.629673] [G loss: 0.785489]\n",
            "[Epoch 45/50] [Batch 39/59] [D loss: 0.640089] [G loss: 0.782834]\n",
            "[Epoch 45/50] [Batch 40/59] [D loss: 0.637667] [G loss: 0.820126]\n",
            "[Epoch 45/50] [Batch 41/59] [D loss: 0.611363] [G loss: 0.763311]\n",
            "[Epoch 45/50] [Batch 42/59] [D loss: 0.637804] [G loss: 0.780530]\n",
            "[Epoch 45/50] [Batch 43/59] [D loss: 0.626049] [G loss: 0.835359]\n",
            "[Epoch 45/50] [Batch 44/59] [D loss: 0.611784] [G loss: 0.842642]\n",
            "[Epoch 45/50] [Batch 45/59] [D loss: 0.635138] [G loss: 0.802606]\n",
            "[Epoch 45/50] [Batch 46/59] [D loss: 0.659550] [G loss: 0.741961]\n",
            "[Epoch 45/50] [Batch 47/59] [D loss: 0.657258] [G loss: 0.829832]\n",
            "[Epoch 45/50] [Batch 48/59] [D loss: 0.668343] [G loss: 0.833697]\n",
            "[Epoch 45/50] [Batch 49/59] [D loss: 0.666230] [G loss: 0.778515]\n",
            "[Epoch 45/50] [Batch 50/59] [D loss: 0.687710] [G loss: 0.763758]\n",
            "[Epoch 45/50] [Batch 51/59] [D loss: 0.663043] [G loss: 0.813852]\n",
            "[Epoch 45/50] [Batch 52/59] [D loss: 0.658001] [G loss: 0.807150]\n",
            "[Epoch 45/50] [Batch 53/59] [D loss: 0.642502] [G loss: 0.785698]\n",
            "[Epoch 45/50] [Batch 54/59] [D loss: 0.633844] [G loss: 0.812375]\n",
            "[Epoch 45/50] [Batch 55/59] [D loss: 0.612569] [G loss: 0.846006]\n",
            "[Epoch 45/50] [Batch 56/59] [D loss: 0.597170] [G loss: 0.790943]\n",
            "[Epoch 45/50] [Batch 57/59] [D loss: 0.629976] [G loss: 0.759927]\n",
            "[Epoch 45/50] [Batch 58/59] [D loss: 0.640531] [G loss: 0.883509]\n",
            "[Epoch 46/50] [Batch 0/59] [D loss: 0.654006] [G loss: 0.785614]\n",
            "[Epoch 46/50] [Batch 1/59] [D loss: 0.648994] [G loss: 0.764619]\n",
            "[Epoch 46/50] [Batch 2/59] [D loss: 0.657865] [G loss: 0.835952]\n",
            "[Epoch 46/50] [Batch 3/59] [D loss: 0.668096] [G loss: 0.778301]\n",
            "[Epoch 46/50] [Batch 4/59] [D loss: 0.667401] [G loss: 0.789417]\n",
            "[Epoch 46/50] [Batch 5/59] [D loss: 0.683107] [G loss: 0.719307]\n",
            "[Epoch 46/50] [Batch 6/59] [D loss: 0.656811] [G loss: 0.682197]\n",
            "[Epoch 46/50] [Batch 7/59] [D loss: 0.653331] [G loss: 0.741807]\n",
            "[Epoch 46/50] [Batch 8/59] [D loss: 0.652775] [G loss: 0.794773]\n",
            "[Epoch 46/50] [Batch 9/59] [D loss: 0.658183] [G loss: 0.764503]\n",
            "[Epoch 46/50] [Batch 10/59] [D loss: 0.635807] [G loss: 0.725130]\n",
            "[Epoch 46/50] [Batch 11/59] [D loss: 0.639072] [G loss: 0.753763]\n",
            "[Epoch 46/50] [Batch 12/59] [D loss: 0.632904] [G loss: 0.807423]\n",
            "[Epoch 46/50] [Batch 13/59] [D loss: 0.611107] [G loss: 0.823882]\n",
            "[Epoch 46/50] [Batch 14/59] [D loss: 0.625862] [G loss: 0.765914]\n",
            "[Epoch 46/50] [Batch 15/59] [D loss: 0.617539] [G loss: 0.780974]\n",
            "[Epoch 46/50] [Batch 16/59] [D loss: 0.602921] [G loss: 0.845188]\n",
            "[Epoch 46/50] [Batch 17/59] [D loss: 0.610178] [G loss: 0.924955]\n",
            "[Epoch 46/50] [Batch 18/59] [D loss: 0.618912] [G loss: 0.711228]\n",
            "[Epoch 46/50] [Batch 19/59] [D loss: 0.632872] [G loss: 0.813690]\n",
            "[Epoch 46/50] [Batch 20/59] [D loss: 0.624266] [G loss: 0.879353]\n",
            "[Epoch 46/50] [Batch 21/59] [D loss: 0.657829] [G loss: 0.690439]\n",
            "[Epoch 46/50] [Batch 22/59] [D loss: 0.635139] [G loss: 0.744148]\n",
            "[Epoch 46/50] [Batch 23/59] [D loss: 0.661068] [G loss: 0.795484]\n",
            "[Epoch 46/50] [Batch 24/59] [D loss: 0.661673] [G loss: 0.737723]\n",
            "[Epoch 46/50] [Batch 25/59] [D loss: 0.660598] [G loss: 0.846749]\n",
            "[Epoch 46/50] [Batch 26/59] [D loss: 0.685263] [G loss: 0.845737]\n",
            "[Epoch 46/50] [Batch 27/59] [D loss: 0.663642] [G loss: 0.782544]\n",
            "[Epoch 46/50] [Batch 28/59] [D loss: 0.636761] [G loss: 0.849587]\n",
            "[Epoch 46/50] [Batch 29/59] [D loss: 0.643768] [G loss: 0.768808]\n",
            "[Epoch 46/50] [Batch 30/59] [D loss: 0.661267] [G loss: 0.831825]\n",
            "[Epoch 46/50] [Batch 31/59] [D loss: 0.616337] [G loss: 0.870602]\n",
            "[Epoch 46/50] [Batch 32/59] [D loss: 0.653423] [G loss: 0.755853]\n",
            "[Epoch 46/50] [Batch 33/59] [D loss: 0.653547] [G loss: 0.757759]\n",
            "[Epoch 46/50] [Batch 34/59] [D loss: 0.630964] [G loss: 0.934708]\n",
            "[Epoch 46/50] [Batch 35/59] [D loss: 0.643611] [G loss: 0.764515]\n",
            "[Epoch 46/50] [Batch 36/59] [D loss: 0.625797] [G loss: 0.705191]\n",
            "[Epoch 46/50] [Batch 37/59] [D loss: 0.623704] [G loss: 0.882840]\n",
            "[Epoch 46/50] [Batch 38/59] [D loss: 0.665188] [G loss: 0.868318]\n",
            "[Epoch 46/50] [Batch 39/59] [D loss: 0.658605] [G loss: 0.765727]\n",
            "[Epoch 46/50] [Batch 40/59] [D loss: 0.633599] [G loss: 0.670291]\n",
            "[Epoch 46/50] [Batch 41/59] [D loss: 0.660666] [G loss: 0.853500]\n",
            "[Epoch 46/50] [Batch 42/59] [D loss: 0.626520] [G loss: 0.819873]\n",
            "[Epoch 46/50] [Batch 43/59] [D loss: 0.619535] [G loss: 0.783970]\n",
            "[Epoch 46/50] [Batch 44/59] [D loss: 0.604707] [G loss: 0.809626]\n",
            "[Epoch 46/50] [Batch 45/59] [D loss: 0.626055] [G loss: 0.782891]\n",
            "[Epoch 46/50] [Batch 46/59] [D loss: 0.600480] [G loss: 0.832060]\n",
            "[Epoch 46/50] [Batch 47/59] [D loss: 0.619940] [G loss: 0.842793]\n",
            "[Epoch 46/50] [Batch 48/59] [D loss: 0.609369] [G loss: 0.715042]\n",
            "[Epoch 46/50] [Batch 49/59] [D loss: 0.626996] [G loss: 0.787006]\n",
            "[Epoch 46/50] [Batch 50/59] [D loss: 0.626680] [G loss: 0.836466]\n",
            "[Epoch 46/50] [Batch 51/59] [D loss: 0.650338] [G loss: 0.756418]\n",
            "[Epoch 46/50] [Batch 52/59] [D loss: 0.637214] [G loss: 0.706215]\n",
            "[Epoch 46/50] [Batch 53/59] [D loss: 0.668437] [G loss: 0.807352]\n",
            "[Epoch 46/50] [Batch 54/59] [D loss: 0.666827] [G loss: 0.723498]\n",
            "[Epoch 46/50] [Batch 55/59] [D loss: 0.672616] [G loss: 0.757637]\n",
            "[Epoch 46/50] [Batch 56/59] [D loss: 0.652427] [G loss: 0.753917]\n",
            "[Epoch 46/50] [Batch 57/59] [D loss: 0.664903] [G loss: 0.788379]\n",
            "[Epoch 46/50] [Batch 58/59] [D loss: 0.663945] [G loss: 0.782680]\n",
            "[Epoch 47/50] [Batch 0/59] [D loss: 0.634106] [G loss: 0.767188]\n",
            "[Epoch 47/50] [Batch 1/59] [D loss: 0.623872] [G loss: 0.876330]\n",
            "[Epoch 47/50] [Batch 2/59] [D loss: 0.618245] [G loss: 0.801961]\n",
            "[Epoch 47/50] [Batch 3/59] [D loss: 0.626835] [G loss: 0.724722]\n",
            "[Epoch 47/50] [Batch 4/59] [D loss: 0.604547] [G loss: 0.880524]\n",
            "[Epoch 47/50] [Batch 5/59] [D loss: 0.614941] [G loss: 0.816589]\n",
            "[Epoch 47/50] [Batch 6/59] [D loss: 0.633993] [G loss: 0.705322]\n",
            "[Epoch 47/50] [Batch 7/59] [D loss: 0.639147] [G loss: 0.934008]\n",
            "[Epoch 47/50] [Batch 8/59] [D loss: 0.658901] [G loss: 0.824077]\n",
            "[Epoch 47/50] [Batch 9/59] [D loss: 0.630534] [G loss: 0.744814]\n",
            "[Epoch 47/50] [Batch 10/59] [D loss: 0.642879] [G loss: 0.700405]\n",
            "[Epoch 47/50] [Batch 11/59] [D loss: 0.640262] [G loss: 0.890258]\n",
            "[Epoch 47/50] [Batch 12/59] [D loss: 0.643576] [G loss: 0.784518]\n",
            "[Epoch 47/50] [Batch 13/59] [D loss: 0.634304] [G loss: 0.789662]\n",
            "[Epoch 47/50] [Batch 14/59] [D loss: 0.665108] [G loss: 0.826487]\n",
            "[Epoch 47/50] [Batch 15/59] [D loss: 0.649250] [G loss: 0.650846]\n",
            "[Epoch 47/50] [Batch 16/59] [D loss: 0.628046] [G loss: 0.855720]\n",
            "[Epoch 47/50] [Batch 17/59] [D loss: 0.604301] [G loss: 0.880388]\n",
            "[Epoch 47/50] [Batch 18/59] [D loss: 0.645862] [G loss: 0.658978]\n",
            "[Epoch 47/50] [Batch 19/59] [D loss: 0.627891] [G loss: 0.824622]\n",
            "[Epoch 47/50] [Batch 20/59] [D loss: 0.620543] [G loss: 0.841596]\n",
            "[Epoch 47/50] [Batch 21/59] [D loss: 0.639827] [G loss: 0.708883]\n",
            "[Epoch 47/50] [Batch 22/59] [D loss: 0.653180] [G loss: 0.767890]\n",
            "[Epoch 47/50] [Batch 23/59] [D loss: 0.667219] [G loss: 0.798035]\n",
            "[Epoch 47/50] [Batch 24/59] [D loss: 0.667224] [G loss: 0.848953]\n",
            "[Epoch 47/50] [Batch 25/59] [D loss: 0.659473] [G loss: 0.663080]\n",
            "[Epoch 47/50] [Batch 26/59] [D loss: 0.656167] [G loss: 0.777646]\n",
            "[Epoch 47/50] [Batch 27/59] [D loss: 0.642119] [G loss: 0.832394]\n",
            "[Epoch 47/50] [Batch 28/59] [D loss: 0.659781] [G loss: 0.727605]\n",
            "[Epoch 47/50] [Batch 29/59] [D loss: 0.624202] [G loss: 0.820096]\n",
            "[Epoch 47/50] [Batch 30/59] [D loss: 0.624787] [G loss: 0.832985]\n",
            "[Epoch 47/50] [Batch 31/59] [D loss: 0.621175] [G loss: 0.768116]\n",
            "[Epoch 47/50] [Batch 32/59] [D loss: 0.613951] [G loss: 0.898436]\n",
            "[Epoch 47/50] [Batch 33/59] [D loss: 0.594276] [G loss: 0.832133]\n",
            "[Epoch 47/50] [Batch 34/59] [D loss: 0.616072] [G loss: 0.798435]\n",
            "[Epoch 47/50] [Batch 35/59] [D loss: 0.632408] [G loss: 0.870092]\n",
            "[Epoch 47/50] [Batch 36/59] [D loss: 0.660567] [G loss: 0.757009]\n",
            "[Epoch 47/50] [Batch 37/59] [D loss: 0.646562] [G loss: 0.806304]\n",
            "[Epoch 47/50] [Batch 38/59] [D loss: 0.620141] [G loss: 0.828757]\n",
            "[Epoch 47/50] [Batch 39/59] [D loss: 0.637284] [G loss: 0.731458]\n",
            "[Epoch 47/50] [Batch 40/59] [D loss: 0.654015] [G loss: 0.792608]\n",
            "[Epoch 47/50] [Batch 41/59] [D loss: 0.623162] [G loss: 0.908226]\n",
            "[Epoch 47/50] [Batch 42/59] [D loss: 0.660044] [G loss: 0.796095]\n",
            "[Epoch 47/50] [Batch 43/59] [D loss: 0.647998] [G loss: 0.728229]\n",
            "[Epoch 47/50] [Batch 44/59] [D loss: 0.635446] [G loss: 0.865687]\n",
            "[Epoch 47/50] [Batch 45/59] [D loss: 0.646078] [G loss: 0.894209]\n",
            "[Epoch 47/50] [Batch 46/59] [D loss: 0.659297] [G loss: 0.741758]\n",
            "[Epoch 47/50] [Batch 47/59] [D loss: 0.663352] [G loss: 0.758263]\n",
            "[Epoch 47/50] [Batch 48/59] [D loss: 0.627914] [G loss: 0.812813]\n",
            "[Epoch 47/50] [Batch 49/59] [D loss: 0.653371] [G loss: 0.710166]\n",
            "[Epoch 47/50] [Batch 50/59] [D loss: 0.643849] [G loss: 0.778702]\n",
            "[Epoch 47/50] [Batch 51/59] [D loss: 0.652290] [G loss: 0.866288]\n",
            "[Epoch 47/50] [Batch 52/59] [D loss: 0.648746] [G loss: 0.679954]\n",
            "[Epoch 47/50] [Batch 53/59] [D loss: 0.646005] [G loss: 0.718000]\n",
            "[Epoch 47/50] [Batch 54/59] [D loss: 0.624576] [G loss: 0.964550]\n",
            "[Epoch 47/50] [Batch 55/59] [D loss: 0.612108] [G loss: 0.713589]\n",
            "[Epoch 47/50] [Batch 56/59] [D loss: 0.644772] [G loss: 0.699476]\n",
            "[Epoch 47/50] [Batch 57/59] [D loss: 0.640780] [G loss: 0.877733]\n",
            "[Epoch 47/50] [Batch 58/59] [D loss: 0.655329] [G loss: 0.802335]\n",
            "[Epoch 48/50] [Batch 0/59] [D loss: 0.617068] [G loss: 0.787070]\n",
            "[Epoch 48/50] [Batch 1/59] [D loss: 0.643478] [G loss: 0.816308]\n",
            "[Epoch 48/50] [Batch 2/59] [D loss: 0.622040] [G loss: 0.846604]\n",
            "[Epoch 48/50] [Batch 3/59] [D loss: 0.630947] [G loss: 0.784403]\n",
            "[Epoch 48/50] [Batch 4/59] [D loss: 0.626789] [G loss: 0.858708]\n",
            "[Epoch 48/50] [Batch 5/59] [D loss: 0.662826] [G loss: 0.792043]\n",
            "[Epoch 48/50] [Batch 6/59] [D loss: 0.662564] [G loss: 0.728133]\n",
            "[Epoch 48/50] [Batch 7/59] [D loss: 0.633639] [G loss: 0.843886]\n",
            "[Epoch 48/50] [Batch 8/59] [D loss: 0.650040] [G loss: 0.825464]\n",
            "[Epoch 48/50] [Batch 9/59] [D loss: 0.653711] [G loss: 0.728406]\n",
            "[Epoch 48/50] [Batch 10/59] [D loss: 0.635867] [G loss: 0.783585]\n",
            "[Epoch 48/50] [Batch 11/59] [D loss: 0.638694] [G loss: 0.883102]\n",
            "[Epoch 48/50] [Batch 12/59] [D loss: 0.643570] [G loss: 0.758807]\n",
            "[Epoch 48/50] [Batch 13/59] [D loss: 0.645540] [G loss: 0.784500]\n",
            "[Epoch 48/50] [Batch 14/59] [D loss: 0.648682] [G loss: 0.812525]\n",
            "[Epoch 48/50] [Batch 15/59] [D loss: 0.638528] [G loss: 0.809950]\n",
            "[Epoch 48/50] [Batch 16/59] [D loss: 0.621843] [G loss: 0.849214]\n",
            "[Epoch 48/50] [Batch 17/59] [D loss: 0.602859] [G loss: 0.832614]\n",
            "[Epoch 48/50] [Batch 18/59] [D loss: 0.643026] [G loss: 0.763822]\n",
            "[Epoch 48/50] [Batch 19/59] [D loss: 0.635633] [G loss: 0.918143]\n",
            "[Epoch 48/50] [Batch 20/59] [D loss: 0.618182] [G loss: 0.782369]\n",
            "[Epoch 48/50] [Batch 21/59] [D loss: 0.634844] [G loss: 0.796688]\n",
            "[Epoch 48/50] [Batch 22/59] [D loss: 0.645594] [G loss: 0.848814]\n",
            "[Epoch 48/50] [Batch 23/59] [D loss: 0.625051] [G loss: 0.795329]\n",
            "[Epoch 48/50] [Batch 24/59] [D loss: 0.649938] [G loss: 0.739663]\n",
            "[Epoch 48/50] [Batch 25/59] [D loss: 0.625809] [G loss: 0.822037]\n",
            "[Epoch 48/50] [Batch 26/59] [D loss: 0.666438] [G loss: 0.772949]\n",
            "[Epoch 48/50] [Batch 27/59] [D loss: 0.667288] [G loss: 0.746626]\n",
            "[Epoch 48/50] [Batch 28/59] [D loss: 0.679257] [G loss: 0.861350]\n",
            "[Epoch 48/50] [Batch 29/59] [D loss: 0.636709] [G loss: 0.767610]\n",
            "[Epoch 48/50] [Batch 30/59] [D loss: 0.637373] [G loss: 0.744450]\n",
            "[Epoch 48/50] [Batch 31/59] [D loss: 0.634758] [G loss: 0.788628]\n",
            "[Epoch 48/50] [Batch 32/59] [D loss: 0.633278] [G loss: 0.879042]\n",
            "[Epoch 48/50] [Batch 33/59] [D loss: 0.639228] [G loss: 0.747613]\n",
            "[Epoch 48/50] [Batch 34/59] [D loss: 0.626016] [G loss: 0.764495]\n",
            "[Epoch 48/50] [Batch 35/59] [D loss: 0.624130] [G loss: 0.865789]\n",
            "[Epoch 48/50] [Batch 36/59] [D loss: 0.655888] [G loss: 0.712011]\n",
            "[Epoch 48/50] [Batch 37/59] [D loss: 0.653444] [G loss: 0.727531]\n",
            "[Epoch 48/50] [Batch 38/59] [D loss: 0.646451] [G loss: 0.881989]\n",
            "[Epoch 48/50] [Batch 39/59] [D loss: 0.663107] [G loss: 0.803994]\n",
            "[Epoch 48/50] [Batch 40/59] [D loss: 0.655915] [G loss: 0.624767]\n",
            "[Epoch 48/50] [Batch 41/59] [D loss: 0.618218] [G loss: 0.788159]\n",
            "[Epoch 48/50] [Batch 42/59] [D loss: 0.625708] [G loss: 0.883073]\n",
            "[Epoch 48/50] [Batch 43/59] [D loss: 0.635049] [G loss: 0.738015]\n",
            "[Epoch 48/50] [Batch 44/59] [D loss: 0.608218] [G loss: 0.738810]\n",
            "[Epoch 48/50] [Batch 45/59] [D loss: 0.621664] [G loss: 0.874837]\n",
            "[Epoch 48/50] [Batch 46/59] [D loss: 0.618182] [G loss: 0.747727]\n",
            "[Epoch 48/50] [Batch 47/59] [D loss: 0.601140] [G loss: 0.840289]\n",
            "[Epoch 48/50] [Batch 48/59] [D loss: 0.615427] [G loss: 0.758981]\n",
            "[Epoch 48/50] [Batch 49/59] [D loss: 0.618981] [G loss: 0.814212]\n",
            "[Epoch 48/50] [Batch 50/59] [D loss: 0.621826] [G loss: 0.809711]\n",
            "[Epoch 48/50] [Batch 51/59] [D loss: 0.638146] [G loss: 0.765066]\n",
            "[Epoch 48/50] [Batch 52/59] [D loss: 0.638296] [G loss: 0.885078]\n",
            "[Epoch 48/50] [Batch 53/59] [D loss: 0.637946] [G loss: 0.703148]\n",
            "[Epoch 48/50] [Batch 54/59] [D loss: 0.644812] [G loss: 0.703415]\n",
            "[Epoch 48/50] [Batch 55/59] [D loss: 0.669877] [G loss: 0.901963]\n",
            "[Epoch 48/50] [Batch 56/59] [D loss: 0.668205] [G loss: 0.687883]\n",
            "[Epoch 48/50] [Batch 57/59] [D loss: 0.652418] [G loss: 0.736476]\n",
            "[Epoch 48/50] [Batch 58/59] [D loss: 0.651208] [G loss: 0.842304]\n",
            "[Epoch 49/50] [Batch 0/59] [D loss: 0.635283] [G loss: 0.844463]\n",
            "[Epoch 49/50] [Batch 1/59] [D loss: 0.658145] [G loss: 0.777395]\n",
            "[Epoch 49/50] [Batch 2/59] [D loss: 0.603543] [G loss: 0.753179]\n",
            "[Epoch 49/50] [Batch 3/59] [D loss: 0.652328] [G loss: 0.906712]\n",
            "[Epoch 49/50] [Batch 4/59] [D loss: 0.599938] [G loss: 0.760011]\n",
            "[Epoch 49/50] [Batch 5/59] [D loss: 0.609859] [G loss: 0.817240]\n",
            "[Epoch 49/50] [Batch 6/59] [D loss: 0.634233] [G loss: 0.872820]\n",
            "[Epoch 49/50] [Batch 7/59] [D loss: 0.640466] [G loss: 0.806715]\n",
            "[Epoch 49/50] [Batch 8/59] [D loss: 0.625934] [G loss: 0.798530]\n",
            "[Epoch 49/50] [Batch 9/59] [D loss: 0.618679] [G loss: 0.846710]\n",
            "[Epoch 49/50] [Batch 10/59] [D loss: 0.654524] [G loss: 0.802765]\n",
            "[Epoch 49/50] [Batch 11/59] [D loss: 0.658923] [G loss: 0.813980]\n",
            "[Epoch 49/50] [Batch 12/59] [D loss: 0.655237] [G loss: 0.706117]\n",
            "[Epoch 49/50] [Batch 13/59] [D loss: 0.638204] [G loss: 0.809121]\n",
            "[Epoch 49/50] [Batch 14/59] [D loss: 0.648628] [G loss: 0.945101]\n",
            "[Epoch 49/50] [Batch 15/59] [D loss: 0.620019] [G loss: 0.787927]\n",
            "[Epoch 49/50] [Batch 16/59] [D loss: 0.612568] [G loss: 0.739798]\n",
            "[Epoch 49/50] [Batch 17/59] [D loss: 0.649026] [G loss: 0.896790]\n",
            "[Epoch 49/50] [Batch 18/59] [D loss: 0.623433] [G loss: 0.782916]\n",
            "[Epoch 49/50] [Batch 19/59] [D loss: 0.616805] [G loss: 0.746475]\n",
            "[Epoch 49/50] [Batch 20/59] [D loss: 0.629224] [G loss: 0.828913]\n",
            "[Epoch 49/50] [Batch 21/59] [D loss: 0.627831] [G loss: 0.837201]\n",
            "[Epoch 49/50] [Batch 22/59] [D loss: 0.639416] [G loss: 0.728649]\n",
            "[Epoch 49/50] [Batch 23/59] [D loss: 0.647020] [G loss: 0.745581]\n",
            "[Epoch 49/50] [Batch 24/59] [D loss: 0.655630] [G loss: 0.835054]\n",
            "[Epoch 49/50] [Batch 25/59] [D loss: 0.647366] [G loss: 0.765165]\n",
            "[Epoch 49/50] [Batch 26/59] [D loss: 0.615385] [G loss: 0.777240]\n",
            "[Epoch 49/50] [Batch 27/59] [D loss: 0.635425] [G loss: 0.815887]\n",
            "[Epoch 49/50] [Batch 28/59] [D loss: 0.630500] [G loss: 0.866177]\n",
            "[Epoch 49/50] [Batch 29/59] [D loss: 0.612205] [G loss: 0.707599]\n",
            "[Epoch 49/50] [Batch 30/59] [D loss: 0.624527] [G loss: 0.874965]\n",
            "[Epoch 49/50] [Batch 31/59] [D loss: 0.615841] [G loss: 0.805749]\n",
            "[Epoch 49/50] [Batch 32/59] [D loss: 0.648236] [G loss: 0.788133]\n",
            "[Epoch 49/50] [Batch 33/59] [D loss: 0.633320] [G loss: 0.805745]\n",
            "[Epoch 49/50] [Batch 34/59] [D loss: 0.632624] [G loss: 0.762800]\n",
            "[Epoch 49/50] [Batch 35/59] [D loss: 0.618342] [G loss: 0.835020]\n",
            "[Epoch 49/50] [Batch 36/59] [D loss: 0.630049] [G loss: 0.864024]\n",
            "[Epoch 49/50] [Batch 37/59] [D loss: 0.645968] [G loss: 0.749234]\n",
            "[Epoch 49/50] [Batch 38/59] [D loss: 0.607000] [G loss: 0.840345]\n",
            "[Epoch 49/50] [Batch 39/59] [D loss: 0.655971] [G loss: 0.876262]\n",
            "[Epoch 49/50] [Batch 40/59] [D loss: 0.621998] [G loss: 0.721422]\n",
            "[Epoch 49/50] [Batch 41/59] [D loss: 0.647130] [G loss: 0.768501]\n",
            "[Epoch 49/50] [Batch 42/59] [D loss: 0.666918] [G loss: 0.977670]\n",
            "[Epoch 49/50] [Batch 43/59] [D loss: 0.631213] [G loss: 0.697585]\n",
            "[Epoch 49/50] [Batch 44/59] [D loss: 0.655677] [G loss: 0.725418]\n",
            "[Epoch 49/50] [Batch 45/59] [D loss: 0.621515] [G loss: 0.855222]\n",
            "[Epoch 49/50] [Batch 46/59] [D loss: 0.653308] [G loss: 0.838367]\n",
            "[Epoch 49/50] [Batch 47/59] [D loss: 0.670634] [G loss: 0.754012]\n",
            "[Epoch 49/50] [Batch 48/59] [D loss: 0.604885] [G loss: 0.743343]\n",
            "[Epoch 49/50] [Batch 49/59] [D loss: 0.671136] [G loss: 0.772014]\n",
            "[Epoch 49/50] [Batch 50/59] [D loss: 0.647360] [G loss: 0.882953]\n",
            "[Epoch 49/50] [Batch 51/59] [D loss: 0.614797] [G loss: 0.698448]\n",
            "[Epoch 49/50] [Batch 52/59] [D loss: 0.655873] [G loss: 0.810852]\n",
            "[Epoch 49/50] [Batch 53/59] [D loss: 0.664596] [G loss: 0.891654]\n",
            "[Epoch 49/50] [Batch 54/59] [D loss: 0.617529] [G loss: 0.811178]\n",
            "[Epoch 49/50] [Batch 55/59] [D loss: 0.619889] [G loss: 0.746967]\n",
            "[Epoch 49/50] [Batch 56/59] [D loss: 0.620947] [G loss: 0.919279]\n",
            "[Epoch 49/50] [Batch 57/59] [D loss: 0.614572] [G loss: 0.890804]\n",
            "[Epoch 49/50] [Batch 58/59] [D loss: 0.616107] [G loss: 0.730851]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Displaying Generated image (Could be error as we need to run the training again)"
      ],
      "metadata": {
        "id": "Ni6mhs-ortzw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "out = generator(z)\n",
        "n=607\n",
        "f, axarr = plt.subplots(1,1)\n",
        "z1 = z.cpu().detach().numpy()\n",
        "out = out.cpu().detach().numpy()\n",
        "axarr[1].imshow(out[n][0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "id": "O05KoIlZ8Xwj",
        "outputId": "2f61f5e1-8cdc-435e-bf14-0f78ece08787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-21844614283e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m607\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxarr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'generator' is not defined"
          ]
        }
      ]
    }
  ]
}